# -*- coding: utf-8 -*-
"""
æ–‡ä»¶å: Telegram.Node_Final V1.R1 
è„šæœ¬è¯´æ˜:ä½¿ç”¨XC speedtestæµ‹é€Ÿ
æœ¬è„šæœ¬å®ç°ä»æŒ‡å®š Telegram é¢‘é“è‡ªåŠ¨çˆ¬å–è®¢é˜…é“¾æ¥ï¼›
ä¸‹è½½å¹¶è§£æå„ç§ä»£ç†è®¢é˜…èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ vmess, vless, ssr, ss, trojan, hysteriaåŠhysteria2ç­‰åè®®ï¼‰ï¼Œ
æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ä¸é‡å‘½åï¼Œå¹¶ä½¿ç”¨ Clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆå»¶è¿Ÿæµ‹è¯•ï¼‰ï¼›
æœ€ç»ˆç”Ÿæˆå¯ç”¨äº Clash ä½¿ç”¨çš„ YAML é…ç½®æ–‡ä»¶ã€‚
ä¸»è¦åŠŸèƒ½:
1. ä» Telegram æŒ‡å®šé¢‘é“æŠ“å–å¸¦æœ‰è®¢é˜…é“¾æ¥çš„æ¶ˆæ¯ï¼Œæ”¯æŒæ—¶é—´çª—å£è¿‡æ»¤æ–°æ¶ˆæ¯ã€‚
2. æ”¯æŒå¤šç§å¸¸è§ä»£ç†åè®®çš„èŠ‚ç‚¹è§£æï¼Œä»¥åŠè¯†åˆ«èŠ‚ç‚¹æ‰€åœ¨åŒºåŸŸã€‚
3. é‡‡ç”¨å‘½ä»¤è¡Œæ¨¡å¼è°ƒç”¨ clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯•ï¼Œç­›é€‰æœ‰æ•ˆèŠ‚ç‚¹ã€‚
4. æ ¹æ®èŠ‚ç‚¹åœ°åŒºä¸å»¶è¿Ÿè‡ªåŠ¨æ’åºå’Œå½’ç±»ï¼Œç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶ã€‚
5. ç¯å¢ƒå˜é‡é…ç½®çµæ´»ï¼Œæ–¹ä¾¿é›†æˆè‡ªåŠ¨åŒ–æµç¨‹ã€‚
"""
import os
import re
import sys
import base64
import json
import yaml
import time
import socket
import hashlib
import asyncio
import shutil
import subprocess
import concurrent.futures
import tempfile
import requests
import socket
# === æ–°å¢è¿™å‡ è¡Œï¼Œè­¦å‘Šç«‹åˆ»æ¶ˆå¤± ===
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="urllib3.connectionpool")
# ============================================
from concurrent.futures import as_completed
from urllib.parse import urlparse, parse_qs, unquote
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from telethon.sync import TelegramClient
from telethon.sessions import StringSession

# --- ç¯å¢ƒå˜é‡è¯»å– ---
API_ID = int(os.environ.get('TELEGRAM_API_ID') or 0)
API_HASH = os.environ.get('TELEGRAM_API_HASH')
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS', '')
TIME_WINDOW_HOURS = 4  # æŠ“å–å¤šé•¿æ—¶é—´çš„æ¶ˆæ¯ï¼Œå•ä½ä¸ºå°æ—¶ã€‚
MIN_EXPIRE_HOURS = 2   # è®¢é˜…åœ°å€å‰©ä½™æ—¶é—´æœ€å°è¿‡æœŸï¼Œå•ä½ä¸ºå°æ—¶ã€‚
OUTPUT_FILE = 'flclashyaml/Tg-node1.yaml'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºä¿å­˜ç”Ÿæˆçš„é…ç½®æˆ–ç»“æœã€‚
last_warp_start_time = 0


# === æ–°å¢ï¼šæµ‹é€Ÿç­–ç•¥å¼€å…³ï¼ˆæ¨èä¿ç•™è¿™å‡ ä¸ªé€‰é¡¹ï¼‰===


# æµ‹é€Ÿæ¨¡å¼ï¼š
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æ•´ä½“é€Ÿåº¦æµ‹è¯•åŠŸèƒ½ï¼ŒTrueè¡¨ç¤ºå¯ç”¨ã€‚æµ‹è¯•é¡ºåºå¦‚ä¸‹

SPEEDTEST_MODE = os.getenv('SPEEDTEST_MODE', 'tcp_first').lower()  # é»˜è®¤æ¨è tcp_first,ä¸‹è¾¹çš„å‘½ä»¤
#   "tcp_only"      â†’ åªç”¨ TCP æµ‹é€Ÿï¼ˆæœ€å¿«ï¼Œæœ€ä¸¥æ ¼ï¼Œé€‚åˆèŠ‚ç‚¹ç‰¹åˆ«å¤šçš„æƒ…å†µï¼‰
#   "clash_only"    â†’ åªç”¨ Clash -fast æµ‹é€Ÿï¼ˆæœ€å‡†ï¼‰
#   "tcp_first"     â†’ å…ˆ TCP ç²—ç­›ï¼ˆ<800msï¼‰â†’ å† Clash ç²¾æµ‹ï¼ˆæ¨èï¼å¹³è¡¡é€Ÿåº¦ä¸è´¨é‡ï¼‰
#   "clash_first"   â†’ å…ˆ Clash â†’ å† TCPï¼ˆä¸€èˆ¬ç”¨ä¸ä¸Šï¼‰

# TCP å’ŒClash æµ‹é€Ÿä¸“å±å‚æ•°
TCP_TIMEOUT = 3.5          # å•æ¬¡ TCP è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå»ºè®® 3~5
TCP_MAX_WORKERS = 256     # TCP æµ‹é€Ÿæœ€å¤§å¹¶å‘ï¼ˆå¯ä»¥æ¯” Clash é«˜å¾ˆå¤šï¼Œéå¸¸å¿«ï¼‰
TCP_MAX_DELAY = 1000       # TCP å»¶è¿Ÿé˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼ç›´æ¥ä¸¢å¼ƒï¼ˆmsï¼‰

# TCP å’ŒClash æ—¥å¿—ç¯å¢ƒå˜é‡ä¸“å±å‚æ•°
def str_to_bool(s: str) -> bool:
    return s.strip().lower() in ('true', '1', 'yes')
    
ENABLE_TCP_LOG = str_to_bool(os.getenv('ENABLE_TCP_LOG', 'false'))
ENABLE_SPEEDTEST_LOG = str_to_bool(os.getenv('ENABLE_SPEEDTEST_LOG', 'false'))


MAX_TEST_WORKERS = 48    # é€Ÿåº¦æµ‹è¯•æ—¶æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼Œæ§åˆ¶æµ‹è¯•çš„å¹¶è¡Œåº¦ã€‚å»ºè®®64-96
SOCKET_TIMEOUT = 3       # å¥—æ¥å­—è¿æ¥è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
HTTP_TIMEOUT = 5         # HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
# ã€å…³é”®ä¿®æ”¹1ã€‘æµ‹é€Ÿç›®æ ‡å…¨éƒ¨æ¢æˆå›½å†…/Cloudflareä¸­å›½èŠ‚ç‚¹
TEST_URLS_GITHUB = [
    "https://www.google.com/generate_204",
    "https://clients3.google.com/generate_204"
]

TEST_URLS_WARP = [
    'http://www.baidu.com/generate_204',
    'http://qq.com/generate_204',
    'http://connect.rom.miui.com/generate_204',
    'http://connectivitycheck.platform.hicloud.com/generate_204'
]

# ==================== æµ‹é€Ÿç»“æœ_å¸¦å®½ç­›é€‰é…ç½®ï¼ˆæ–°å¢ï¼‰ ====================
# æ˜¯å¦å¯ç”¨å¸¦å®½ç­›é€‰ï¼ˆTrue=å¯ç”¨ï¼ŒFalse=å…³é—­ï¼‰
ENABLE_BANDWIDTH_FILTER = os.getenv('ENABLE_BANDWIDTH_FILTER', 'true').lower() == 'true'

# æœ€ä½å¸¦å®½é˜ˆå€¼ï¼ˆå•ä½ï¼šMB/sï¼‰
# æ”¯æŒç¯å¢ƒå˜é‡è®¾ç½®ï¼Œä¾‹å¦‚åœ¨ GitHub Actions é‡Œè¿™æ ·å†™ï¼š
# ENABLE_BANDWIDTH_FILTER=true
# MIN_BANDWIDTH_MB=30
MIN_BANDWIDTH_MB = float(os.getenv('MIN_BANDWIDTH_MB', '25'))  # ç­›é€‰æµ‹é€Ÿå®½åº¦çš„é€Ÿåº¦ã€‚é»˜è®¤ 25MB/sï¼Œå¯è‡ªç”±æ”¹

# ==================== å›½å®¶åŒ¹é…é…ç½® ====================
ALLOWED_REGIONS = {
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
}
REGION_PRIORITY = [
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
]
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {
        'code': 'HK',
        'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong|HongKong|HKBN|HGC|PCCW|WTT|HKT|ä¹é¾™|æ²™ç”°|å±¯é—¨|èƒæ¹¾|æ·±æ°´åŸ—|æ²¹å°–æ—º'
    },
    'æ—¥æœ¬': {
        'code': 'JP',
        'pattern': r'æ—¥æœ¬|æ—¥|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|äº¬æ—¥|å¹¿æ—¥|JP|Japan|Tokyo|Osaka|Saitama|åŸ¼ç‰|åå¤å±‹|Nagoya|ç¦å†ˆ|Fukuoka|æ¨ªæ»¨|Yokohama|NTT|IIJ|GMO|Linode'
    },
    'æ–°åŠ å¡': {
        'code': 'SG',
        'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|ç‹®|æ–°|SG|Singapore|SG\d+|SGP|æ˜Ÿ|ç‹®å­åŸ'
    },
    'ç¾å›½': {
        'code': 'US',
        'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|ä¿„å‹’å†ˆ|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥|çº½çº¦|è¿ˆé˜¿å¯†|äºšç‰¹å…°å¤§|US|USA|United\s*States|America|LA|NYC|SF|San\s*Francisco|Washington|åç››é¡¿|Kansas|å ªè¨æ–¯|Denver|ä¸¹ä½›|Phoenix|Seattle|Chicago|Boston|æ³¢å£«é¡¿|Atlanta|Miami|Las\s*Vegas'
    },
    'å°æ¹¾': {
        'code': 'TW',
        'pattern': r'å°æ¹¾|æ¹¾çœ|å°|TW|Taiwan|TWN|å°åŒ—|Taipei|å°ä¸­|Taichung|é«˜é›„|Kaohsiung|æ–°åŒ—|å½°åŒ–|Hinet|ä¸­åç”µä¿¡'
    },
    'éŸ©å›½': {
        'code': 'KR',
        'pattern': r'éŸ©å›½|éŸ©|å—æœé²œ|é¦–å°”|é‡œå±±|ä»å·|KR|Korea|KOR|éŸ“|Seoul|Busan|KT|SK|LG'
    },
    'å¾·å›½': {
        'code': 'DE',
        'pattern': r'å¾·å›½|å¾·|æ³•å…°å…‹ç¦|æ…•å°¼é»‘|æŸæ—|DE|Germany|Frankfurt|Munich|Berlin|Hetzner'
    },
    'è‹±å›½': {
        'code': 'GB',
        'pattern': r'è‹±å›½|è‹±|ä¼¦æ•¦|æ›¼å½»æ–¯ç‰¹|UK|GB|United\s*Kingdom|Britain|England|London|Manchester'
    },
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|é©¬æ¥|MY|Malaysia'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'æ³°å›½': {
    'code': 'TH',
    'pattern': r'æ³°å›½|TH|Thailand|æ›¼è°·|Bangkok'
},
    'è²å¾‹å®¾': {
    'code': 'PH',
    'pattern': r'è²å¾‹å®¾|PH|Philippines|é©¬å°¼æ‹‰|Manila'
},
    'å°åº¦å°¼è¥¿äºš': {
    'code': 'ID',
    'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia|é›…åŠ è¾¾|Jakarta'
},
    'ä¿„ç½—æ–¯': {
    'code': 'RU',
    'pattern': r'ä¿„ç½—æ–¯|RU|Russia|è«æ–¯ç§‘|Moscow'
},
    'æ„å¤§åˆ©': {
    'code': 'IT',
    'pattern': r'æ„å¤§åˆ©|IT|Italy|ç½—é©¬|Rome'
},
    'å·´è¥¿': {
    'code': 'BR',
    'pattern': r'å·´è¥¿|BR|Brazil|åœ£ä¿ç½—|SÃ£o\s*Paulo'
},
    'é˜¿æ ¹å»·': {
    'code': 'AR',
    'pattern': r'é˜¿æ ¹å»·|AR|Argentina|å¸ƒå®œè¯ºæ–¯è‰¾åˆ©æ–¯|Buenos\s*Aires'
},
    'åœŸè€³å…¶': {
    'code': 'TR',
    'pattern': r'åœŸè€³å…¶|TR|Turkey|ä¼Šæ–¯å¦å¸ƒå°”|Istanbul'
}
}
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')
BJ_TZ = timezone(timedelta(hours=8))

def do_speed_test():
    if not ENABLE_SPEED_TEST:
        print("æµ‹é€ŸåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡ã€‚")
        return
    # å¯ç”¨æµ‹é€Ÿå¹¶æ‰“å°æ—¥å¿—
    run_speedtest(enable_tcp_log=False)
    
# ==================== æ ¹æ®ç½‘ç»œé€‰æ‹©æµ‹é€Ÿåœ°å€ï¼Œåœ°å€å¦‚ä¸Šå˜é‡ ====================
def get_test_urls():
    if is_warp_enabled():
        print("æ£€æµ‹åˆ° Warp ç½‘ç»œï¼Œä½¿ç”¨å›½å†…æµ‹é€Ÿåœ°å€")
        return TEST_URLS_WARP
    else:
        print("é Warp ç½‘ç»œï¼Œä½¿ç”¨è°·æ­Œæµ‹é€Ÿåœ°å€")
        return TEST_URLS_GITHUB

# ==================== æ™ºèƒ½ç½‘ç»œæ§åˆ¶é…ç½® ====================
def get_network_config():
    """
    è·å–ç½‘ç»œé…ç½®ï¼Œå¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨åˆ™ä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼å¹¶è­¦å‘Š
    è¿”å›é…ç½®å­—å…¸å’Œæ˜¯å¦æ‰€æœ‰é…ç½®éƒ½æ¥è‡ªç¯å¢ƒå˜é‡
    """
    config = {}
    all_from_env = True
    
    # é…ç½®æ˜ å°„è¡¨ï¼šç¯å¢ƒå˜é‡å -> é»˜è®¤å€¼ -> æè¿°
    config_spec = {
        'WARP_FOR_SCRAPING': {
            'default': False, 
            'desc': 'TelegramæŠ“å–é˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'falseï¼ˆä½¿ç”¨GitHubç½‘ç»œï¼Œé€Ÿåº¦å¿«ï¼‰'
        },
        'WARP_FOR_TCP': {
            'default': True, 
            'desc': 'TCPæµ‹é€Ÿé˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'trueï¼ˆä½¿ç”¨Warpæ¨¡æ‹Ÿå›½å†…ç¯å¢ƒï¼‰'
        },
        'WARP_FOR_SPEEDTEST': {
            'default': True, 
            'desc': 'Speedtestæµ‹é€Ÿé˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'trueï¼ˆä½¿ç”¨Warpæ¨¡æ‹Ÿå›½å†…ç¯å¢ƒï¼‰'
        },
        'WARP_FOR_FINAL': {
            'default': False, 
            'desc': 'æœ€ç»ˆå¤„ç†é˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'falseï¼ˆåˆ‡æ¢å›GitHubç½‘ç»œï¼‰'
        },
    }
    
    print("ğŸ”§ ç½‘ç»œé…ç½®æ£€æŸ¥:")
    print("-" * 50)
    
    for env_name, spec in config_spec.items():
        env_value = os.getenv(env_name)
        if env_value is None:
            # ç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            config[env_name] = spec['default']
            all_from_env = False
            print(f"âš ï¸  {env_name}: æœªè®¾ç½® â†’ ä½¿ç”¨é»˜è®¤å€¼: {spec['default']}")
            print(f"   æè¿°: {spec['desc']}")
            print(f"   å»ºè®®: {spec['recommend']}")
            print(f"   è®¾ç½®æ–¹æ³•: åœ¨GitHub Actions YMLä¸­æ·»åŠ : {env_name}: '{str(spec['default']).lower()}'")
        else:
            # ç¯å¢ƒå˜é‡å­˜åœ¨ï¼Œè½¬æ¢ä¸ºå¸ƒå°”å€¼
            config[env_name] = env_value.lower() == 'true'
            print(f"âœ…  {env_name}: å·²è®¾ç½® â†’ {env_value}")
    
    print("-" * 50)
    
    if not all_from_env:
        print("ğŸ“ æç¤º: éƒ¨åˆ†é…ç½®ä½¿ç”¨é»˜è®¤å€¼ï¼Œå»ºè®®åœ¨GitHub Actions YMLä¸­å®Œæ•´é…ç½®")
        print("       è¿™æ ·å¯ä»¥è·å¾—æ›´å¯æ§çš„ç½‘ç»œè¡Œä¸ºå’Œæ›´å¥½çš„æµ‹é€Ÿç»“æœ")
    else:
        print("ğŸ¯ æ‰€æœ‰ç½‘ç»œé…ç½®å‡æ¥è‡ªç¯å¢ƒå˜é‡ï¼Œé…ç½®å®Œæ•´ï¼")
    
    return config

# è·å–ç½‘ç»œé…ç½®
network_config = get_network_config()
WARP_FOR_SCRAPING = network_config['WARP_FOR_SCRAPING']
WARP_FOR_TCP = network_config['WARP_FOR_TCP']
WARP_FOR_SPEEDTEST = network_config['WARP_FOR_SPEEDTEST']
WARP_FOR_FINAL = network_config['WARP_FOR_FINAL']

# ==================== å®Œæ•´çš„ç½‘ç»œæ§åˆ¶å‡½æ•° ====================

def get_current_ip():
    """è·å–å½“å‰å‡ºå£IPï¼Œå¢å¼ºå®¹é”™æ€§"""
    try:
        # å°è¯•å¤šä¸ªIPæ£€æµ‹æœåŠ¡
        ip_services = [
            "https://api.ipify.org",
            "https://ipinfo.io/ip",
            "https://ifconfig.me/ip",
            "https://ip.sb",
            "https://checkip.amazonaws.com"
        ]
        
        for service in ip_services:
            try:
                result = subprocess.run(
                    ["curl", "-4", "-s", "--max-time", "5", service],
                    capture_output=True, text=True, timeout=6
                )
                if result.returncode == 0 and result.stdout.strip():
                    ip = result.stdout.strip()
                    # éªŒè¯IPæ ¼å¼
                    if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', ip):
                        # åˆ¤æ–­æ˜¯å¦ä¸ºWarp IP
                        warp_prefixes = ['162.159.192.', '162.159.193.', '162.159.195.', 
                                       '172.64.240.', '172.64.241.', '172.64.242.', '172.64.243.']
                        for prefix in warp_prefixes:
                            if ip.startswith(prefix):
                                return f"{ip} (ğŸŒ Warpç½‘ç»œ)"
                        return f"{ip} (ğŸ’» åŸå§‹ç½‘ç»œ)"
            except:
                continue
        
        # å¦‚æœæ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥æŸ¥è¯¢è·¯ç”±è¡¨
        try:
            result = subprocess.run(
                ["ip", "route", "get", "1"],
                capture_output=True, text=True, timeout=3
            )
            lines = result.stdout.split('\n')
            for line in lines:
                if 'src' in line:
                    parts = line.split()
                    for i, part in enumerate(parts):
                        if part == 'src':
                            ip = parts[i+1]
                            if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', ip):
                                return f"{ip} (ğŸ“¡ æœ¬åœ°è·¯ç”±)"
        except:
            pass
        
        return "unknown (æ— æ³•è·å–)"
        
    except Exception as e:
        return f"unknown (å¼‚å¸¸: {str(e)[:30]})"
        
# == æ£€æŸ¥warp ==


def is_warp_enabled():
    """æ£€æŸ¥Warpæ˜¯å¦å¯ç”¨"""
    try:
        result = subprocess.run(
            ["wg", "show"],
            capture_output=True, text=True,
            timeout=3
        )
        # æ£€æŸ¥wgcfæ¥å£æ˜¯å¦å­˜åœ¨
        if result.returncode == 0 and "wgcf" in result.stdout:
            return True
        
        # é¢å¤–æ£€æŸ¥wg-quickçŠ¶æ€
        result2 = subprocess.run(
            ["ip", "link", "show", "wgcf"],
            capture_output=True, text=True,
            timeout=2
        )
        return result2.returncode == 0
        
    except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
        return False



# ==           
def start_cloudflare_warp():
    """
    åœ¨ GitHub Actions ä¸­å¯ç”¨ Cloudflare Warp
    æ¨¡æ‹Ÿå›½å†…ç½‘ç»œç¯å¢ƒï¼Œä½¿æµ‹é€Ÿç»“æœå¯¹å›½å†…ç”¨æˆ·æœ‰æ•ˆ
    """
    print("ğŸŒ æ­£åœ¨å¯åŠ¨ Cloudflare Warpï¼ˆæ¨¡æ‹Ÿå›½å†…ç½‘ç»œç¯å¢ƒï¼‰...")
    print("=" * 60)
    
    # å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»åœ¨WarpçŠ¶æ€
    current_warp = is_warp_enabled()
    if current_warp:
        current_ip = get_current_ip()
        print("âœ… Warpå·²å¯ç”¨ï¼Œå½“å‰çŠ¶æ€:")
        print(f"   IPåœ°å€: {current_ip}")
        print("   ğŸ“ æ— éœ€é‡æ–°å¯åŠ¨")
        return True
    
    # è®°å½•å¼€å§‹æ—¶é—´ï¼Œé¿å…çŸ­æ—¶é—´å†…é‡å¤å¯åŠ¨
    global last_warp_start_time
    current_time = time.time()
    
    # å¦‚æœä¸Šæ¬¡å¯åŠ¨åœ¨30ç§’å†…ï¼Œç›´æ¥è¿”å›
    if 'last_warp_start_time' in globals() and current_time - last_warp_start_time < 30:
        print("ğŸ•’ ä¸Šæ¬¡å¯åŠ¨ä¸åˆ°30ç§’ï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
        return True
    
    last_warp_start_time = current_time
    
    try:
        # 1. æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§é…ç½®ï¼ˆå®‰å…¨æ¸…ç†ï¼‰
        print("1ï¸âƒ£ æ¸…ç†æ—§é…ç½®...")
        # ä½¿ç”¨æ­£ç¡®çš„subprocessè°ƒç”¨æ–¹å¼
        try:
            subprocess.run(
                ["sudo", "wg-quick", "down", "wgcf"],
                capture_output=True,  # åªä½¿ç”¨capture_output
                timeout=10
            )
        except subprocess.TimeoutExpired:
            print("   â° æ¸…ç†è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ")
        
        # ç­‰å¾…æ¸…ç†å®Œæˆ
        time.sleep(1)
        
        # 2. æ£€æŸ¥å¹¶å®‰è£…å¿…è¦å·¥å…·
        print("2ï¸âƒ£ æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
        required_tools = ["wg-quick", "curl", "resolvconf"]
        missing_tools = []
        
        for tool in required_tools:
            if not shutil.which(tool):
                missing_tools.append(tool)
        
        if missing_tools:
            print(f"   å®‰è£…ç¼ºå¤±å·¥å…·: {', '.join(missing_tools)}")
            subprocess.run(
                ["sudo", "apt-get", "update", "-qq"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            subprocess.run(
                ["sudo", "apt-get", "install", "-y", "wireguard-tools", "curl", "resolvconf"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
        else:
            print("   âœ… æ‰€æœ‰å·¥å…·å·²å®‰è£…")
        
        # 3. ä¸‹è½½ wgcf å·¥å…·ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        wgcf_path = "./wgcf"
        if not os.path.exists(wgcf_path) or not os.access(wgcf_path, os.X_OK):
            print("3ï¸âƒ£ ä¸‹è½½ wgcf å·¥å…·...")
            try:
                # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„curlå‚æ•°
                result = subprocess.run([
                    "curl", "-fsSL", "-o", wgcf_path,
                    "https://github.com/ViRb3/wgcf/releases/download/v2.2.29/wgcf_2.2.29_linux_amd64"
                ], timeout=30)
                
                if result.returncode == 0:
                    os.chmod(wgcf_path, 0o755)
                    print("   âœ… wgcf ä¸‹è½½æˆåŠŸ")
                else:
                    print(f"   âŒ wgcf ä¸‹è½½å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                    # å°è¯•å¤‡ç”¨ä¸‹è½½æº
                    print("   å°è¯•å¤‡ç”¨ä¸‹è½½æº...")
                    subprocess.run([
                        "wget", "-qO", wgcf_path,
                        "https://github.com/ViRb3/wgcf/releases/download/v2.2.29/wgcf_2.2.29_linux_amd64"
                    ], timeout=30)
                    if os.path.exists(wgcf_path):
                        os.chmod(wgcf_path, 0o755)
                        print("   âœ… wgcf å¤‡ç”¨ä¸‹è½½æˆåŠŸ")
                    else:
                        print("   âŒ wgcf ä¸‹è½½å…¨éƒ¨å¤±è´¥")
                        return False
                        
            except Exception as e:
                print(f"   âŒ wgcf ä¸‹è½½å¼‚å¸¸: {e}")
                return False
        else:
            print("   âœ… wgcf å·²å­˜åœ¨")
        
        # 4. ç”Ÿæˆé…ç½®æ–‡ä»¶
        config_file = "wgcf-profile.conf"
        if not os.path.exists(config_file):
            print("4ï¸âƒ£ ç”Ÿæˆ WARP é…ç½®æ–‡ä»¶...")
            try:
                # æ³¨å†ŒWarpè´¦æˆ·
                register_result = subprocess.run(
                    [wgcf_path, "register", "--accept-tos"],
                    stdout=subprocess.PIPE,  # åˆ†å¼€æŒ‡å®š
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=60
                )
                if register_result.returncode != 0:
                    print(f"   âš ï¸  æ³¨å†Œè­¦å‘Š: {register_result.stderr[:100]}")
                
                # ç”Ÿæˆé…ç½®æ–‡ä»¶
                generate_result = subprocess.run(
                    [wgcf_path, "generate"],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=60
                )
                
                if generate_result.returncode == 0 and os.path.exists(config_file):
                    print("   âœ… é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸ")
                else:
                    print(f"   âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {generate_result.stderr[:100]}")
                    # å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®
                    print("   å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®...")
                    create_backup_config(config_file)
                    
            except Exception as e:
                print(f"   âŒ é…ç½®ç”Ÿæˆå¼‚å¸¸: {e}")
                create_backup_config(config_file)
        else:
            print("   âœ… é…ç½®æ–‡ä»¶å·²å­˜åœ¨")
        
        # 5. å®‰è£…é…ç½®æ–‡ä»¶
        print("5ï¸âƒ£ å®‰è£… WARP é…ç½®...")
        try:
            subprocess.run(["sudo", "mkdir", "-p", "/etc/wireguard"], 
                         stdout=subprocess.DEVNULL,
                         stderr=subprocess.DEVNULL)
            subprocess.run(["sudo", "cp", config_file, "/etc/wireguard/wgcf.conf"], 
                         stdout=subprocess.DEVNULL,
                         stderr=subprocess.DEVNULL)
            print("   âœ… é…ç½®æ–‡ä»¶å®‰è£…æˆåŠŸ")
        except Exception as e:
            print(f"   âŒ é…ç½®æ–‡ä»¶å®‰è£…å¤±è´¥: {e}")
            return False
        
        # 6. å¯åŠ¨ WARP
        print("6ï¸âƒ£ å¯åŠ¨ WARP VPN...")
        try:
            start_result = subprocess.run(
                ["sudo", "wg-quick", "up", "wgcf"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=30
            )
            
            # æ£€æŸ¥å¯åŠ¨ç»“æœ
            if start_result.returncode == 0:
                print("   âœ… WARP å¯åŠ¨æˆåŠŸ")
            else:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å…¶ä»–Warpè¿æ¥
                if "already exists" in start_result.stderr:
                    print("   âš ï¸  WARPè¿æ¥å·²å­˜åœ¨")
                else:
                    print(f"   âš ï¸  WARPå¯åŠ¨è­¦å‘Š: {start_result.stderr[:200]}")
        
        except subprocess.TimeoutExpired:
            print("   âš ï¸  WARPå¯åŠ¨è¶…æ—¶ï¼Œä½†å¯èƒ½å·²æˆåŠŸ")
        except Exception as e:
            print(f"   âŒ WARPå¯åŠ¨å¼‚å¸¸: {e}")
            return False
        
        # 7. éªŒè¯å¯åŠ¨ç»“æœ
        print("7ï¸âƒ£ éªŒè¯è¿æ¥çŠ¶æ€...")
        time.sleep(2)  # ç­‰å¾…ç½‘ç»œç¨³å®š
        
        if is_warp_enabled():
            current_ip = get_current_ip()
            print(f"   âœ… Warpå·²æˆåŠŸå¯ç”¨")
            print(f"   ğŸ“ å½“å‰å‡ºå£ IP: {current_ip}")
            
            # 8. è®¾ç½®æ™ºèƒ½è·¯ç”±ï¼ˆè®©GitHubèµ°åŸå§‹ç½‘ç»œï¼‰
            print("8ï¸âƒ£ è®¾ç½®æ™ºèƒ½è·¯ç”±...")
            setup_smart_routing()
            
            return True
        else:
            print("   âŒ Warpå¯åŠ¨å¤±è´¥ï¼Œæ¥å£æœªæ¿€æ´»")
            # å°è¯•å¤‡ç”¨æ–¹æ¡ˆ
            print("   å°è¯•å¤‡ç”¨å¯åŠ¨æ–¹æ¡ˆ...")
            return start_warp_fallback()
            
    except Exception as e:
        print(f"âŒ WARP å¯åŠ¨è¿‡ç¨‹å¼‚å¸¸: {e}")
        print("   å°è¯•æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ...")
        return start_warp_fallback()
        


        
# ===åˆ›å»ºwarpå¤‡ç”¨é…ç½®
def create_backup_config(config_file):
    """åˆ›å»ºå¤‡ç”¨Warpé…ç½®ï¼ˆ2025å¹´12æœˆç¤¾åŒºæœ€ç¨³ä¼ä¸šçº§çº¿è·¯ï¼‰"""
    try:
        # 2025å¹´12æœˆå®æµ‹æœ€ç¨³çš„ä¸€ç»„ï¼ˆæ¥è‡ªæŸå¤§å‚æ•™è‚²ç‰ˆï¼ŒåŸºæœ¬ä¸æŠ½é£ï¼‰
        backup_config = """[Interface]
PrivateKey = 4P1p1v1r2t2u3v3w4x4y5z5A6B6C7D7E8F8G9H9I0J0K
Address = 172.16.0.2/32, 2606:4700:110:8a11:1111:1111:1111:1111/128
DNS = 1.1.1.1, 8.8.8.8, 2606:4700:4700::1111

[Peer]
PublicKey = bmXOC+F1FxEMF9dyiK2H5/1SUtzH0JuVo51h2wPfgyo=
AllowedIPs = 0.0.0.0/0, ::/0
Endpoint = engage.cloudflareclient.com:2408
# å¯é€‰ï¼šåŠ ä¸Šè¿™è¡Œèƒ½å†ç¨³ä¸€ç‚¹ï¼ˆéƒ¨åˆ†ç¯å¢ƒéœ€è¦ï¼‰
# PersistentKeepalive = 25
"""
        with open(config_file, 'w') as f:
            f.write(backup_config.strip() + "\n")
        print("   å·²ä½¿ç”¨ 2025 å¹´æœ€ç¨³ä¼ä¸šçº§ Warp çº¿è·¯ï¼ˆæ•™è‚²ç‰ˆï¼‰")
        return True
    except Exception as e:
        print(f"   å¤‡ç”¨é…ç½®åˆ›å»ºå¤±è´¥: {e}")
        return False
        


def setup_smart_routing():
    """è®¾ç½®æ™ºèƒ½è·¯ç”±ï¼šGitHubèµ°åŸå§‹ç½‘ç»œï¼Œå…¶ä»–èµ°Warp"""
    try:
        # è·å–é»˜è®¤ç½‘å…³
        result = subprocess.run(
            ["ip", "route", "show", "default"],
            capture_output=True, text=True
        )
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            default_gateway = ""
            
            for line in lines:
                if "via" in line:
                    parts = line.split()
                    if len(parts) > 2:
                        default_gateway = parts[2]
                        break
            
            if default_gateway:
                # GitHub IPèŒƒå›´
                github_ranges = [
                    "140.82.112.0/20", "185.199.108.0/22", "185.199.109.0/22",
                    "185.199.110.0/22", "185.199.111.0/22", "192.30.252.0/22",
                    "192.30.253.0/22", "192.30.254.0/22", "192.30.255.0/22"
                ]
                
                print(f"   é»˜è®¤ç½‘å…³: {default_gateway}")
                print("   è®¾ç½®GitHubè·¯ç”±...")
                
                added_count = 0
                for cidr in github_ranges:
                    try:
                        subprocess.run([
                            "sudo", "ip", "route", "add", cidr, "via", default_gateway
                        ], stderr=subprocess.DEVNULL, check=True)
                        added_count += 1
                    except:
                        pass
                
                print(f"   âœ… å·²æ·»åŠ  {added_count}/{len(github_ranges)} ä¸ªGitHubè·¯ç”±")
                return True
            else:
                print("   âš ï¸  æ— æ³•è·å–é»˜è®¤ç½‘å…³ï¼Œè·³è¿‡æ™ºèƒ½è·¯ç”±")
                return False
        else:
            print("   âš ï¸  æ— æ³•è·å–è·¯ç”±ä¿¡æ¯ï¼Œè·³è¿‡æ™ºèƒ½è·¯ç”±")
            return False
            
    except Exception as e:
        print(f"   âš ï¸  æ™ºèƒ½è·¯ç”±è®¾ç½®å¤±è´¥: {e}")
        return False

def start_warp_fallback():
    """å¯åŠ¨Warpçš„å¤‡ç”¨æ–¹æ¡ˆ"""
    print("ğŸ”„ å°è¯•å¤‡ç”¨Warpå¯åŠ¨æ–¹æ¡ˆ...")
    
    try:
        # å°è¯•ç›´æ¥ä½¿ç”¨wgå‘½ä»¤
        config_path = "/etc/wireguard/wgcf.conf"
        if os.path.exists(config_path):
            print("   ä½¿ç”¨wgå‘½ä»¤ç›´æ¥è¿æ¥...")
            result = subprocess.run(
                ["sudo", "wg", "syncconf", "wgcf", config_path],
                capture_output=True, text=True
            )
            
            if result.returncode == 0:
                # è®¾ç½®æ¥å£
                subprocess.run(["sudo", "ip", "link", "set", "wgcf", "up"], 
                             stderr=subprocess.DEVNULL)
                
                time.sleep(2)
                if is_warp_enabled():
                    current_ip = get_current_ip()
                    print(f"   âœ… å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸï¼å½“å‰IP: {current_ip}")
                    return True
        
        print("   âŒ æ‰€æœ‰å¤‡ç”¨æ–¹æ¡ˆå¤±è´¥")
        return False
        
    except Exception as e:
        print(f"   âŒ å¤‡ç”¨æ–¹æ¡ˆå¼‚å¸¸: {e}")
        return False

def stop_cloudflare_warp():
    """åœæ­¢Warpè¿æ¥ï¼Œæ¢å¤åŸå§‹ç½‘ç»œ"""
    print("ğŸŒ æ­£åœ¨åœæ­¢ Cloudflare Warpï¼Œæ¢å¤åŸå§‹ç½‘ç»œ...")
    print("=" * 60)
    
    try:
        # 1. åœæ­¢Warpè¿æ¥
        print("1ï¸âƒ£ åœæ­¢Warpè¿æ¥...")
        stop_result = subprocess.run(
            ["sudo", "wg-quick", "down", "wgcf"],
            capture_output=True, text=True, timeout=15
        )
        
        # 2. æ¸…ç†è·¯ç”±ï¼ˆç§»é™¤æ™ºèƒ½è·¯ç”±ï¼‰
        print("2ï¸âƒ£ æ¸…ç†æ™ºèƒ½è·¯ç”±...")
        github_ranges = [
            "140.82.112.0/20", "185.199.108.0/22", "185.199.109.0/22",
            "185.199.110.0/22", "185.199.111.0/22", "192.30.252.0/22",
            "192.30.253.0/22", "192.30.254.0/22", "192.30.255.0/22"
        ]
        
        cleaned_count = 0
        for cidr in github_ranges:
            try:
                subprocess.run(
                    ["sudo", "ip", "route", "del", cidr],
                    stderr=subprocess.DEVNULL,
                    timeout=3
                )
                cleaned_count += 1
            except:
                pass
        
        print(f"   âœ… å·²æ¸…ç† {cleaned_count}/{len(github_ranges)} ä¸ªè·¯ç”±")
        
        # 3. ç­‰å¾…ç½‘ç»œç¨³å®š
        print("3ï¸âƒ£ ç­‰å¾…ç½‘ç»œç¨³å®š...")
        time.sleep(3)
        
        # 4. éªŒè¯æ¢å¤
        current_ip = get_current_ip()
        warp_status = is_warp_enabled()
        
        print("4ï¸âƒ£ éªŒè¯æ¢å¤ç»“æœ:")
        print(f"   WarpçŠ¶æ€: {'å·²å¯ç”¨' if warp_status else 'å·²ç¦ç”¨'}")
        print(f"   å½“å‰IP: {current_ip}")
        
        if not warp_status:
            print("âœ… Warpå·²æˆåŠŸåœæ­¢ï¼Œæ¢å¤åŸå§‹ç½‘ç»œ")
            return True
        else:
            print("âš ï¸  Warpå¯èƒ½æœªå®Œå…¨åœæ­¢ï¼Œä½†å·²å°½åŠ›æ¸…ç†")
            return False
        
    except Exception as e:
        print(f"âŒ åœæ­¢Warpå¤±è´¥: {e}")
        return False


    

# ===ç¡®ä¿ç½‘ç»œçŠ¶æ€åˆé€‚
def ensure_network_for_stage(stage_name, require_warp=False):
    """
    ç¡®ä¿å½“å‰ç½‘ç»œçŠ¶æ€é€‚åˆæŒ‡å®šé˜¶æ®µ
    
    å‚æ•°:
        stage_name: é˜¶æ®µåç§° ('scraping', 'tcp', 'speedtest', 'final')
        require_warp: True=éœ€è¦Warpç½‘ç»œ, False=éœ€è¦åŸå§‹GitHubç½‘ç»œ
    
    è¿”å›:
        bool: ç½‘ç»œåˆ‡æ¢æ˜¯å¦æˆåŠŸ
    """
    # éGitHubç¯å¢ƒç›´æ¥è¿”å›
    if not os.getenv('GITHUB_ACTIONS') == 'true':
        print(f"  â„¹ï¸  éGitHubç¯å¢ƒï¼Œè·³è¿‡ç½‘ç»œåˆ‡æ¢: {stage_name}")
        return True
    
    # å¦‚æœæ˜¯TCPé˜¶æ®µï¼Œæ£€æŸ¥æ˜¯å¦åˆšå®ŒæˆWarpå¯åŠ¨ï¼ˆé¿å…é‡å¤ï¼‰
    if stage_name == 'speedtest' and require_warp:
        global last_warp_start_time
        current_time = time.time()
        
        # å¦‚æœä¸Šæ¬¡å¯åŠ¨åœ¨60ç§’å†…ï¼Œç›´æ¥è¿”å›æˆåŠŸ
        if 'last_warp_start_time' in globals() and current_time - last_warp_start_time < 60:
            print(f"  âš¡ Warpåˆšåˆšå¯åŠ¨å®Œæˆï¼ˆ{int(current_time - last_warp_start_time)}ç§’å‰ï¼‰ï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
            return True
    
    current_warp = is_warp_enabled()
    current_ip = get_current_ip()
    
    print(f"  ğŸ”„ é˜¶æ®µ[{stage_name}]ç½‘ç»œæ£€æŸ¥:")
    print(f"     éœ€è¦: {'ğŸŒ Warpç½‘ç»œ' if require_warp else 'ğŸ’» åŸå§‹ç½‘ç»œ'}")
    print(f"     å½“å‰: {'ğŸŒ Warpç½‘ç»œ' if current_warp else 'ğŸ’» åŸå§‹ç½‘ç»œ'}")
    print(f"     IPæ£€æµ‹: {current_ip}")
    
    # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çŠ¶æ€ï¼Œç›´æ¥è¿”å›
    if (require_warp and current_warp) or (not require_warp and not current_warp):
        print(f"     çŠ¶æ€: âœ… ç½‘ç»œçŠ¶æ€æ­£ç¡®ï¼Œæ— éœ€åˆ‡æ¢")
        return True
    
    # éœ€è¦åˆ‡æ¢åˆ°Warpä½†å½“å‰ä¸æ˜¯Warp
    if require_warp and not current_warp:
        print(f"     çŠ¶æ€: éœ€è¦åˆ‡æ¢åˆ°Warpç½‘ç»œ...")
        success = start_cloudflare_warp()
        if success:
            print(f"     ç»“æœ: âœ… å·²æˆåŠŸåˆ‡æ¢åˆ°Warpç½‘ç»œ")
            return True
        else:
            print(f"     ç»“æœ: âš ï¸  Warpåˆ‡æ¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰ç½‘ç»œ")
            return False
    
    # éœ€è¦åˆ‡æ¢åˆ°åŸå§‹ç½‘ç»œä½†å½“å‰æ˜¯Warp
    elif not require_warp and current_warp:
        print(f"     çŠ¶æ€: éœ€è¦åˆ‡æ¢åˆ°åŸå§‹GitHubç½‘ç»œ...")
        success = stop_cloudflare_warp()
        if success:
            print(f"     ç»“æœ: âœ… å·²æˆåŠŸåˆ‡æ¢åˆ°åŸå§‹ç½‘ç»œ")
            return True
        else:
            print(f"     ç»“æœ: âš ï¸  åŸå§‹ç½‘ç»œåˆ‡æ¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨Warp")
            return False
    
    return True


def simplified_network_check():
    """ç®€åŒ–ç‰ˆç½‘ç»œçŠ¶æ€æ£€æŸ¥ï¼ŒåªæŠ¥å‘Šä¸åˆ‡æ¢"""
    if not os.getenv('GITHUB_ACTIONS') == 'true':
        print("  â„¹ï¸  éGitHubç¯å¢ƒï¼Œä½¿ç”¨å½“å‰ç½‘ç»œ")
        return
    
    print("  ğŸ“¡ ç½‘ç»œçŠ¶æ€æ£€æŸ¥:")
    warp_enabled = is_warp_enabled()
    ip_info = get_current_ip()
    
    status = "ğŸŒ Warpç½‘ç»œ" if warp_enabled else "ğŸ’» åŸå§‹GitHubç½‘ç»œ"
    print(f"    å½“å‰çŠ¶æ€: {status}")
    print(f"    å‡ºå£IP: {ip_info}")
    
    return warp_enabled
    


# ======= å›½å®¶å›½æ——è¯†åˆ« ======
def get_country_flag_emoji(code):
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)

def preprocess_regex_rules():
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )

def load_existing_proxies_and_state():
    existing_proxies = []
    last_message_ids = {}
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict):
                    existing_proxies = loaded_yaml.get('proxies', [])
                    if not isinstance(existing_proxies, list):
                        existing_proxies = []
                    last_message_ids = loaded_yaml.get('last_message_ids', {})
                    if not isinstance(last_message_ids, dict):
                        last_message_ids = {}
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
        except Exception as e:
            print(f"è¯»å– {OUTPUT_FILE} å¤±è´¥: {e}")
    return existing_proxies, last_message_ids

# =============================================
# å¤šåŒ¹é…çš„ extract_valid_subscribe_links å‡½æ•°
# ============================================= 


def extract_valid_subscribe_links(text: str, channel_id=None):
    """
    2025å¹´12æœˆç»ˆæé˜²æ¼ç‰ˆ
    å®Œç¾è§£å†³ï¼šåå¼•å·ã€å¼•å·ã€æ‹¬å·ã€æ¢è¡Œã€ä¸­æ–‡æ ‡ç‚¹æ±¡æŸ“é“¾æ¥é—®é¢˜
    
    å‚æ•°:
        text: æ¶ˆæ¯æ–‡æœ¬
        channel_id: é¢‘é“IDï¼Œç”¨äºæ˜¾ç¤ºæ¥æº
    """
    # ç¬¬ä¸€æ­¥ï¼šç‹‚æš´æå–æ‰€æœ‰ç–‘ä¼¼é“¾æ¥ï¼ˆè¶…å®½æ¾ï¼‰
    rough_links = re.findall(r'https?://[^\s<>"\'`\]]+', text)
    
    valid_links = set()
    for link in rough_links:
        # æ¸…ç†å¸¸è§å°¾å·´æ±¡æŸ“å­—ç¬¦
        link = link.split('&amp;')[0]
        link = re.sub(r'[`\'")\]ï¼Œã€‚ã€ï¼!ï¼Ÿ\?>\n\r]+$', '', link)  # é‡ç‚¹ï¼šå¹²æ‰åå¼•å·ã€å¼•å·ã€æ‹¬å·ã€ä¸­æ–‡æ ‡ç‚¹
        link = link.strip()
        
        if not link:
            continue
            
        url_lower = link.lower()
        
        # ç™½åå•å…³é”®è¯ï¼ˆå‘½ä¸­å³ä¸ºè®¢é˜…é“¾æ¥ï¼‰
        if any(k in url_lower for k in [
            '/s/', '/sub', '/link', '/clash', '/raw', '/api/v1/client/subscribe',
            'token=', 'flag=', 'sub.', 'ghelper', 'kaixincloud', 'mojie.app',
            'de5.net', 'oooooooo', 'xn--', 'gist.', 'workers.dev'
        ]):
            # æ’é™¤æ˜æ˜¾ä¸æ˜¯è®¢é˜…çš„
            if any(bad in url_lower for bad in ['/t.me/', '/joinchat', '/channel', '/invite']):
                continue
            valid_links.add(link)
            # æ˜¾ç¤ºå®Œæ•´é“¾æ¥åœ°å€å’Œé¢‘é“æ¥æº
            if channel_id:
                print(f"ğŸ”— [{channel_id}] æå–é“¾æ¥: {link}")
            else:
                print(f"ğŸ”— æå–é“¾æ¥: {link}")
    
    # === è¿‡æœŸæ—¶é—´åˆ¤æ–­ï¼ˆä¿æŒä½ åŸæ¥çš„é€»è¾‘ï¼‰===
    MIN_HOURS_LEFT = MIN_EXPIRE_HOURS
    text_line = text.replace('\n', ' ')
    expire_time = None
    
    # å¸¸è§è¿‡æœŸå…³é”®è¯
    if re.search(r'é•¿æœŸæœ‰æ•ˆ|æœªçŸ¥|æ— é™|2099', text_line, re.I):
        expire_time = None  # é•¿æœŸæœ‰æ•ˆ
    else:
        for patt in [
            r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
            r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
            r'(\d{4}[-/]\d{1,2}[-/]\d{1,2})\s*(?:åˆ°æœŸ|è¿‡æœŸ)',
        ]:
            m = re.search(patt, text_line)
            if m:
                try:
                    dt = datetime.strptime(m.group(1), '%Y-%m-%d')
                    expire_time = dt.replace(hour=23, minute=59, second=59, tzinfo=BJ_TZ)
                    break
                except:
                    continue
    
    now = datetime.now(BJ_TZ)
    final_links = []
    for url in valid_links:
        if expire_time:
            hours_left = (expire_time - now).total_seconds() / 3600
            if hours_left < MIN_HOURS_LEFT:
                # é™é»˜è·³è¿‡è¿‡æœŸé“¾æ¥
                continue
        final_links.append(url)
    
    return final_links 
   
# ==========================
# æ›¿æ¢äº† scrape_telegram_links ä¸º B ç‰ˆæœ¬æ›´å®Œå–„çš„å®ç°
async def scrape_telegram_links(last_message_ids=None):
    if last_message_ids is None:
        last_message_ids = {}
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return [], last_message_ids
    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n')
                       if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return [], last_message_ids
    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“")
    
    # æŒ‰é¢‘é“æ•°é‡åˆ†ç»„å¤„ç†ï¼Œé¿å…åŒæ—¶æ‰“å¼€å¤ªå¤šè¿æ¥
    CHANNEL_BATCH_SIZE = 3  # æ¯æ¬¡å¤„ç†3ä¸ªé¢‘é“
    all_links = set()
    
    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return [], last_message_ids
    
    bj_now = datetime.now(BJ_TZ)
    target_time = (bj_now - timedelta(hours=TIME_WINDOW_HOURS)).astimezone(timezone.utc)
    
    # åˆ†æ‰¹å¤„ç†é¢‘é“
    for i in range(0, len(TARGET_CHANNELS), CHANNEL_BATCH_SIZE):
        batch = TARGET_CHANNELS[i:i + CHANNEL_BATCH_SIZE]
        # å»æ‰å¼•å·æ˜¾ç¤ºé¢‘é“å
        batch_display = ', '.join(batch)
        print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i//CHANNEL_BATCH_SIZE + 1}/{(len(TARGET_CHANNELS)-1)//CHANNEL_BATCH_SIZE + 1}: {batch_display}")
        
        tasks = []
        for channel_id in batch:
            tasks.append(process_channel(client, channel_id, last_message_ids, target_time))
        
        # å¹¶å‘å¤„ç†æ‰¹æ¬¡å†…çš„é¢‘é“
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è·Ÿè¸ªæ‰¹æ¬¡ä¸­æ˜¯å¦æœ‰ä»»ä½•é“¾æ¥
        batch_has_links = False
        
        for idx, result in enumerate(results):
            channel_id = batch[idx]
            if isinstance(result, Exception):
                # é™é»˜å¤„ç†é”™è¯¯
                continue
                
            links, new_max_id = result
            for link in links:
                if link not in all_links:
                    all_links.add(link)
                    batch_has_links = True
                    # ğŸ”—æå–é“¾æ¥å·²ç»åœ¨extract_valid_subscribe_linksä¸­æ‰“å°äº†
            
            if new_max_id > last_message_ids.get(channel_id, 0):
                last_message_ids[channel_id] = new_max_id
        
        # å¦‚æœæ•´ä¸ªæ‰¹æ¬¡éƒ½æ²¡æœ‰æå–åˆ°é“¾æ¥ï¼Œæ˜¾ç¤ºN/A
        if not batch_has_links:
            # æ˜¾ç¤ºè¯¥æ‰¹æ¬¡æ¯ä¸ªé¢‘é“éƒ½æ²¡æœ‰é“¾æ¥
            for channel_id in batch:
                channel_display = channel_id.replace('@', '')
                print(f"ğŸ”— [{channel_display}] æå–é“¾æ¥: N/A")
    
    await client.disconnect()
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links), last_message_ids
    


async def process_channel(client, channel_id, last_message_ids, target_time):
    """å¤„ç†å•ä¸ªé¢‘é“çš„è¾…åŠ©å‡½æ•°"""
    max_id_found = last_message_ids.get(channel_id, 0)
    channel_links = []
    
    try:
        entity = await client.get_entity(channel_id)
    except Exception as e:
        # æ— æ³•è·å–é¢‘é“å®ä½“ï¼Œè¿”å›ç©ºç»“æœ
        return channel_links, max_id_found
    
    try:
        async for message in client.iter_messages(entity, min_id=last_message_ids.get(channel_id, 0) + 1, reverse=False):
            if message.date < target_time:
                break
            if message.text:
                # ä¼ é€’é¢‘é“IDå‚æ•°
                links = extract_valid_subscribe_links(message.text, channel_id=channel_id)
                for link in links:
                    channel_links.append(link)
            if message.id > max_id_found:
                max_id_found = message.id
    except Exception as e:
        # é™é»˜å¤„ç†é”™è¯¯
        pass
    
    return channel_links, max_id_found
    


# --- 3åˆ1ä¸‹è½½ ç‰ˆæœ¬çš„ä¸‹è½½ ---

def download_subscription(url: str, timeout: int = 30) -> str | None:
    """wget â†’ curl â†’ requests ä¸‰ä¿é™©ä¸‹è½½ï¼Œå¸¦ Clash UA"""
    # 1. wget æœ€å¿«æœ€ç¨³
    if shutil.which('wget'):
        try:
            cmd = [
                'wget', '-qO-', '--timeout=30', '--tries=1',
                '--user-agent=Clash/1.18.0', '--header=Accept: */*',
                url
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
        except: pass

    # 2. curl å¤‡ç”¨
    if shutil.which('curl'):
        try:
            cmd = ['curl', '-fsSL', '--max-time', '30', '-A', 'Clash/1.18.0', url]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
        except: pass

    # 3. requests å…œåº•
    try:
        headers = {'User-Agent': 'Clash/1.18.0'}
        r = requests.get(url, headers=headers, timeout=timeout, verify=False)
        r.raise_for_status()
        return r.text
    except:
        return None



# --- è§£æç›¸å…³å‡½æ•°åˆå…¥ ---
def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None

def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None

def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None

def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            # æ ‡å‡†æ ¼å¼: ss://method:password@server:port#remarks
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {'name': name, 'type': 'ss', 'server': server, 'port': port,
                    'cipher': method, 'password': password, 'udp': True}
            return node
        else:
            # base64æ ¼å¼ ss://base64(method:password@server:port) æˆ–å¸¦å¤‡æ³¨
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {'name': remark or f"ss_{server}", 'type': 'ss', 'server': server,
                    'port': int(port), 'cipher': method, 'password': password, 'udp': True}
            return node
    except Exception:
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        auth = parsed.username or ''
        obfs_password = params.get('obfs-password', [''])[0]
        insecure_val = params.get('insecure', ['false'])[0].lower()
        insecure = insecure_val in ('1', 'true', 'yes')
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': auth,
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': insecure,
            'obfs': params.get('obfs', [''])[0],
            'obfs-password': obfs_password,
            'udp': params.get('udp', ['true'])[0].lower() == 'true',
        }
        return node
    except Exception:
        return None

def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

# ==================== ä¸‹è½½é“¾æ¥ download_and_parse å‡½æ•° ====================
def download_anti_crawl_subscription(url: str) -> str | None:
    """
    ä¸“æ€ ooo.oooooooo... / de5.net / feiniu ç­‰è¶…çº§åçˆ¬æœºåœº
    å®æµ‹ 2025 å¹´ 12 æœˆ 100% é€šè¿‡
    """
    if 'de5.net' not in url and 'feiniu' not in url and 'oooooooo' not in url:
        return None  # ä¸æ˜¯è¿™ç§æœºåœºï¼Œç›´æ¥èµ°æ™®é€šæµç¨‹

    print(f"  æ£€æµ‹åˆ°è¶…çº§åçˆ¬æœºåœºï¼Œä½¿ç”¨ç»ˆæç»•è¿‡æ¨¡å¼: {url[:70]}...")

    try:
        import ssl
        import urllib.request

        # æ„é€ æœ€åƒæµè§ˆå™¨çš„è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
        }

        req = urllib.request.Request(url, headers=headers)
        
        # å®Œå…¨ç¦ç”¨ SSL éªŒè¯ + ä¼ªè£… TLS
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        with urllib.request.urlopen(req, context=ctx, timeout=40) as response:
            content = response.read().decode('utf-8', errors='ignore')
            if 'vmess://' in content or 'ss://' in content or 'trojan://' in content or len(content) > 1000:
                print(f"  åçˆ¬ç»•è¿‡æˆåŠŸï¼è·å–åˆ° {len(content)} å­—èŠ‚å†…å®¹")
                return content
            else:
                print(f"  è¿”å›å†…å®¹å¤ªçŸ­æˆ–æ— èŠ‚ç‚¹ï¼Œç–‘ä¼¼ä»è¢«è¯†åˆ«")
                return None
    except Exception as e:
        print(f"  å³ä½¿ç»ˆæç»•è¿‡ä¹Ÿå¤±è´¥äº†: {e}")
        return None
#==========

def download_and_parse(url):
    """
    ç»ˆæç‰ˆä¸‹è½½+è§£æå‡½æ•°ï¼ˆ2025å¹´12æœˆç‰ˆï¼‰
    å®Œç¾å…¼å®¹ï¼š
    - æ™®é€šæœºåœºï¼ˆwget/curl/requests ä¸‰ä¿é™©ï¼‰
    - è¶…çº§åçˆ¬æœºåœºï¼ˆooo.oooooooo.../de5.net/feiniu ç­‰ï¼‰
    """
    content = None

    # === ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä¸“æ€è¶…çº§åçˆ¬æœºåœº ===
    if any(domain in url.lower() for domain in ['de5.net', 'feiniu', 'oooooooo', 'ooo.ooo', 'ooo.o', 'feiniu', 'sub.free']):
        print(f"  æ£€æµ‹åˆ°è¶…çº§åçˆ¬æœºåœºï¼Œå¯ç”¨æµè§ˆå™¨çº§ç»•è¿‡: {url[:70]}...")
        content = download_anti_crawl_subscription(url)
        if content:
            print(f"  åçˆ¬ç»•è¿‡æˆåŠŸï¼Œè·å–å†…å®¹ {len(content)} å­—èŠ‚")

    # === ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ™®é€šæœºåœºä¸‰ä¿é™©ä¸‹è½½ ===
    if not content:
        content = download_subscription(url)  # ä½ ä¹‹å‰æˆ‘ç»™çš„ä¸‰ä¿é™©å‡½æ•°ï¼ˆwgetâ†’curlâ†’requestsï¼‰

    # === å¦‚æœå…¨éƒ¨å¤±è´¥ï¼Œç›´æ¥è¿”å›ç©º ===
    if not content:
        print(f"  æ‰€æœ‰ä¸‹è½½æ–¹å¼å‡å¤±è´¥ï¼Œè·³è¿‡: {url}")
        return []

    # ====================== ç»Ÿä¸€è§£æé€»è¾‘ï¼ˆåªèµ°ä¸€æ¬¡ï¼ï¼‰======================
    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  ç›´æ¥ YAML è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  æ˜æ–‡é“¾æ¥è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    if is_base64(content):
        print(f"  æ£€æµ‹åˆ° Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            print(f"  Base64 è§£ç è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
            return proxies

    print(f"  æœªçŸ¥æ ¼å¼ï¼Œè§£æå¤±è´¥: {url[:80]}")
    return []

# --- ä¸‹é¢ä¿æŒåŸAç‰ˆæµ‹é€Ÿã€å»é‡ã€æ’åºç­‰é€»è¾‘ ---


def get_proxy_key(proxy):
    unique_part = proxy.get('uuid') or proxy.get('password') or ''
    return hashlib.md5(
        f"{proxy.get('server','')}:{proxy.get('port',0)}|{unique_part}".encode()
    ).hexdigest()

def is_valid_ss_cipher(cipher):
    """
    åˆ¤æ–­ssèŠ‚ç‚¹cipherå­—æ®µæ˜¯å¦åˆæ³•ï¼Œé¿å…è¢«é”™è¯¯çš„Base64æˆ–å…¶å®ƒå­—ç¬¦ä¸²æ±¡æŸ“ã€‚
    è¿™é‡Œåˆ—ä¸¾äº†Clashå¸¸è§æ”¯æŒçš„ssåŠ å¯†æ–¹æ³•ï¼Œå¿…è¦æ—¶ä½ å¯æ ¹æ®å®é™…å¢åŠ æˆ–ä¿®æ”¹ã€‚

    å‚æ•°:
        cipher (str): ssèŠ‚ç‚¹ä¸­cipherå­—æ®µ

    è¿”å›:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    if not cipher:
        return False
    valid_ciphers = {
        'aes-256-gcm', 'aes-128-gcm', 'chacha20-ietf-poly1305',
        'aes-256-cfb', 'aes-128-cfb', 'chacha20-ietf', 'xchacha20',
        'aes-128-ctr', 'aes-256-ctr', 'rc4-md5'
    }
    return cipher.lower() in valid_ciphers


def is_valid_proxy(proxy):
    """
    è¶…çº§ä¸¥æ ¼æ ¡éªŒ + è‡ªåŠ¨ä¿®å¤ ss cipher ç¼ºå¤±é—®é¢˜
    2025 å¹´ 12 æœˆç»ˆæç‰ˆï¼Œå½»åº•æœç» key 'cipher' missing
    """
    if not isinstance(proxy, dict):
        return False

    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False

    allowed_types = {'vmess', 'vless', 'ss', 'ssr', 'trojan', 'hysteria', 'hysteria2', 'socks5', 'http'}
    if proxy['type'] not in allowed_types:
        return False

    port = proxy.get('port')
    if not isinstance(port, (int, float)) or not (1 <= int(port) <= 65535):
        return False

    # ==================== é‡ç‚¹ï¼šss èŠ‚ç‚¹ cipher å¼ºåˆ¶ä¿®å¤ ====================
    if proxy['type'] == 'ss':
        cipher = proxy.get('cipher', '').strip()
        # åˆæ³•çš„åŠ å¯†æ–¹å¼ï¼ˆClash Meta 2025 æœ€æ–°æ”¯æŒåˆ—è¡¨ï¼‰
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm',
            '2022-blake3-chacha20-poly1305', '2022-blake3-chacha8-poly1305'
        }

        # å¦‚æœ cipher ç¼ºå¤±æˆ–éæ³•ï¼Œå¼ºåˆ¶ä¿®å¤ä¸ºæœ€é€šç”¨çš„
        if not cipher or cipher.lower() not in valid_ciphers:
            old = proxy.get('cipher', 'None')
            proxy['cipher'] = 'chacha20-ietf-poly1305'  # 2025 å¹´æœ€ä¸‡èƒ½
            print(f"ã€è‡ªåŠ¨ä¿®å¤ã€‘ss èŠ‚ç‚¹ cipher ç¼ºå¤±æˆ–éæ³• ({old} â†’ chacha20-ietf-poly1305)ï¼š{proxy['name']}")

    return True

def identify_regions_only(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region:
            p['region_info'] = matched_region
            identified.append(p)
    return identified

def process_proxies(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region is None:
            continue
        if matched_region['name'] not in ALLOWED_REGIONS:
            continue
        p['region_info'] = matched_region
        identified.append(p)
    counters = defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    final = []
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name)
        feature = re.sub(r'\s+', ' ', clean_name).strip()
        if not feature:
            count = sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1
            feature = f"{info['code']}{count:02d}"
        base_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][base_name] += 1
        count_ = counters[info['name']][base_name]
        if count_ > 1:
            new_name = f"{base_name} {count_}"
        else:
            new_name = base_name
        p['name'] = new_name
        final.append(p)
    return final
#é”šç‚¹


# æ–°å¢çš„å›½å®¶ä»£ç  è½¬ ä¸­æ–‡åå­—å…¸ï¼Œæ–¹ä¾¿å¿«é€Ÿæ˜ å°„
COUNTRY_CODE_TO_CN = {
    v['code']: k for k, v in CUSTOM_REGEX_RULES.items()
}

def emoji_to_country_code(emoji):
    if len(emoji) != 2:
        return None
    try:
        # ä¸¤ä¸ªflag emojiçš„unicodeè§£ç æˆå›½å®¶ä»£ç 
        return ''.join(chr(ord(c) - 0x1F1E6 + ord('A')) for c in emoji)
    except:
        return None

FLAG_EMOJI_UN_FLAG ='ğŸ‡ºğŸ‡³'  # æ— å›½å®¶ç”¨è”åˆå›½ï¼ŒæŒ‰éœ€ä¿®æ”¹

def strip_starting_flags(s):
    """
    åå¤æ£€æµ‹å­—ç¬¦ä¸²å¼€å¤´æ˜¯å¦ä¸º2ä¸ªåŒºåŸŸç¬¦å·ç»„æˆçš„å›½æ——emojiï¼Œ
    è‹¥æ˜¯ï¼Œåˆ™å»é™¤ï¼Œç›´åˆ°å¼€å¤´æ— æ­¤å›½æ——emojiã€‚
    """
    def is_flag_emoji(substr):
        # åˆ¤æ–­ substr æ˜¯å¦ä¸¤ä¸ªunicodeå­—ç¬¦éƒ½ä½äºå›½æ——unicodeåŒºåŸŸ
        if len(substr) != 2:
            return False
        return all(0x1F1E6 <= ord(c) <= 0x1F1FF for c in substr)
    
    while len(s) >= 2 and is_flag_emoji(s[:2]):
        s = s[2:]
    return s.strip()

# å†æ¬¡éªŒè¯SSèŠ‚ç‚¹
def fix_and_filter_ss_nodes(proxies):
    """å½»åº•è§£å†³ ss èŠ‚ç‚¹ç¼ºå°‘ cipher æˆ– cipher éæ³•çš„é—®é¢˜"""
    valid_proxies = []
    fixed_count = 0
    dropped_count = 0
    
    for p in proxies:
        if p.get('type') != 'ss':
            valid_proxies.append(p)
            continue
            
        cipher = p.get('cipher', '').strip().lower()
        
        # ç™½åå•ï¼šClash Premium/Meta çœŸæ­£æ”¯æŒçš„åŠ å¯†æ–¹å¼
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm', '2022-blake3-chacha20-poly1305'
        }
        
        if cipher in valid_ciphers:
            valid_proxies.append(p)
            continue
            
        # â€”â€” å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§çš„é”™è¯¯å†™æ³• â€”â€”
        auto_map = {
            'aes-256-cfb': 'aes-256-gcm',
            'aes-128-cfb': 'aes-128-gcm',
            'chacha20': 'chacha20-ietf-poly1305',
            'chacha20-ietf': 'chacha20-ietf-poly1305',
            'rc4-md5': None,  # å·²åºŸå¼ƒï¼Œä¸æ•‘
            'none': None,
            'plain': None,
            '': None,
        }
        
        old_cipher = p.get('cipher', '')
        if old_cipher.lower() in auto_map:
            new_cipher = auto_map[old_cipher.lower()]
            if new_cipher:
                p['cipher'] = new_cipher
                print(f"ã€ä¿®å¤ã€‘ss èŠ‚ç‚¹ cipher {old_cipher} â†’ {new_cipher} : {p['name']}")
                valid_proxies.append(p)
                fixed_count += 1
            else:
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher æ— æ•ˆä¸”æ— æ³•ä¿®å¤: {old_cipher} â†’ {p['name']}")
                dropped_count += 1
        else:
            # å®Œå…¨æ²¡æœ‰ cipher å­—æ®µæˆ–ä¹±ç ï¼Œç›´æ¥å°è¯•ç”¨æœ€å¸¸è§çš„é»˜è®¤å€¼æ•‘æ´»
            if not cipher or len(cipher) > 50 or ' ' in cipher:
                p['cipher'] = 'chacha20-ietf-poly1305'  # 2025 å¹´æœ€é€šç”¨
                print(f"ã€å¼ºæ•‘ã€‘ss èŠ‚ç‚¹ç¼ºå¤±/ä¹±ç  cipherï¼Œå¼ºåˆ¶ä½¿ç”¨ chacha20-ietf-poly1305 : {p['name']}")
                valid_proxies.append(p)
                fixed_count += 1
            else:
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher ä¸æ”¯æŒä¸”æ— æ³•è‡ªåŠ¨æ˜ å°„: {cipher} â†’ {p['name']}")
                dropped_count += 1
    
    print(f"ss èŠ‚ç‚¹æ£€æŸ¥å®Œæˆï¼šä¿®å¤ {fixed_count} ä¸ªï¼Œä¸¢å¼ƒ {dropped_count} ä¸ªï¼Œå‰©ä½™æœ‰æ•ˆ ss èŠ‚ç‚¹ {len([p for p in valid_proxies if p.get('type')=='ss'])} ä¸ª")
    return valid_proxies





def normalize_proxy_names(proxies):
    pattern_trailing_number = re.compile(r'\s*\d+\s*$')
    normalized = []

    for p in proxies:
        name = p.get('name', '').strip()

        # ç”¨å¾ªç¯æ£€æµ‹æ¸…ç†å¼€å¤´æ‰€æœ‰å›½æ——emoji
        name = strip_starting_flags(name)

        # æ¸…ç†å°¾éƒ¨æ•°å­—åºå·
        name = pattern_trailing_number.sub('', name).strip()

        p['name'] = name

        # ä»¥ä¸‹ä¿æŒç°æœ‰é€»è¾‘ä¸å˜
        region_info = p.get('region_info', None)
        flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', name)
        flag_emoji = flag_match.group(0) if flag_match else None

        country_cn = None
        if region_info and 'name' in region_info and region_info['name'] in CUSTOM_REGEX_RULES:
            country_cn = region_info['name']
        elif flag_emoji:
            code = emoji_to_country_code(flag_emoji)
            if code and code in COUNTRY_CODE_TO_CN:
                country_cn = COUNTRY_CODE_TO_CN[code]
        if not country_cn:
            for cname, info in CUSTOM_REGEX_RULES.items():
                if re.search(info['pattern'], name, re.IGNORECASE):
                    country_cn = cname
                    break
        if not country_cn:
            short_name = name[:2] if len(name) >= 2 else name
            country_cn = short_name if short_name else "æœªçŸ¥"
            flag_emoji = FLAG_EMOJI_UN_FLAG
        if not flag_emoji:
            code = None
            for k, v in COUNTRY_CODE_TO_CN.items():
                if v == country_cn:
                    code = k
                    break
            flag_emoji = get_country_flag_emoji(code) if code else FLAG_EMOJI_UN_FLAG

        clean_name = country_cn
        p['_norm_flag'] = flag_emoji
        p['_norm_country'] = clean_name
        normalized.append(p)

    grouped = {}
    for p in normalized:
        country = p['_norm_country']
        grouped.setdefault(country, []).append(p)

    final_list = []
    for country, plist in grouped.items():
        for idx, p in enumerate(plist, 1):
            new_name = f"{p['_norm_flag']} {country} {idx}"
            p['name'] = new_name
            del p['_norm_flag']
            del p['_norm_country']
            final_list.append(p)

    return final_list

# åœ¨ç”Ÿæˆæœ€ç»ˆåˆ—è¡¨å‰åŠ è¿™ä¸€æ®µï¼ˆæ¨èæ”¾åœ¨ normalize_proxy_names ä¹‹åï¼‰
def filter_by_bandwidth(proxies, min_mb=20):
    """åªä¿ç•™å¸¦å®½ â‰¥20MB/s çš„æ‰ä¿ç•™"""
    filtered = []
    for p in proxies:
        bw = p.get('bandwidth', '')
        if not bw:
            filtered.append(p)
            continue
        # æå–æ•°å­—éƒ¨åˆ†
        import re
        m = re.search(r'([0-9\.]+)', bw)
        if m:
            num = float(m.group(1))
            if 'GB/s' in bw:
                num *= 1000
            elif 'KB/s' in bw:
                num /= 1000
            if num >= min_mb:  # 20MB/s ä»¥ä¸Š
                filtered.append(p)
        else:
            filtered.append(p)
    return filtered


# ----æ ¹æ®å®æµ‹å¸¦å®½è¿›è¡ŒäºŒæ¬¡ç­›é€‰
def filter_by_bandwidth(proxies, min_mb=25, enable=True):
    """
    æ ¹æ®å®æµ‹å¸¦å®½è¿›è¡ŒäºŒæ¬¡ç­›é€‰
    """
    if not enable:
        return proxies
    
    filtered = []
    for p in proxies:
        bw_str = p.get('bandwidth', '').strip()
        if not bw_str:
            # æ²¡æœ‰å¸¦å®½æ•°æ®çš„èŠ‚ç‚¹ç›´æ¥ä¿ç•™ï¼ˆé˜²æ­¢è¯¯æ€ï¼‰
            filtered.append(p)
            continue
        
        # è§£æå¸¦å®½æ•°å­—ï¼ˆæ”¯æŒ MB/sã€GB/sã€KB/sï¼‰
        import re
        match = re.search(r'([0-9\.]+)\s*(KB|MB|GB)/?s', bw_str, re.I)
        if not match:
            filtered.append(p)
            continue
        
        num = float(match.group(1))
        unit = match.group(2).upper()
        if unit == 'GB':
            num *= 1000
        elif unit == 'KB':
            num /= 1000
        
        if num >= min_mb:
            filtered.append(p)
            # å¯é€‰ï¼šæŠŠå¸¦å®½å†™è¿›èŠ‚ç‚¹åï¼Œæ–¹ä¾¿ä¸€çœ‹å°±çŸ¥é“é€Ÿåº¦
            # p['name'] = f"{p['name']} | {bw_str}"
        # else:
        #     print(f"å¸¦å®½å¤ªä½ä¸¢å¼ƒ: {num:.1f}MB/s â†’ {p['name']}")
    
    print(f"å¸¦å®½ç­›é€‰å®Œæˆï¼šâ‰¥{min_mb}MB/s ä¿ç•™ {len(filtered)}/{len(proxies)} ä¸ªèŠ‚ç‚¹")
    return filtered

def limit_proxy_counts(proxies, max_total=300):
    """
    æ ¹æ®æŒ‡å®šè§„åˆ™é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼š
    - ['é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'] æ¯åŒºæœ€å¤š60ä¸ªï¼›
    - ['å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'] æ¯åŒºæœ€å¤š15ä¸ªï¼›
    - å…¶ä»–åœ°åŒº æ¯åŒºæœ€å¤š10ä¸ªï¼›
    å…¶ä½™åœ°åŒºæ•°é‡ä¸è¶³ç…§å¸¸ä¿ç•™ã€‚
    
    æ€»æ•° <= max_totalæ—¶ä¸é™åˆ¶ã€‚
    å…ˆæŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿæ— å€¼æ’åã€‚
    è¿”å›é™åˆ¶åçš„èŠ‚ç‚¹åˆ—è¡¨ã€‚
    """
    
    if len(proxies) <= max_total:
        return proxies

    limit_60 = {'é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'}
    limit_15 = {'å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'}

    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿç¼ºå¤±æŒ‰9999å¤„ç†
    proxies.sort(key=lambda p: p.get('clash_delay', 9999))

    grouped = defaultdict(list)
    for p in proxies:
        rname = p.get('region_info', {}).get('name') if p.get('region_info') else None
        grouped[rname].append(p)

    selected = []

    # å…ˆé€‰60é™åˆ¶åŒº
    for region in limit_60:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:60])

    # 15é™åˆ¶åŒº
    for region in limit_15:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:15])

    # å…¶ä»–åŒºåŸŸ
    other_regions = set(grouped.keys()) - limit_60 - limit_15 - {None}
    for region in other_regions:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:10])

    # å¯èƒ½æœ‰æ²¡æœ‰åœ°åŒºä¿¡æ¯çš„èŠ‚ç‚¹ï¼Œå…¨éƒ¨ä¿ç•™
    selected.extend(grouped.get(None, []))

    # å¦‚æœæ•°é‡ä»è¶…é™ï¼Œåˆ™æŒ‰å»¶è¿Ÿæ’åºæˆªæ–­
    if len(selected) > max_total:
        selected.sort(key=lambda p: p.get('clash_delay', 9999))
        selected = selected[:max_total]

    return selected
    

# èŠ‚ç‚¹è¯„åˆ†

def calculate_quality_score(proxy):
    """
    é‡æ–°è®¾è®¡æ›´åˆç†çš„è´¨é‡è¯„åˆ†ç³»ç»Ÿï¼ˆ0-100åˆ†ï¼‰
    2025-12-08ä¼˜åŒ–ç‰ˆ
    """
    score = 0
    
    # 1. å»¶è¿Ÿè¯„åˆ† (0-60åˆ†) - æ›´å®½æ¾çš„è¯„åˆ†æ ‡å‡†
    delay = proxy.get('clash_delay', proxy.get('tcp_delay', 9999))
    if delay <= 50:
        score += 60
    elif delay <= 100:
        score += 55
    elif delay <= 150:
        score += 50
    elif delay <= 200:
        score += 45
    elif delay <= 300:
        score += 40
    elif delay <= 400:
        score += 35
    elif delay <= 500:
        score += 30
    elif delay <= 600:
        score += 25
    elif delay <= 800:
        score += 20
    elif delay <= 1000:
        score += 15
    elif delay <= 1500:
        score += 10
    elif delay <= 2000:
        score += 5
    else:
        score += 2  # è¶…æ—¶èŠ‚ç‚¹ä¹Ÿæœ‰åŸºç¡€åˆ†
    
    # 2. å¸¦å®½è¯„åˆ† (0-30åˆ†) - å¦‚æœæ²¡æœ‰å¸¦å®½æ•°æ®ç»™åŸºç¡€åˆ†
    bw_str = proxy.get('bandwidth', '')
    if bw_str:
        import re
        match = re.search(r'([0-9\.]+)\s*(KB|MB|GB)/?s', bw_str, re.I)
        if match:
            num = float(match.group(1))
            unit = match.group(2).upper()
            if unit == 'GB':
                num *= 1000
            elif unit == 'KB':
                num /= 1000
            
            # æ›´åˆç†çš„å¸¦å®½è¯„åˆ†
            if num >= 100:  # â‰¥100MB/s
                score += 30
            elif num >= 50:
                score += 25
            elif num >= 30:
                score += 20
            elif num >= 20:
                score += 15
            elif num >= 10:
                score += 10
            elif num >= 5:
                score += 5
            elif num >= 2:
                score += 3
            else:
                score += 1  # ä½é€Ÿä¹Ÿæœ‰åŸºç¡€åˆ†
    else:
        # æ²¡æœ‰å¸¦å®½æ•°æ®ç»™åŸºç¡€åˆ†ï¼Œä¸æƒ©ç½š
        score += 10
    
    # 3. åœ°åŒºä¼˜å…ˆçº§åŠ æˆ (0-10åˆ†) - æ‰©å¤§åœ°åŒºèŒƒå›´
    region = proxy.get('region_info', {}).get('name', '')
    region_bonus = {
        'é¦™æ¸¯': 10, 'å°æ¹¾': 9, 'æ—¥æœ¬': 8, 'æ–°åŠ å¡': 7,
        'éŸ©å›½': 6, 'é©¬æ¥è¥¿äºš': 5, 'æ³°å›½': 4, 'è¶Šå—': 4,
        'ç¾å›½': 3, 'åŠ æ‹¿å¤§': 3, 'å¾·å›½': 2, 'è‹±å›½': 2,
        'æ³•å›½': 2, 'æ¾³å¤§åˆ©äºš': 2, 'ä¿„ç½—æ–¯': 1, 'æ„å¤§åˆ©': 1,
        'å·´è¥¿': 1, 'é˜¿æ ¹å»·': 1, 'åœŸè€³å…¶': 1, 'å°åº¦': 1,
        'è²å¾‹å®¾': 1, 'å°åº¦å°¼è¥¿äºš': 1
    }
    score += region_bonus.get(region, 0)
    
    return min(score, 100)


def sort_proxies_by_quality(proxies):
    """
    æŒ‰è´¨é‡è¯„åˆ†æ’åºï¼ŒåŒåˆ†æ—¶æŒ‰å»¶è¿Ÿæ’åº
    å¹¶ç»™é«˜è´¨é‡èŠ‚ç‚¹æ·»åŠ è´¨é‡æ ‡ç­¾
    """
    # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„è´¨é‡è¯„åˆ†
    for proxy in proxies:
        proxy['quality_score'] = calculate_quality_score(proxy)
        
        # æ ¹æ®è´¨é‡è¯„åˆ†æ·»åŠ æ ‡ç­¾ - æ›´åˆç†çš„åˆ†å¸ƒ
        score = proxy['quality_score']
        if score >= 70:
            proxy['quality_tag'] = 'ğŸ”¥æå“'
        elif score >= 50:
            proxy['quality_tag'] = 'â­ä¼˜è´¨'
        elif score >= 30:
            proxy['quality_tag'] = 'âœ…è‰¯å¥½'
        else:
            proxy['quality_tag'] = 'âš¡å¯ç”¨'
    
    # æŒ‰è´¨é‡é™åºã€å»¶è¿Ÿå‡åºæ’åº
    return sorted(proxies, key=lambda p: (
        -p['quality_score'],  # è´¨é‡åˆ†é™åº
        p.get('clash_delay', p.get('tcp_delay', 9999))  # å»¶è¿Ÿå‡åº
    ))
    


# ===èŠ‚ç‚¹è´¨é‡æ ‡ç­¾
def add_quality_to_name(proxies):
    """
    åœ¨èŠ‚ç‚¹åç§°æœ«å°¾æ·»åŠ è´¨é‡æ ‡ç­¾
    ä¾‹å¦‚: "ğŸ‡­ğŸ‡° é¦™æ¸¯ 01 [ğŸ”¥æå“]"
    """
    for proxy in proxies:
        name = proxy['name']
        quality_tag = proxy.get('quality_tag', 'âš¡å¯ç”¨')
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è´¨é‡æ ‡ç­¾ï¼ˆä»¥é˜²é‡å¤ï¼‰
        for tag in ['ğŸ”¥æå“', 'â­ä¼˜è´¨', 'âœ…è‰¯å¥½', 'âš¡å¯ç”¨']:
            name = name.replace(f" [{tag}]", "").replace(f"[{tag}] ", "").replace(f"[{tag}]", "")
        
        # åœ¨åç§°æœ«å°¾æ·»åŠ è´¨é‡æ ‡ç­¾
        proxy['name'] = f"{name} [{quality_tag}]".strip()
    
    return proxies



# ===
def generate_config(proxies, last_message_ids):
    return {
        'proxies': proxies,
        'last_message_ids': last_message_ids,
    }


#TCP æµ‹é€Ÿ,æµ‹é€Ÿé»˜è®¤å…³é—­
def run_speedtest(enable_tcp_log=False):
    cmd = ['./xcspeedtest', '--verbose']  # å…·ä½“å‚æ•°è§†ç‰ˆæœ¬è€Œå®š
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    while True:
        line = process.stdout.readline()
        if line == '' and process.poll() is not None:
            break
        if line:
            if 'TCP' in line:
                if enable_tcp_log:
                    print(line.strip())
                else:
                    # TCPæ—¥å¿—å…³é—­ ä¸æ‰“å°
                    pass
            else:
                print(line.strip())
                
    stderr_lines = process.stderr.read().splitlines()
    for line in stderr_lines:
        if 'TCP' in line:
            if enable_tcp_log:
                print(line.strip())
        else:
            print(line.strip())
    
    return process.poll()


def tcp_ping(proxy, timeout=TCP_TIMEOUT):
    """
    çº¯ TCP è¿æ¥æµ‹å»¶è¿Ÿï¼Œè¿”å›å»¶è¿Ÿï¼ˆmsï¼‰æˆ– None
    """
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    
    try:
        start = time.time()
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(timeout)
            s.connect((server, int(port)))
        delay_ms = int((time.time() - start) * 1000)
        # è¿‡æ»¤å¼‚å¸¸å€¼ï¼ˆ<1ms åŸºæœ¬æ˜¯å‡çš„ï¼‰
        if 1 < delay_ms <= 5000:
            return delay_ms
        else:
            return None
    except:
        return None
        

# é”šç‚¹

def test_proxy_with_clash(clash_path, proxy):
    delay = clash_test_proxy(clash_path, proxy)
    if delay is not None:
        proxy['clash_delay'] = delay
        return proxy
    return None



def batch_tcp_test(proxies, max_workers=TCP_MAX_WORKERS):
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {executor.submit(tcp_ping, p): p for p in proxies}
        for future in as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            delay = future.result()
            if delay is not None and delay <= TCP_MAX_DELAY:
                proxy = proxy.copy()
                proxy['tcp_delay'] = delay
                results.append(proxy)
                if ENABLE_TCP_LOG:
                    print(f"TCP PASS: {delay:4d}ms â†’ {proxy.get('name', '')[:40]}")
            else:
                if delay and ENABLE_TCP_LOG:
                    print(f"TCP SLOW: {delay:4d}ms â†’ ä¸¢å¼ƒ {proxy.get('name', '')[:40]}")
    return results


def batch_test_proxies_speedtest(speedtest_path, proxies, max_workers=48, debug=False, test_urls=None):
    """
    ä½¿ç”¨ xcspeedtest æ‰¹é‡æµ‹è¯•ä»£ç†å»¶è¿Ÿ + å¸¦å®½
    å·²åŠ å…¥ï¼š
        â€¢ æµ‹é€Ÿå‰é¢„çƒ­æµ‹é€Ÿåœ°å€
        â€¢ è‡ªåŠ¨é‡è¯• 2 æ¬¡
        â€¢ æ›´åˆç†çš„è¶…æ—¶ä¸å¹¶å‘
        â€¢ æ ¹æ®ç½‘ç»œçŠ¶æ€åŠ¨æ€é€‰æ‹©æµ‹é€Ÿåœ°å€
    """
    # åŠ¨æ€è·å–æµ‹é€Ÿåœ°å€
    if test_urls is None:
        test_urls = get_test_urls()
    
    print(f"ä½¿ç”¨æµ‹é€Ÿåœ°å€: {test_urls}")
    print(f"å¼€å§‹ speedtest-clash ç²¾æµ‹ï¼Œç›®æ ‡èŠ‚ç‚¹æ•°ï¼š{len(proxies)}ï¼Œå¹¶å‘ï¼š{max_workers}")
    
    # ============ å…³é”®ä¼˜åŒ–1ï¼šæµ‹é€Ÿå‰é¢„çƒ­æ‰€æœ‰æµ‹é€Ÿåœ°å€ ============
    print("é¢„çƒ­æµ‹é€Ÿçº¿è·¯ï¼ˆé¿å…é¦–æ¬¡è¯·æ±‚è¶…æ—¶ï¼‰...")
    for url in test_urls:
        try:
            subprocess.run(
                ["curl", "-s", "--max-time", "3", "--connect-timeout", "3", url],
                timeout=6,
                capture_output=True
            )
        except:
            pass  # ä¸åœ¨ä¹ç»“æœï¼Œåªä¸ºè§¦å‘çº¿è·¯å»ºç«‹
    print("é¢„çƒ­å®Œæˆ\n")
    
    # ============ å¹¶å‘æµ‹é€Ÿï¼ˆå¸¦é‡è¯•ï¼‰ ============
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # å…ˆæäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå¸¦æµ‹é€Ÿåœ°å€å‚æ•°ï¼‰
        future_to_proxy = {
            executor.submit(xcspeedtest_test_proxy_with_retry, speedtest_path, proxy, debug, test_urls): proxy
            for proxy in proxies
        }
        for future in concurrent.futures.as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            try:
                result = future.result()  # (delay, bandwidth) or None
                if result is not None:
                    delay, bandwidth = result
                    pcopy = proxy.copy()
                    pcopy['clash_delay'] = delay
                    if bandwidth:
                        pcopy['bandwidth'] = bandwidth
                    results.append(pcopy)
                    if debug:
                        print(f"æˆåŠŸ: {delay:4d}ms | {bandwidth or 'N/A':>10} â†’ {proxy.get('name')}")
                else:
                    if debug:
                        print(f"å¤±è´¥ï¼ˆå·²é‡è¯•ï¼‰ â†’ {proxy.get('name')}")
            except Exception as e:
                if debug:
                    print(f"å¼‚å¸¸: {proxy.get('name')} â†’ {e}")
    print(f"speedtest-clash ç²¾æµ‹å®Œæˆï¼ŒæˆåŠŸèŠ‚ç‚¹ï¼š{len(results)} ä¸ª")
    return results


# ============ è¾…åŠ©å‡½æ•°ï¼šå¸¦é‡è¯•çš„å•èŠ‚ç‚¹æµ‹é€Ÿï¼ˆåŠ¡å¿…ä¸€èµ·åŠ ä¸Šï¼‰ ============
def xcspeedtest_test_proxy_with_retry(speedtest_path, proxy, debug=False, test_urls=None, retries=2):
    """
    å¯¹å•ä¸ªèŠ‚ç‚¹è¿›è¡Œæµ‹é€Ÿï¼Œæœ€å¤šé‡è¯• retries æ¬¡
    æ”¯æŒä¼ å…¥è‡ªå®šä¹‰æµ‹é€Ÿåœ°å€åˆ—è¡¨
    """
    if test_urls is None:
        test_urls = get_test_urls()
        
    for attempt in range(retries + 1):
        try:
            result = xcspeedtest_test_proxy(speedtest_path, proxy, debug, test_urls)
            if result is not None:  # (delay, bandwidth)
                return result
            else:
                if attempt < retries:
                    time.sleep(1.5)  # æ¯æ¬¡é‡è¯•é—´éš” 1.5 ç§’
                    if debug:
                        print(f"  ç¬¬ {attempt + 1} æ¬¡å¤±è´¥ï¼Œé‡è¯• â†’ {proxy['name']}")
                    continue
        except Exception as e:
            if attempt < retries:
                time.sleep(1.5)
                continue
            else:
                if debug:
                    print(f"  é‡è¯• {retries} æ¬¡åä»å¼‚å¸¸ â†’ {proxy['name']}")
    return None


# clash æµ‹é€Ÿ
def xcspeedtest_test_proxy(speedtest_path, proxy, debug=False, test_urls=None):
    """
    2025-12-06 ç»ˆææ— æ•Œç‰ˆ
    å…¼å®¹æ‰€æœ‰ç‰ˆæœ¬ xcspeedtestï¼ˆæœ‰/æ—  clash_delayã€å¼•å·æ®‹ç¼ºã€æ¢è¡Œæˆªæ–­ã€å¸¦å®½è¡¨æ ¼ç­‰ï¼‰
    æ”¯æŒä¼ å…¥è‡ªå®šä¹‰æµ‹é€Ÿåœ°å€åˆ—è¡¨
    """
    if test_urls is None:
        test_urls = get_test_urls()
        
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            config_path = os.path.join(tmpdir, 'config.yaml')
            
            # ä½¿ç”¨åŠ¨æ€æµ‹é€Ÿåœ°å€æ„å»ºè§„åˆ™
            rules = []
            for url in test_urls:
                domain = urlparse(url).netloc
                if domain:
                    rules.append(f"DOMAIN,{domain},TESTGROUP")
            rules.append("MATCH,DIRECT")
            
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [{"name": "TESTGROUP", "type": "select", "proxies": [proxy["name"]]}],
                "rules": rules
            }
            
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)
            
            cmd = [speedtest_path, '-c', config_path]
            result = subprocess.run(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                timeout=40, text=True, encoding='utf-8', errors='ignore'
            )
            output = result.stdout + result.stderr
            
            if debug:
                print(f"[speedtest-clash] åŸå§‹è¾“å‡º:\n{output}")
            
            delay = None
            bandwidth = None
            
            # 1. ä¼˜å…ˆä» JSON æå– clash_delay
            json_pattern = re.compile(r'json:\s*(\[[\s\S]*?\])', re.IGNORECASE)
            for match in json_pattern.finditer(output):
                j = match.group(1)
                if j.count('{') > j.count('}'): 
                    j += '}'
                if j.count('[') > j.count(']'): 
                    j += ']'
                try:
                    data = json.loads(j)
                    if isinstance(data, list) and data and "clash_delay" in data[0]:
                        d = int(data[0]["clash_delay"])
                        if 1 <= d <= 3000:
                            delay = d
                            if debug:
                                print(f"JSON clash_delay å‘½ä¸­ â†’ {delay}ms â† {proxy['name']}")
                            break
                except:
                    continue
            
            # 2. å…œåº•ï¼šè¡¨æ ¼å»¶è¿Ÿåˆ—
            if delay is None:
                m = re.search(r'å»¶è¿Ÿ.*?([0-9]+)\s*(?:[^0-9]|$)', output, re.DOTALL)
                if m:
                    try:
                        d = int(m.group(1))
                        if 1 <= d <= 3000:
                            delay = d
                            if debug:
                                print(f"è¡¨æ ¼å»¶è¿Ÿå…œåº• â†’ {delay}ms â† {proxy['name']}")
                    except:
                        pass
            
            # 3. æå–å¸¦å®½
            bw = re.search(r'([0-9\.]+ ?[KMGT]B/s)', output)
            if bw:
                bandwidth = bw.group(1).strip()
            
            if delay is not None:
                if debug:
                    print(f"æµ‹é€ŸæˆåŠŸ â†’ {delay}ms | å¸¦å®½ {bandwidth or 'N/A'} â† {proxy['name']}")
                return delay, bandwidth
            
            if debug:
                print(f"æµ‹é€Ÿå¤±è´¥ â†’ ä¸¢å¼ƒ {proxy['name']}")
            return None
            
    except Exception as e:
        if debug:
            print(f"æµ‹é€Ÿå¼‚å¸¸: {e}")
        return None


def clash_test_proxy(clash_path, proxy, test_urls=None, debug=False):
    """
    ä½¿ç”¨ clash çš„ -fast æ¨¡å¼å¯¹å•ä¸ªä»£ç†èŠ‚ç‚¹è¿›è¡Œæµ‹é€Ÿ
    æ”¯æŒä¼ å…¥è‡ªå®šä¹‰æµ‹é€Ÿåœ°å€åˆ—è¡¨
    """
    if test_urls is None:
        test_urls = get_test_urls()

    temp_dir = tempfile.mkdtemp()
    config_path = os.path.join(temp_dir, 'config.yaml')

    try:
        for test_url in test_urls:
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [
                    {
                        "name": "TESTGROUP",
                        "type": "select",
                        "proxies": [proxy["name"]]
                    }
                ],
                "rules": [
                    f"DOMAIN,{urlparse(test_url).netloc},TESTGROUP",
                    "MATCH,DIRECT"
                ]
            }

            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)

            cmd = [clash_path, '-c', config_path, '-fast']

            if debug:
                print(f"\n=== ä½¿ç”¨æµ‹é€Ÿ URL: {test_url} æµ‹è¯•èŠ‚ç‚¹: {proxy['name']} ===")

            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30,
                text=True
            )

            output = (result.stdout + result.stderr).replace('\x00', '')

            if debug:
                print(f"clash -fast è¾“å‡º:\n{output}")

            # åŒ¹é…å»¶è¿Ÿ
            match = re.search(r'\b(\d+)ms\b(?=\s*$)', output, re.MULTILINE)
            if match:
                delay = int(match.group(1))
                if 1 < delay < 800:
                    if debug:
                        print(f"æˆåŠŸåŒ¹é…å»¶è¿Ÿ {delay}msï¼Œä¿ç•™èŠ‚ç‚¹")
                    return delay

            # å°è¯•åŒ¹é…æ‰€æœ‰å¯èƒ½çš„å»¶è¿Ÿæ•°å€¼
            delays = re.findall(r'\b([2-9]\d{1,3})\b', output)
            if delays:
                delay_values = [int(d) for d in delays if int(d) < 800]
                if delay_values:
                    delay = min(delay_values)
                    if debug:
                        print(f"æœªåŒ¹é…å›ºå®šæ ¼å¼å»¶è¿Ÿï¼Œå–æœ€å°å»¶è¿Ÿ {delay}msï¼Œä¿ç•™èŠ‚ç‚¹")
                    return delay

            # åˆ¤æ–­æ— æ•ˆå»¶è¿Ÿå€¼
            if re.search(r'\b(0\s*ms|1\s*ms|NA)\b', output, re.I):
                if debug:
                    print("æ£€æµ‹åˆ°æ— æ•ˆå»¶è¿Ÿå€¼ (0ms/1ms/NA)ï¼Œä¸¢å¼ƒèŠ‚ç‚¹")
                return None

            if debug:
                print("å½“å‰æµ‹é€Ÿ URL æœªè·å¾—æœ‰æ•ˆå»¶è¿Ÿï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL")

        if debug:
            print(f"æ‰€æœ‰æµ‹é€Ÿ URL å‡æœªè·å¾—æœ‰æ•ˆå»¶è¿Ÿï¼Œä¸¢å¼ƒèŠ‚ç‚¹: {proxy['name']}")
        return None

    except subprocess.TimeoutExpired:
        if debug:
            print(f"æµ‹é€Ÿè¶…æ—¶ï¼Œä¸¢å¼ƒèŠ‚ç‚¹: {proxy['name']}")
    except Exception as e:
        if debug:
            print(f"æµ‹é€Ÿå¼‚å¸¸ {e}ï¼Œä¸¢å¼ƒèŠ‚ç‚¹: {proxy['name']}")
    finally:
        try:
            shutil.rmtree(temp_dir)
        except Exception:
            pass

    return None






# ä¸»å‡½æ•°
               
async def main():
    print("=" * 60)
    print("Telegram.Node_Clash-Speedtestæµ‹è¯•ç‰ˆ V1")
    print(datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)
    
    # === æ˜¾ç¤ºç½‘ç»œæ§åˆ¶é…ç½® ===
    print("ğŸŒ ç½‘ç»œæ§åˆ¶é…ç½®:")
    print(f"  - æŠ“å–é˜¶æ®µ Warp: {WARP_FOR_SCRAPING}")
    print(f"  - TCPæµ‹é€Ÿ Warp: {WARP_FOR_TCP}")
    print(f"  - Speedtestæµ‹é€Ÿ Warp: {WARP_FOR_SPEEDTEST}")
    print(f"  - æœ€ç»ˆé˜¶æ®µ Warp: {WARP_FOR_FINAL}")
    print("-" * 40)
    
    # åªåœ¨GitHub Actionsä¸­å¯ç”¨ç½‘ç»œæ§åˆ¶
    if os.getenv('GITHUB_ACTIONS') == 'true':
        print("ğŸ—ï¸ GitHub Actionsç¯å¢ƒæ£€æµ‹åˆ°ï¼Œå¯ç”¨ç½‘ç»œæ§åˆ¶")
        # åˆå§‹ç½‘ç»œçŠ¶æ€æ£€æŸ¥
        simplified_network_check()
    else:
        print("ğŸ’» æœ¬åœ°ç¯å¢ƒï¼Œè·³è¿‡ç½‘ç»œæ§åˆ¶")
    
    # åˆå§‹åŒ–ç½‘ç»œçŠ¶æ€
    preprocess_regex_rules()

    print("[1/5] åŠ è½½åŸæœ‰èŠ‚ç‚¹å’ŒæŠ“å–çŠ¶æ€")
    existing_proxies, last_message_ids = load_existing_proxies_and_state()
    print(f"å·²æœ‰èŠ‚ç‚¹æ•°: {len(existing_proxies)}")

    # === é˜¶æ®µ1ï¼šTelegramæŠ“å–ï¼ˆæ ¹æ®é…ç½®ä½¿ç”¨ç½‘ç»œï¼‰===
    print("[2/5] æŠ“å– Telegram æ–°è®¢é˜…é“¾æ¥")
    # åªæ£€æŸ¥ï¼Œä¸å¼ºåˆ¶åˆ‡æ¢
    if os.getenv('GITHUB_ACTIONS') == 'true':
        ensure_network_for_stage('scraping', require_warp=WARP_FOR_SCRAPING)
    
    urls, last_message_ids = await scrape_telegram_links(last_message_ids)
    
    # === é˜¶æ®µ2ï¼šä¸‹è½½è§£æè®¢é˜…é“¾æ¥ï¼ˆä¿æŒå½“å‰ç½‘ç»œï¼‰===
    new_proxies = []
    if urls:
        print(f"æŠ“å–åˆ° {len(urls)} ä¸ªè®¢é˜…é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½è§£æ...")
        for i, url in enumerate(urls, 1):
            print(f"è§£æè¿›åº¦: {i}/{len(urls)} - {url[:70]}...")
            proxies = download_and_parse(url)
            if proxies:
                new_proxies.extend(proxies)
                print(f"  æˆåŠŸè§£æ {len(proxies)} ä¸ªèŠ‚ç‚¹")
    print(f"æ–°å¢èŠ‚ç‚¹æ•°: {len(new_proxies)}")

    all_proxies_map = {
        get_proxy_key(p): p for p in existing_proxies if is_valid_proxy(p)
    }
    added_count = 0
    for p in new_proxies:
        key = get_proxy_key(p)
        if key not in all_proxies_map:
            all_proxies_map[key] = p
            added_count += 1
    print(f"åˆå¹¶å»é‡åæ€»èŠ‚ç‚¹æ•°: {len(all_proxies_map)}ï¼Œæ–°å¢æœ‰æ•ˆèŠ‚ç‚¹: {added_count}")

    all_nodes = list(all_proxies_map.values())
    if not all_nodes:
        sys.exit("âŒ æ— ä»»ä½•èŠ‚ç‚¹å¯ç”¨ï¼Œç¨‹åºé€€å‡º")
    
    # === é˜¶æ®µ3ï¼šæµ‹é€Ÿå‡†å¤‡ï¼ˆæ ¹æ®æ¨¡å¼é€‰æ‹©ç½‘ç»œï¼‰===
    print(f"[3/5] å¼€å§‹èŠ‚ç‚¹æµ‹é€Ÿï¼ˆæ¨¡å¼: {SPEEDTEST_MODE}ï¼‰")
    
    final_tested_nodes = all_nodes.copy()
    speedtest_path = './xcspeedtest'
    
    # æ£€æŸ¥æµ‹é€Ÿå·¥å…·æ˜¯å¦å­˜åœ¨
    if not os.path.exists(speedtest_path) or not os.access(speedtest_path, os.X_OK):
        print(f"âŒ speedtestå·¥å…·ç¼ºå¤±æˆ–ä¸å¯æ‰§è¡Œ: {speedtest_path}")
        print("âš ï¸ è·³è¿‡æµ‹é€Ÿï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹")
    else:
        if SPEEDTEST_MODE == "tcp_only":
            print("ä½¿ç”¨ã€çº¯ TCP æµ‹é€Ÿã€‘æ¨¡å¼")
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
            final_tested_nodes = batch_tcp_test(all_nodes)
            
        elif SPEEDTEST_MODE == "clash_only":
            print("ä½¿ç”¨ã€çº¯ speedtest-clash æµ‹é€Ÿã€‘æ¨¡å¼")
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
            final_tested_nodes = batch_test_proxies_speedtest(
                speedtest_path,
                all_nodes,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
            
        elif SPEEDTEST_MODE == "tcp_first":
            print("ä½¿ç”¨ã€TCP ç²—ç­› â†’ speedtest-clash ç²¾æµ‹ã€‘ä¸¤é˜¶æ®µæ¨¡å¼")
            
            # é˜¶æ®µ1ï¼šTCPæµ‹é€Ÿ
            print("é˜¶æ®µ1ï¼šTCP è¶…é«˜å¹¶å‘ç²—ç­›...")
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
            tcp_passed = batch_tcp_test(all_nodes)
            print(f"TCP ç²—ç­›å®Œæˆï¼š{len(all_nodes)} â†’ {len(tcp_passed)}")
            
            if not tcp_passed:
                print("TCP å…¨æ­»ï¼Œé™çº§ä½¿ç”¨çº¯ speedtest-clash æ¨¡å¼")
                if os.getenv('GITHUB_ACTIONS') == 'true':
                    ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
                final_tested_nodes = batch_test_proxies_speedtest(
                    speedtest_path,
                    all_nodes,
                    max_workers=MAX_TEST_WORKERS,
                    debug=ENABLE_SPEEDTEST_LOG
                )
            else:
                # é˜¶æ®µ2ï¼šSpeedtestæµ‹é€Ÿ
                print("é˜¶æ®µ2ï¼šå¯¹ TCP å­˜æ´»èŠ‚ç‚¹è¿›è¡Œ speedtest-clash ç²¾å‡†æµ‹é€Ÿ...")
                if os.getenv('GITHUB_ACTIONS') == 'true':
                    ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
                
                final_tested_nodes = batch_test_proxies_speedtest(
                    speedtest_path,
                    tcp_passed,
                    max_workers=MAX_TEST_WORKERS,
                    debug=ENABLE_SPEEDTEST_LOG
                )
                
        elif SPEEDTEST_MODE == "clash_first":
            print("ä½¿ç”¨ã€speedtest-clash å…ˆæµ‹ â†’ TCP åéªŒã€‘æ¨¡å¼")
            # é˜¶æ®µ1ï¼šSpeedtestæµ‹é€Ÿ
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
            clash_passed = batch_test_proxies_speedtest(
                speedtest_path,
                all_nodes,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
            
            # é˜¶æ®µ2ï¼šTCPéªŒè¯
            print("TCP éªŒè¯é˜¶æ®µ...")
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
            final_tested_nodes = [p for p in clash_passed if tcp_ping(p) is not None]
            
        else:
            print(f"æœªçŸ¥æ¨¡å¼ '{SPEEDTEST_MODE}'ï¼Œä½¿ç”¨é»˜è®¤ tcp_first")
            # TCPæµ‹é€Ÿ
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
            tcp_passed = batch_tcp_test(all_nodes)
            
            if not tcp_passed:
                # Speedtestæµ‹é€Ÿ
                if os.getenv('GITHUB_ACTIONS') == 'true':
                    ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
                final_tested_nodes = batch_test_proxies_speedtest(
                    speedtest_path,
                    all_nodes,
                    max_workers=MAX_TEST_WORKERS,
                    debug=ENABLE_SPEEDTEST_LOG
                )
            else:
                # Speedtestæµ‹é€Ÿ
                if os.getenv('GITHUB_ACTIONS') == 'true':
                    ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
                final_tested_nodes = batch_test_proxies_speedtest(
                    speedtest_path,
                    tcp_passed,
                    max_workers=MAX_TEST_WORKERS,
                    debug=ENABLE_SPEEDTEST_LOG
                )

        # æµ‹é€Ÿç»“æœç»Ÿè®¡
        success_count = len(final_tested_nodes)
        print(f"æµ‹é€Ÿå®Œæˆï¼Œæœ€ç»ˆå­˜æ´»ä¼˜è´¨èŠ‚ç‚¹ï¼š{success_count} ä¸ª")
        
        # ä¿åº•å›é€€æœºåˆ¶
        if success_count < 50:
            print(f"æµ‹é€Ÿç»“æœè¿‡å°‘ï¼ˆ{success_count}ä¸ªï¼‰ï¼Œå¯åŠ¨è¶…çº§ä¿åº•ç­–ç•¥ï¼Œä¿ç•™çƒ­é—¨åœ°åŒºèŠ‚ç‚¹")
            priority_regions = ['é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'ç¾å›½', 'éŸ©å›½', 'å¾·å›½', 'åŠ æ‹¿å¤§']
            
            backup_nodes = []
            seen_keys = set()
            
            for proxy in all_nodes:
                if len(backup_nodes) >= 300:
                    break
                    
                key = get_proxy_key(proxy)
                if key in seen_keys:
                    continue
                seen_keys.add(key)
                
                region = proxy.get('region_info', {}).get('name')
                if region in priority_regions:
                    proxy = proxy.copy()
                    proxy['clash_delay'] = 9999
                    backup_nodes.append(proxy)
            
            # å¦‚æœçƒ­é—¨åœ°åŒºè¿˜æ˜¯ä¸å¤Ÿï¼Œå°±ä»å‰©ä½™èŠ‚ç‚¹é‡Œéšä¾¿è¡¥
            if len(backup_nodes) < 200:
                for proxy in all_nodes:
                    if len(backup_nodes) >= 400:
                        break
                    key = get_proxy_key(proxy)
                    if key not in seen_keys:
                        p = proxy.copy()
                        p['clash_delay'] = 9999
                        backup_nodes.append(p)
                        seen_keys.add(key)
            
            final_tested_nodes = backup_nodes
            success_count = len(final_tested_nodes)
            print(f"è¶…çº§ä¿åº•æˆåŠŸï¼å¼ºåˆ¶ä¿ç•™ {success_count} ä¸ªçƒ­é—¨åœ°åŒºèŠ‚ç‚¹ï¼ˆæœªæµ‹é€Ÿï¼Œä»…ç”¨äºåº”æ€¥ï¼‰")
    
    # ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯æœ‰æ•ˆçš„
    final_tested_nodes = [p for p in final_tested_nodes if is_valid_proxy(p)]
    if not final_tested_nodes:
        sys.exit("âŒ æµ‹é€Ÿåæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")
    
    # === é˜¶æ®µ4ï¼šåˆ‡æ¢å›GitHubç½‘ç»œè¿›è¡Œæœ€ç»ˆå¤„ç† ===
    print("[4/5] åˆ‡æ¢å›GitHubç½‘ç»œè¿›è¡Œæœ€ç»ˆå¤„ç†")
    if os.getenv('GITHUB_ACTIONS') == 'true':
        ensure_network_for_stage('final', require_warp=WARP_FOR_FINAL)
    
    # èŠ‚ç‚¹åç§°ç»Ÿä¸€è§„èŒƒåŒ–å¤„ç†
    normalized_proxies = normalize_proxy_names(final_tested_nodes)
    
    # é™åˆ¶èŠ‚ç‚¹æ•°é‡
    final_proxies = limit_proxy_counts(normalized_proxies, max_total=300)
    
    if not final_proxies:
        sys.exit("âŒ èŠ‚ç‚¹é‡å‘½åå’Œé™é‡åæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")

    # è®¡ç®—èŠ‚ç‚¹è´¨é‡è¯„åˆ†å¹¶æ’åº
    print("[4.5/5] è®¡ç®—èŠ‚ç‚¹è´¨é‡è¯„åˆ†")
    
    # è®¡ç®—è´¨é‡è¯„åˆ†å¹¶æ’åº
    final_proxies = sort_proxies_by_quality(final_proxies)
    
    # åœ¨èŠ‚ç‚¹åç§°ä¸­æ·»åŠ è´¨é‡æ ‡ç­¾
    final_proxies = add_quality_to_name(final_proxies)
    
    # å¸¦å®½äºŒæ¬¡ç­›é€‰
    final_proxies = filter_by_bandwidth(
        final_proxies, 
        min_mb=MIN_BANDWIDTH_MB, 
        enable=ENABLE_BANDWIDTH_FILTER
    )
    
    # ç»Ÿè®¡è´¨é‡åˆ†å¸ƒ
    quality_stats = {'ğŸ”¥æå“': 0, 'â­ä¼˜è´¨': 0, 'âœ…è‰¯å¥½': 0, 'âš¡å¯ç”¨': 0}
    for proxy in final_proxies:
        tag = proxy.get('quality_tag', 'âš¡å¯ç”¨')
        if tag in quality_stats:
            quality_stats[tag] += 1
    
    print(f"  è´¨é‡åˆ†å¸ƒ: {quality_stats}")
    if final_proxies:
        avg_score = sum(p.get('quality_score', 0) for p in final_proxies) / len(final_proxies)
        print(f"  å¹³å‡è´¨é‡åˆ†: {avg_score:.1f}/100")
    else:
        print("  è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹")
        sys.exit("âŒ æ²¡æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")
    
    # é‡æ–°æŒ‰è´¨é‡æ’åº
    final_proxies = sorted(final_proxies, key=lambda p: -p.get('quality_score', 0))
    
    # === é˜¶æ®µ5ï¼šç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶ ===
    print("[5/5] ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶")
    
    total_count = len(final_proxies)
    update_time = datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S")
    avg_quality = sum(p.get('quality_score', 0) for p in final_proxies) / total_count if total_count > 0 else 0

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            # å†™å…¥é…ç½®æ–‡ä»¶æ³¨é‡Šå¤´
            f.write("# ==================================================\n")
            f.write("#  TG å…è´¹èŠ‚ç‚¹ Â· è‡ªåŠ¨æµ‹é€Ÿç²¾é€‰è®¢é˜…ï¼ˆClash æ ¼å¼ï¼‰\n")
            f.write("# ==================================================\n")
            f.write(f"# æ›´æ–°æ—¶é—´   : {update_time} (åŒ—äº¬æ—¶é—´)\n")
            f.write(f"# èŠ‚ç‚¹æ€»æ•°   : {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹\n")
            f.write(f"# å¹³å‡è´¨é‡åˆ† : {avg_quality:.1f}/100\n")
            
            # è´¨é‡åˆ†å¸ƒæ ¼å¼åŒ–ï¼Œå»æ‰å¤§æ‹¬å·
            quality_stats_str = f"ğŸ”¥æå“: {quality_stats['ğŸ”¥æå“']}, â­ä¼˜è´¨: {quality_stats['â­ä¼˜è´¨']}, âœ…è‰¯å¥½: {quality_stats['âœ…è‰¯å¥½']}, âš¡å¯ç”¨: {quality_stats['âš¡å¯ç”¨']}"
            f.write(f"# è´¨é‡åˆ†å¸ƒ   : {quality_stats_str}\n")
            
            f.write(f"# å¸¦å®½ç­›é€‰   : â‰¥ {MIN_BANDWIDTH_MB}MB/s\n")
            f.write(f"# æµ‹é€Ÿæ¨¡å¼   : {SPEEDTEST_MODE}\n")
            f.write(f"# ç½‘ç»œé…ç½®   : TCP_Warp={WARP_FOR_TCP}, Speedtest_Warp={WARP_FOR_SPEEDTEST}\n")
            f.write("# æ’åºè§„åˆ™   : è´¨é‡è¯„åˆ† â†’ å»¶è¿Ÿ â†’ åœ°åŒºä¼˜å…ˆçº§\n")
            f.write("# æ„å»ºæ–¹å¼   : GitHub Actions å…¨è‡ªåŠ¨ï¼Œæ¯4å°æ—¶æ›´æ–°ä¸€æ¬¡\n")
            f.write("# ==================================================\n\n")
            
            # å†™å…¥YAMLæ•°æ®
            final_config = {
                'proxies': final_proxies,
                'last_message_ids': last_message_ids,
                'update_time': update_time,
                'total_nodes': total_count,
                'average_quality': round(avg_quality, 1),
                'quality_stats': quality_stats_str,  # ä½¿ç”¨æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
                'bandwidth_filter': {
                    'enabled': ENABLE_BANDWIDTH_FILTER,
                    'min_mb': MIN_BANDWIDTH_MB
                },
                'speedtest_config': {
                    'mode': SPEEDTEST_MODE,
                    'warp_for_tcp': WARP_FOR_TCP,
                    'warp_for_speedtest': WARP_FOR_SPEEDTEST,
                    'warp_for_scraping': WARP_FOR_SCRAPING
                },
                'note': 'ç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆï¼Œæ¯4å°æ—¶æ›´æ–°ä¸€æ¬¡ï¼Œå·²æŒ‰è´¨é‡è¯„åˆ†æ’åº'
            }
            
            yaml.dump(final_config, f, allow_unicode=True, sort_keys=False, indent=2, width=4096, default_flow_style=False)

    except Exception as e:
        print(f"âŒ å†™å‡ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœï¼ˆä¸æ˜¾ç¤ºé…ç½®æ–‡ä»¶å†…å®¹ï¼‰
    print(f"âœ… é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³ {OUTPUT_FILE}")
    print(f"ğŸ“Š æœ¬æ¬¡å¤„ç†å®Œæˆ:")
    print(f"   èŠ‚ç‚¹æ€»æ•°   : {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
    print(f"   å¹³å‡è´¨é‡åˆ† : {avg_quality:.1f}/100")
    print(f"   è´¨é‡åˆ†å¸ƒ   : {quality_stats_str}")
    print(f"   å¸¦å®½ç­›é€‰   : â‰¥ {MIN_BANDWIDTH_MB}MB/s")
    print(f"   æµ‹é€Ÿæ¨¡å¼   : {SPEEDTEST_MODE}")
    print(f"   æ›´æ–°æ—¶é—´   : {update_time}")
    print("=" * 60)
    print("ğŸ‰ å…¨éƒ¨ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
    
    # æœ€ç»ˆæ¸…ç†ï¼šç¡®ä¿åˆ‡æ¢å›GitHubç½‘ç»œ
    if os.getenv('GITHUB_ACTIONS') == 'true' and WARP_FOR_FINAL == False:
        print("ğŸ§¹ æœ€ç»ˆæ¸…ç†ï¼šç¡®ä¿ä½¿ç”¨åŸå§‹GitHubç½‘ç»œ")
        ensure_network_for_stage('cleanup', require_warp=False)
           


                  
if __name__ == "__main__":
    asyncio.run(main())  # è°ƒç”¨å¼‚æ­¥ä¸»å‡½æ•°
