# -*- coding: utf-8 -*-
"""
æ–‡ä»¶å: Telegram.Node_xc
è„šæœ¬è¯´æ˜:
æœ¬è„šæœ¬å®ç°ä»æŒ‡å®š Telegram é¢‘é“è‡ªåŠ¨çˆ¬å–è®¢é˜…é“¾æ¥ï¼›
ä¸‹è½½å¹¶è§£æå„ç§ä»£ç†è®¢é˜…èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ vmess, vless, ssr, ss, trojan, hysteriaåŠhysteria2ç­‰åè®®ï¼‰ï¼Œ
æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ä¸é‡å‘½åï¼Œå¹¶ä½¿ç”¨ Clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆå»¶è¿Ÿæµ‹è¯•ï¼‰ï¼›
æœ€ç»ˆç”Ÿæˆå¯ç”¨äº Clash ä½¿ç”¨çš„ YAML é…ç½®æ–‡ä»¶ã€‚
ä¸»è¦åŠŸèƒ½:
1. ä» Telegram æŒ‡å®šé¢‘é“æŠ“å–å¸¦æœ‰è®¢é˜…é“¾æ¥çš„æ¶ˆæ¯ï¼Œæ”¯æŒæ—¶é—´çª—å£è¿‡æ»¤æ–°æ¶ˆæ¯ã€‚
2. æ”¯æŒå¤šç§å¸¸è§ä»£ç†åè®®çš„èŠ‚ç‚¹è§£æï¼Œä»¥åŠè¯†åˆ«èŠ‚ç‚¹æ‰€åœ¨åŒºåŸŸã€‚
3. é‡‡ç”¨å‘½ä»¤è¡Œæ¨¡å¼è°ƒç”¨ clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯•ï¼Œç­›é€‰æœ‰æ•ˆèŠ‚ç‚¹ã€‚
4. æ ¹æ®èŠ‚ç‚¹åœ°åŒºä¸å»¶è¿Ÿè‡ªåŠ¨æ’åºå’Œå½’ç±»ï¼Œç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶ã€‚
5. ç¯å¢ƒå˜é‡é…ç½®çµæ´»ï¼Œæ–¹ä¾¿é›†æˆè‡ªåŠ¨åŒ–æµç¨‹ã€‚
"""
import os
import re
import sys
import base64
import json
import yaml
import time
import socket
import hashlib
import asyncio
import shutil
import subprocess
import concurrent.futures
import tempfile
import requests
import socket
from concurrent.futures import as_completed
from urllib.parse import urlparse, parse_qs, unquote
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from telethon.sync import TelegramClient
from telethon.sessions import StringSession

# --- ç¯å¢ƒå˜é‡è¯»å– ---
API_ID = int(os.environ.get('TELEGRAM_API_ID') or 0)
API_HASH = os.environ.get('TELEGRAM_API_HASH')
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS', '')
TIME_WINDOW_HOURS = 4  # æŠ“å–å¤šé•¿æ—¶é—´çš„æ¶ˆæ¯ï¼Œå•ä½ä¸ºå°æ—¶ã€‚
MIN_EXPIRE_HOURS = 2   # è®¢é˜…åœ°å€å‰©ä½™æ—¶é—´æœ€å°è¿‡æœŸï¼Œå•ä½ä¸ºå°æ—¶ã€‚
OUTPUT_FILE = 'flclashyaml/Tg-node1.yaml'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºä¿å­˜ç”Ÿæˆçš„é…ç½®æˆ–ç»“æœã€‚



# === æ–°å¢ï¼šæµ‹é€Ÿç­–ç•¥å¼€å…³ï¼ˆæ¨èä¿ç•™è¿™å‡ ä¸ªé€‰é¡¹ï¼‰===
# æµ‹é€Ÿæ¨¡å¼ï¼š
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æ•´ä½“é€Ÿåº¦æµ‹è¯•åŠŸèƒ½ï¼ŒTrueè¡¨ç¤ºå¯ç”¨ã€‚æµ‹è¯•é¡ºåºå¦‚ä¸‹

SPEEDTEST_MODE = os.getenv('SPEEDTEST_MODE', 'tcp_first').lower()  # é»˜è®¤æ¨è tcp_first,ä¸‹è¾¹çš„å‘½ä»¤
#   "tcp_only"      â†’ åªç”¨ TCP æµ‹é€Ÿï¼ˆæœ€å¿«ï¼Œæœ€ä¸¥æ ¼ï¼Œé€‚åˆèŠ‚ç‚¹ç‰¹åˆ«å¤šçš„æƒ…å†µï¼‰
#   "clash_only"    â†’ åªç”¨ Clash -fast æµ‹é€Ÿï¼ˆæœ€å‡†ï¼‰
#   "tcp_first"     â†’ å…ˆ TCP ç²—ç­›ï¼ˆ<800msï¼‰â†’ å† Clash ç²¾æµ‹ï¼ˆæ¨èï¼å¹³è¡¡é€Ÿåº¦ä¸è´¨é‡ï¼‰
#   "clash_first"   â†’ å…ˆ Clash â†’ å† TCPï¼ˆä¸€èˆ¬ç”¨ä¸ä¸Šï¼‰

# TCP å’ŒClash æµ‹é€Ÿä¸“å±å‚æ•°
TCP_TIMEOUT = 4.0          # å•æ¬¡ TCP è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå»ºè®® 3~5
TCP_MAX_WORKERS = 200      # TCP æµ‹é€Ÿæœ€å¤§å¹¶å‘ï¼ˆå¯ä»¥æ¯” Clash é«˜å¾ˆå¤šï¼Œéå¸¸å¿«ï¼‰
TCP_MAX_DELAY = 1000       # TCP å»¶è¿Ÿé˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼ç›´æ¥ä¸¢å¼ƒï¼ˆmsï¼‰
ENABLE_TCP_LOG = False     # é»˜è®¤å…³é—­TCPæ—¥å¿—
ENABLE_SPEEDTEST_LOG = True  # é»˜è®¤å…³é—­ speedtest è¯¦ç»†æ—¥å¿—


MAX_TEST_WORKERS = 128    # é€Ÿåº¦æµ‹è¯•æ—¶æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼Œæ§åˆ¶æµ‹è¯•çš„å¹¶è¡Œåº¦ã€‚
SOCKET_TIMEOUT = 3       # å¥—æ¥å­—è¿æ¥è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
HTTP_TIMEOUT = 5         # HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
TEST_URLS = [
    'http://www.gstatic.com/generate_204',
    'http://www.youtube.com',
]


ALLOWED_REGIONS = {
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
}
REGION_PRIORITY = [
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
]
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {
        'code': 'HK',
        'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong|HongKong|HKBN|HGC|PCCW|WTT|HKT|ä¹é¾™|æ²™ç”°|å±¯é—¨|èƒæ¹¾|æ·±æ°´åŸ—|æ²¹å°–æ—º'
    },
    'æ—¥æœ¬': {
        'code': 'JP',
        'pattern': r'æ—¥æœ¬|æ—¥|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|äº¬æ—¥|å¹¿æ—¥|JP|Japan|Tokyo|Osaka|Saitama|åŸ¼ç‰|åå¤å±‹|Nagoya|ç¦å†ˆ|Fukuoka|æ¨ªæ»¨|Yokohama|NTT|IIJ|GMO|Linode'
    },
    'æ–°åŠ å¡': {
        'code': 'SG',
        'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|ç‹®|æ–°|SG|Singapore|SG\d+|SGP|æ˜Ÿ|ç‹®å­åŸ'
    },
    'ç¾å›½': {
        'code': 'US',
        'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|ä¿„å‹’å†ˆ|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥|çº½çº¦|è¿ˆé˜¿å¯†|äºšç‰¹å…°å¤§|US|USA|United\s*States|America|LA|NYC|SF|San\s*Francisco|Washington|åç››é¡¿|Kansas|å ªè¨æ–¯|Denver|ä¸¹ä½›|Phoenix|Seattle|Chicago|Boston|æ³¢å£«é¡¿|Atlanta|Miami|Las\s*Vegas'
    },
    'å°æ¹¾': {
        'code': 'TW',
        'pattern': r'å°æ¹¾|æ¹¾çœ|å°|TW|Taiwan|TWN|å°åŒ—|Taipei|å°ä¸­|Taichung|é«˜é›„|Kaohsiung|æ–°åŒ—|å½°åŒ–|Hinet|ä¸­åç”µä¿¡'
    },
    'éŸ©å›½': {
        'code': 'KR',
        'pattern': r'éŸ©å›½|éŸ©|å—æœé²œ|é¦–å°”|é‡œå±±|ä»å·|KR|Korea|KOR|éŸ“|Seoul|Busan|KT|SK|LG'
    },
    'å¾·å›½': {
        'code': 'DE',
        'pattern': r'å¾·å›½|å¾·|æ³•å…°å…‹ç¦|æ…•å°¼é»‘|æŸæ—|DE|Germany|Frankfurt|Munich|Berlin|Hetzner'
    },
    'è‹±å›½': {
        'code': 'GB',
        'pattern': r'è‹±å›½|è‹±|ä¼¦æ•¦|æ›¼å½»æ–¯ç‰¹|UK|GB|United\s*Kingdom|Britain|England|London|Manchester'
    },
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|é©¬æ¥|MY|Malaysia'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'æ³°å›½': {
    'code': 'TH',
    'pattern': r'æ³°å›½|TH|Thailand|æ›¼è°·|Bangkok'
},
    'è²å¾‹å®¾': {
    'code': 'PH',
    'pattern': r'è²å¾‹å®¾|PH|Philippines|é©¬å°¼æ‹‰|Manila'
},
    'å°åº¦å°¼è¥¿äºš': {
    'code': 'ID',
    'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia|é›…åŠ è¾¾|Jakarta'
},
    'ä¿„ç½—æ–¯': {
    'code': 'RU',
    'pattern': r'ä¿„ç½—æ–¯|RU|Russia|è«æ–¯ç§‘|Moscow'
},
    'æ„å¤§åˆ©': {
    'code': 'IT',
    'pattern': r'æ„å¤§åˆ©|IT|Italy|ç½—é©¬|Rome'
},
    'å·´è¥¿': {
    'code': 'BR',
    'pattern': r'å·´è¥¿|BR|Brazil|åœ£ä¿ç½—|SÃ£o\s*Paulo'
},
    'é˜¿æ ¹å»·': {
    'code': 'AR',
    'pattern': r'é˜¿æ ¹å»·|AR|Argentina|å¸ƒå®œè¯ºæ–¯è‰¾åˆ©æ–¯|Buenos\s*Aires'
},
    'åœŸè€³å…¶': {
    'code': 'TR',
    'pattern': r'åœŸè€³å…¶|TR|Turkey|ä¼Šæ–¯å¦å¸ƒå°”|Istanbul'
}
}
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')
BJ_TZ = timezone(timedelta(hours=8))

def do_speed_test():
    if not ENABLE_SPEED_TEST:
        print("æµ‹é€ŸåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡ã€‚")
        return
    # å¯ç”¨æµ‹é€Ÿå¹¶æ‰“å°æ—¥å¿—
    run_speedtest(enable_tcp_log=False)

def get_country_flag_emoji(code):
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)

def preprocess_regex_rules():
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )

def load_existing_proxies_and_state():
    existing_proxies = []
    last_message_ids = {}
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict):
                    existing_proxies = loaded_yaml.get('proxies', [])
                    if not isinstance(existing_proxies, list):
                        existing_proxies = []
                    last_message_ids = loaded_yaml.get('last_message_ids', {})
                    if not isinstance(last_message_ids, dict):
                        last_message_ids = {}
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
        except Exception as e:
            print(f"è¯»å– {OUTPUT_FILE} å¤±è´¥: {e}")
    return existing_proxies, last_message_ids

def extract_valid_subscribe_links(text):
    MIN_HOURS_LEFT = MIN_EXPIRE_HOURS
    link_pattern = re.compile(
        r'(?:è®¢é˜…é“¾æ¥|è®¢é˜…åœ°å€|è®¢é˜…|é“¾æ¥)[\s:ï¼š`]*?(https?://[A-Za-z0-9\-._~:/?#[\]@!$&\'()*+,;=%]+)'
    )
    expire_patterns = [
        r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¯¥è®¢é˜…å°†äº(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})(?:\s*\+\d{4}\s*[A-Za-z]{3})?è¿‡æœŸ',
        r'è¿‡æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'åˆ°æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'è¯¥è®¢é˜…å°†äºæœªçŸ¥è¿‡æœŸ',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*é•¿æœŸæœ‰æ•ˆ',
        r'è¿‡æœŸ[:ï¼š]\s*æœªçŸ¥/æ— é™',
    ]
    text_single_line = text.replace('\n', ' ')
    expire_time = None
    for patt in expire_patterns:
        match = re.search(patt, text_single_line)
        if match:
            if 'æœªçŸ¥' in match.group(0) or 'é•¿æœŸæœ‰æ•ˆ' in match.group(0) or 'æ— é™' in match.group(0):
                expire_time = None
                break
            if match.lastindex:
                dt_str = match.group(1)
                fmt_candidates = ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%Y-%m-%d', '%Y/%m/%d']
                for fmt in fmt_candidates:
                    try:
                        dt = datetime.strptime(dt_str, fmt)
                        if fmt in ('%Y-%m-%d', '%Y/%m/%d'):
                            dt = dt.replace(hour=23, minute=59, second=59)
                        expire_time = dt.replace(tzinfo=BJ_TZ)
                        break
                    except Exception:
                        continue
            break
    now = datetime.now(BJ_TZ)
    valid_links = []
    links = link_pattern.findall(text)
    for url in links:
        if expire_time is not None:
            hours_left = (expire_time - now).total_seconds() / 3600
            if hours_left < MIN_HOURS_LEFT:
                continue
        valid_links.append(url)
    return valid_links

# ==========================
# æ›¿æ¢äº† scrape_telegram_links ä¸º B ç‰ˆæœ¬æ›´å®Œå–„çš„å®ç°
async def scrape_telegram_links(last_message_ids=None):
    if last_message_ids is None:
        last_message_ids = {}
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return [], last_message_ids
    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n')
                       if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return [], last_message_ids
    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“: {TARGET_CHANNELS}")
    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return [], last_message_ids
    bj_now = datetime.now(BJ_TZ)
    target_time = (bj_now - timedelta(hours=TIME_WINDOW_HOURS)).astimezone(timezone.utc)
    all_links = set()
    for channel_id in TARGET_CHANNELS:
        print(f"\n ğŸ¯æ­£åœ¨å¤„ç†é¢‘é“: {channel_id} ...")
        try:
            entity = await client.get_entity(channel_id)
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•è·å–é¢‘é“å®ä½“ {channel_id}: {e}")
            continue
        last_id = last_message_ids.get(channel_id, 0)
        max_id_found = last_id
        try:
            async for message in client.iter_messages(entity, min_id=last_id + 1, reverse=False):
                if message.date < target_time:
                    break
                if message.text:
                    links = extract_valid_subscribe_links(message.text)
                    for link in links:
                        if link not in all_links:
                            all_links.add(link)
                            print(f"  âœ… æ‰¾åˆ°é“¾æ¥: {link[:70]}...")
                if message.id > max_id_found:
                    max_id_found = message.id
            last_message_ids[channel_id] = max_id_found
        except Exception as e:
            print(f"âŒ é”™è¯¯: ä»é¢‘é“ '{channel_id}' è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    await client.disconnect()
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links), last_message_ids

# --- B ç‰ˆæœ¬çš„ä¸‹è½½åŠè§£æç›¸å…³å‡½æ•°åˆå…¥ ---

def attempt_download_using_wget(url):
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ wget ä¸‹è½½: {url[:80]}...")
    if not shutil.which("wget"):
        print("  âœ— é”™è¯¯: wget æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œä¸‹è½½ã€‚")
        return None
    try:
        content = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        ).stdout
        return content if content else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget ä¸‹è½½å¤±è´¥: {e.stderr}")
        return None

def attempt_download_using_requests(url):
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ requests ä¸‹è½½: {url[:80]}...")
    try:
        headers = {'User-Agent': 'Clash'}
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'utf-8'
        return response.text
    except requests.RequestException as e:
        print(f"  âœ— requests ä¸‹è½½å¤±è´¥: {e}")
        return None

def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None

def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None

def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None

def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            # æ ‡å‡†æ ¼å¼: ss://method:password@server:port#remarks
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {'name': name, 'type': 'ss', 'server': server, 'port': port,
                    'cipher': method, 'password': password, 'udp': True}
            return node
        else:
            # base64æ ¼å¼ ss://base64(method:password@server:port) æˆ–å¸¦å¤‡æ³¨
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {'name': remark or f"ss_{server}", 'type': 'ss', 'server': server,
                    'port': int(port), 'cipher': method, 'password': password, 'udp': True}
            return node
    except Exception:
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        auth = parsed.username or ''
        obfs_password = params.get('obfs-password', [''])[0]
        insecure_val = params.get('insecure', ['false'])[0].lower()
        insecure = insecure_val in ('1', 'true', 'yes')
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': auth,
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': insecure,
            'obfs': params.get('obfs', [''])[0],
            'obfs-password': obfs_password,
            'udp': params.get('udp', ['true'])[0].lower() == 'true',
        }
        return node
    except Exception:
        return None

def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

def download_and_parse(url):
    # ç”¨ B ç‰ˆæœ¬çš„ä¸‹è½½è§£æé€»è¾‘æ›¿ä»£ A é‡ŒåŸ download_and_parse ä½“
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        print(f"  âŒ ä¸‹è½½å¤±è´¥: {url}")
        return []
    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  - ç›´æ¥ YAML è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies
    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  - æ˜æ–‡å†…å®¹è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies
    if is_base64(content):
        print(f"  - å†…å®¹ä¸º Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç è§£æ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        else:
            print(f"  - Base64 è§£ç æ— æœ‰æ•ˆèŠ‚ç‚¹")
            return []
    print(f"  - å†…å®¹ä¸ç¬¦åˆå·²çŸ¥æ ¼å¼ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
    return []

# --- ä¸‹é¢ä¿æŒåŸAç‰ˆæµ‹é€Ÿã€å»é‡ã€æ’åºç­‰é€»è¾‘ ---


def get_proxy_key(proxy):
    unique_part = proxy.get('uuid') or proxy.get('password') or ''
    return hashlib.md5(
        f"{proxy.get('server','')}:{proxy.get('port',0)}|{unique_part}".encode()
    ).hexdigest()

def is_valid_ss_cipher(cipher):
    """
    åˆ¤æ–­ssèŠ‚ç‚¹cipherå­—æ®µæ˜¯å¦åˆæ³•ï¼Œé¿å…è¢«é”™è¯¯çš„Base64æˆ–å…¶å®ƒå­—ç¬¦ä¸²æ±¡æŸ“ã€‚
    è¿™é‡Œåˆ—ä¸¾äº†Clashå¸¸è§æ”¯æŒçš„ssåŠ å¯†æ–¹æ³•ï¼Œå¿…è¦æ—¶ä½ å¯æ ¹æ®å®é™…å¢åŠ æˆ–ä¿®æ”¹ã€‚

    å‚æ•°:
        cipher (str): ssèŠ‚ç‚¹ä¸­cipherå­—æ®µ

    è¿”å›:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    if not cipher:
        return False
    valid_ciphers = {
        'aes-256-gcm', 'aes-128-gcm', 'chacha20-ietf-poly1305',
        'aes-256-cfb', 'aes-128-cfb', 'chacha20-ietf', 'xchacha20',
        'aes-128-ctr', 'aes-256-ctr', 'rc4-md5'
    }
    return cipher.lower() in valid_ciphers


def is_valid_proxy(proxy):
    """
    éªŒè¯ä»£ç†èŠ‚ç‚¹åŸºæœ¬å®Œæ•´æ€§å’Œå­—æ®µæœ‰æ•ˆæ€§ï¼Œå¢åŠ å¯¹ssåŠ å¯†æ–¹æ³•çš„å•ç‹¬éªŒè¯ã€‚

    å‚æ•°:
        proxy (dict): ä»£ç†èŠ‚ç‚¹å­—å…¸

    è¿”å›:
        bool: åˆæ³•ä¸ºTrueï¼Œå¦åˆ™False
    """
    if not isinstance(proxy, dict):
        return False
    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False

    allowed_types = {'http', 'socks5', 'trojan', 'vless', 'ss', 'vmess', 'ssr', 'hysteria', 'hysteria2'}
    if proxy['type'] not in allowed_types:
        return False

    port = proxy.get('port')
    if not isinstance(port, int) or not (1 <= port <= 65535):
        return False

    # SSåè®®ç‰¹æœ‰çš„åŠ å¯†æ–¹æ³•å­—æ®µæ£€æŸ¥ï¼Œç¡®ä¿ä¸ºæœ‰æ•ˆcipher
    if proxy['type'] == 'ss':
        cipher = proxy.get('cipher', '')
        if not is_valid_ss_cipher(cipher):
            if cipher:
                print(f"âš ï¸ æ— æ•ˆçš„ ss cipher: {cipher}ï¼ŒèŠ‚ç‚¹å: {proxy.get('name')}")
            return False

    return True

def identify_regions_only(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region:
            p['region_info'] = matched_region
            identified.append(p)
    return identified

def process_proxies(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region is None:
            continue
        if matched_region['name'] not in ALLOWED_REGIONS:
            continue
        p['region_info'] = matched_region
        identified.append(p)
    counters = defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    final = []
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name)
        feature = re.sub(r'\s+', ' ', clean_name).strip()
        if not feature:
            count = sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1
            feature = f"{info['code']}{count:02d}"
        base_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][base_name] += 1
        count_ = counters[info['name']][base_name]
        if count_ > 1:
            new_name = f"{base_name} {count_}"
        else:
            new_name = base_name
        p['name'] = new_name
        final.append(p)
    return final
#é”šç‚¹


# æ–°å¢çš„å›½å®¶ä»£ç  è½¬ ä¸­æ–‡åå­—å…¸ï¼Œæ–¹ä¾¿å¿«é€Ÿæ˜ å°„
COUNTRY_CODE_TO_CN = {
    v['code']: k for k, v in CUSTOM_REGEX_RULES.items()
}

def emoji_to_country_code(emoji):
    if len(emoji) != 2:
        return None
    try:
        # ä¸¤ä¸ªflag emojiçš„unicodeè§£ç æˆå›½å®¶ä»£ç 
        return ''.join(chr(ord(c) - 0x1F1E6 + ord('A')) for c in emoji)
    except:
        return None

FLAG_EMOJI_UN_FLAG ='ğŸ‡ºğŸ‡³'  # æ— å›½å®¶ç”¨è”åˆå›½ï¼ŒæŒ‰éœ€ä¿®æ”¹

def strip_starting_flags(s):
    """
    åå¤æ£€æµ‹å­—ç¬¦ä¸²å¼€å¤´æ˜¯å¦ä¸º2ä¸ªåŒºåŸŸç¬¦å·ç»„æˆçš„å›½æ——emojiï¼Œ
    è‹¥æ˜¯ï¼Œåˆ™å»é™¤ï¼Œç›´åˆ°å¼€å¤´æ— æ­¤å›½æ——emojiã€‚
    """
    def is_flag_emoji(substr):
        # åˆ¤æ–­ substr æ˜¯å¦ä¸¤ä¸ªunicodeå­—ç¬¦éƒ½ä½äºå›½æ——unicodeåŒºåŸŸ
        if len(substr) != 2:
            return False
        return all(0x1F1E6 <= ord(c) <= 0x1F1FF for c in substr)
    
    while len(s) >= 2 and is_flag_emoji(s[:2]):
        s = s[2:]
    return s.strip()

def normalize_proxy_names(proxies):
    pattern_trailing_number = re.compile(r'\s*\d+\s*$')
    normalized = []

    for p in proxies:
        name = p.get('name', '').strip()

        # ç”¨å¾ªç¯æ£€æµ‹æ¸…ç†å¼€å¤´æ‰€æœ‰å›½æ——emoji
        name = strip_starting_flags(name)

        # æ¸…ç†å°¾éƒ¨æ•°å­—åºå·
        name = pattern_trailing_number.sub('', name).strip()

        p['name'] = name

        # ä»¥ä¸‹ä¿æŒç°æœ‰é€»è¾‘ä¸å˜
        region_info = p.get('region_info', None)
        flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', name)
        flag_emoji = flag_match.group(0) if flag_match else None

        country_cn = None
        if region_info and 'name' in region_info and region_info['name'] in CUSTOM_REGEX_RULES:
            country_cn = region_info['name']
        elif flag_emoji:
            code = emoji_to_country_code(flag_emoji)
            if code and code in COUNTRY_CODE_TO_CN:
                country_cn = COUNTRY_CODE_TO_CN[code]
        if not country_cn:
            for cname, info in CUSTOM_REGEX_RULES.items():
                if re.search(info['pattern'], name, re.IGNORECASE):
                    country_cn = cname
                    break
        if not country_cn:
            short_name = name[:2] if len(name) >= 2 else name
            country_cn = short_name if short_name else "æœªçŸ¥"
            flag_emoji = FLAG_EMOJI_UN_FLAG
        if not flag_emoji:
            code = None
            for k, v in COUNTRY_CODE_TO_CN.items():
                if v == country_cn:
                    code = k
                    break
            flag_emoji = get_country_flag_emoji(code) if code else FLAG_EMOJI_UN_FLAG

        clean_name = country_cn
        p['_norm_flag'] = flag_emoji
        p['_norm_country'] = clean_name
        normalized.append(p)

    grouped = {}
    for p in normalized:
        country = p['_norm_country']
        grouped.setdefault(country, []).append(p)

    final_list = []
    for country, plist in grouped.items():
        for idx, p in enumerate(plist, 1):
            new_name = f"{p['_norm_flag']} {country} {idx}"
            p['name'] = new_name
            del p['_norm_flag']
            del p['_norm_country']
            final_list.append(p)

    return final_list

# ----


def limit_proxy_counts(proxies, max_total=600):
    """
    æ ¹æ®æŒ‡å®šè§„åˆ™é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼š
    - ['é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'] æ¯åŒºæœ€å¤š60ä¸ªï¼›
    - ['å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'] æ¯åŒºæœ€å¤š15ä¸ªï¼›
    - å…¶ä»–åœ°åŒº æ¯åŒºæœ€å¤š10ä¸ªï¼›
    å…¶ä½™åœ°åŒºæ•°é‡ä¸è¶³ç…§å¸¸ä¿ç•™ã€‚
    
    æ€»æ•° <= max_totalæ—¶ä¸é™åˆ¶ã€‚
    å…ˆæŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿæ— å€¼æ’åã€‚
    è¿”å›é™åˆ¶åçš„èŠ‚ç‚¹åˆ—è¡¨ã€‚
    """
    
    if len(proxies) <= max_total:
        return proxies

    limit_60 = {'é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'}
    limit_15 = {'å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'}

    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿç¼ºå¤±æŒ‰9999å¤„ç†
    proxies.sort(key=lambda p: p.get('clash_delay', 9999))

    grouped = defaultdict(list)
    for p in proxies:
        rname = p.get('region_info', {}).get('name') if p.get('region_info') else None
        grouped[rname].append(p)

    selected = []

    # å…ˆé€‰60é™åˆ¶åŒº
    for region in limit_60:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:60])

    # 15é™åˆ¶åŒº
    for region in limit_15:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:15])

    # å…¶ä»–åŒºåŸŸ
    other_regions = set(grouped.keys()) - limit_60 - limit_15 - {None}
    for region in other_regions:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:10])

    # å¯èƒ½æœ‰æ²¡æœ‰åœ°åŒºä¿¡æ¯çš„èŠ‚ç‚¹ï¼Œå…¨éƒ¨ä¿ç•™
    selected.extend(grouped.get(None, []))

    # å¦‚æœæ•°é‡ä»è¶…é™ï¼Œåˆ™æŒ‰å»¶è¿Ÿæ’åºæˆªæ–­
    if len(selected) > max_total:
        selected.sort(key=lambda p: p.get('clash_delay', 9999))
        selected = selected[:max_total]

    return selected


def generate_config(proxies, last_message_ids):
    return {
        'proxies': proxies,
        'last_message_ids': last_message_ids,
    }


#TCP æµ‹é€Ÿ,æµ‹é€Ÿé»˜è®¤å…³é—­
def run_speedtest(enable_tcp_log=False):
    cmd = ['./xcspeedtest', '--verbose']  # å…·ä½“å‚æ•°è§†ç‰ˆæœ¬è€Œå®š
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    while True:
        line = process.stdout.readline()
        if line == '' and process.poll() is not None:
            break
        if line:
            if 'TCP' in line:
                if enable_tcp_log:
                    print(line.strip())
                else:
                    # TCPæ—¥å¿—å…³é—­ ä¸æ‰“å°
                    pass
            else:
                print(line.strip())
                
    stderr_lines = process.stderr.read().splitlines()
    for line in stderr_lines:
        if 'TCP' in line:
            if enable_tcp_log:
                print(line.strip())
        else:
            print(line.strip())
    
    return process.poll()


def tcp_ping(proxy, timeout=TCP_TIMEOUT):
    """
    çº¯ TCP è¿æ¥æµ‹å»¶è¿Ÿï¼Œè¿”å›å»¶è¿Ÿï¼ˆmsï¼‰æˆ– None
    """
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    
    try:
        start = time.time()
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(timeout)
            s.connect((server, int(port)))
        delay_ms = int((time.time() - start) * 1000)
        # è¿‡æ»¤å¼‚å¸¸å€¼ï¼ˆ<1ms åŸºæœ¬æ˜¯å‡çš„ï¼‰
        if 1 < delay_ms <= 5000:
            return delay_ms
        else:
            return None
    except:
        return None
        

# é”šç‚¹

def test_proxy_with_clash(clash_path, proxy):
    delay = clash_test_proxy(clash_path, proxy)
    if delay is not None:
        proxy['clash_delay'] = delay
        return proxy
    return None



def batch_tcp_test(proxies, max_workers=TCP_MAX_WORKERS):
    """è¶…é«˜å¹¶å‘ TCP æµ‹é€Ÿ"""
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {executor.submit(tcp_ping, p): p for p in proxies}
        for future in as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            delay = future.result()
            if delay is not None and delay <= TCP_MAX_DELAY:
                proxy = proxy.copy()  # é¿å…ä¿®æ”¹åŸå­—å…¸
                proxy['tcp_delay'] = delay
                results.append(proxy)
                print(f"TCP PASS: {delay:4d}ms â†’ {proxy.get('name', '')[:40]}")
            else:
                if delay:
                    print(f"TCP SLOW: {delay:4d}ms â†’ ä¸¢å¼ƒ {proxy.get('name', '')[:40]}")
    return results

def batch_test_proxies_speedtest(speedtest_path, proxies, max_workers=32, debug=False):
    """
    ä½¿ç”¨ speedtest-clash æ‰¹é‡æµ‹è¯•ä»£ç†å»¶è¿Ÿã€‚
    :param speedtest_path: speedtest-clash äºŒè¿›åˆ¶è·¯å¾„
    :param proxies: ä»£ç†èŠ‚ç‚¹åˆ—è¡¨
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param debug: æ˜¯å¦æ‰“å°è¯¦ç»†æµ‹é€Ÿæ—¥å¿—
    :return: æµ‹é€ŸæˆåŠŸå¹¶å¸¦å»¶è¿Ÿå­—æ®µçš„ä»£ç†åˆ—è¡¨
    """
        
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(xcspeedtest_test_proxy, speedtest_path, proxy, debug): proxy
            for proxy in proxies
        }
        for future in concurrent.futures.as_completed(futures):
            proxy = futures[future]
            try:
                delay = future.result()
            except Exception as e:
                if debug:
                    print(f"[speedtest-clash] æµ‹é€Ÿå¼‚å¸¸: èŠ‚ç‚¹ {proxy.get('name')} é”™è¯¯: {e}")
                delay = None
            if delay is not None:
                pcopy = proxy.copy()
                pcopy['clash_delay'] = delay
                if debug:
                    print(f"[speedtest-clash] èŠ‚ç‚¹ {proxy.get('name')} æµ‹é€Ÿå»¶è¿Ÿ: {delay} ms")
                results.append(pcopy)
            else:
                if debug:
                    print(f"[speedtest-clash] èŠ‚ç‚¹ {proxy.get('name')} æµ‹é€Ÿå¤±è´¥æˆ–è¶…æ—¶")
    return results


# clash æµ‹é€Ÿ

def xcspeedtest_test_proxy(speedtest_path, proxy, debug=True):
    """
    ä½¿ç”¨ speedtest-clash äºŒè¿›åˆ¶ä»¥ -fast å‚æ•°æµ‹è¯•ä»£ç†å»¶è¿Ÿï¼ŒæˆåŠŸè¿”å›å»¶è¿Ÿ(ms)ï¼Œå¤±è´¥è¿”å›Noneã€‚
    debug=True æ—¶æ‰“å°æµ‹é€Ÿæ—¥å¿—å’Œå»¶è¿Ÿä¿¡æ¯ã€‚
    """
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            config_path = os.path.join(tmpdir, 'config.yaml')
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [{"name": "TESTGROUP", "type": "select", "proxies": [proxy["name"]]}],
                "rules": ["MATCH,DIRECT"]
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)

            cmd = [speedtest_path, '-c', config_path, '-fast']
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                    timeout=25, text=True)
            output = result.stdout + result.stderr

            if debug:
                print(f"[speedtest-clash æ—¥å¿—] è¾“å‡º:\n{output}")

            import re
            m = re.search(r"delay[:\s]*([0-9\.]+)\s*ms", output, re.I)
            if m:
                delay = int(float(m.group(1)))
                if debug:
                    print(f"[speedtest-clash æ—¥å¿—] ä»£ç† {proxy.get('name')} å»¶è¿Ÿ: {delay} ms")
                if 1 < delay < 800:
                    return delay

            # å¦‚æœæ²¡æ•è·åˆ° delay å…³é”®å­—ï¼Œåˆ™å°è¯•æŠ“å–æ‰€æœ‰åˆç†æ•°å­—æœ€å°çš„ä½œä¸ºå¤‡ç”¨
            delays = re.findall(r'(\d+)', output)
            delays = [int(d) for d in delays if 1 < int(d) < 800]
            if delays:
                delay = min(delays)
                if debug:
                    print(f"[speedtest-clash æ—¥å¿—] ä»£ç† {proxy.get('name')} æ›¿ä»£å»¶è¿Ÿ: {delay} ms")
                return delay

    except Exception as e:
        if debug:
            print(f"[speedtest-clash æ—¥å¿—] æµ‹é€Ÿå¼‚å¸¸: {e}")
    return None



def clash_test_proxy(clash_path, proxy, debug=False):
    temp_dir = tempfile.mkdtemp()
    config_path = os.path.join(temp_dir, 'config.yaml')
    try:
        for test_url in TEST_URLS:
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [{"name": "TESTGROUP", "type": "select", "proxies": [proxy["name"]]}],
                "rules": [f"DOMAIN,{urlparse(test_url).netloc},TESTGROUP", "MATCH,DIRECT"]
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)
            cmd = [clash_path, '-c', config_path, '-fast']
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=22,
                text=True
            )
            output = (result.stdout + result.stderr).replace('\x00', '')
            if debug:
                print(f"\n=== [-fast] æµ‹è¯• URL: {test_url} [{proxy['name']}] ===\n{output}\n{'='*60}")
            # è§£æå»¶è¿Ÿï¼Œé€»è¾‘åŒä¹‹å‰
            match = re.search(r'\b(\d+)ms\b(?=\s*$)', output, re.MULTILINE)
            if match:
                delay = int(match.group(1))
                if 1 < delay < 800:
                    if debug:
                        print(f"æˆåŠŸæŠ“åˆ°å»¶è¿Ÿ: {delay}ms â†’ ä¿ç•™")
                    return delay
            delays = re.findall(r'\b([2-9]\d{1,3})\b', output)
            if delays:
                delay = min(int(x) for x in delays if int(x) < 800)
                if delay > 1:
                    return delay
            if re.search(r'\b(0\s*ms|1\s*ms|NA)\b', output, re.I):
                if debug:
                    print("æ£€æµ‹åˆ° 0ms/1ms/NA â†’ ä¸¢å¼ƒ")
                return None
        # æ‰€æœ‰æµ‹é€Ÿåœ°å€éƒ½æ— ç»“æœæ—¶è¿”å› None
        if debug:
            print(f"æ‰€æœ‰æµ‹é€Ÿåœ°å€å‡æœªé€šè¿‡ â†’ ä¸¢å¼ƒ: {proxy['name']}")
    except subprocess.TimeoutExpired:
        if debug:
            print(f"[-fast] æµ‹é€Ÿè¶…æ—¶ â†’ ä¸¢å¼ƒ: {proxy['name']}")
    except Exception as e:
        if debug:
            print(f"[-fast] å¼‚å¸¸: {proxy['name']} â†’ {e}")
    finally:
        try:
            shutil.rmtree(temp_dir)
        except:
            pass
    return None




# ä¸»å‡½æ•°
async def main():
    print("=" * 60)
    print("Telegram.Node_Clash-Speedtestæµ‹è¯•ç‰ˆ V1")
    print(datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)

    preprocess_regex_rules()

    print("[1/5] åŠ è½½åŸæœ‰èŠ‚ç‚¹å’ŒæŠ“å–çŠ¶æ€")
    existing_proxies, last_message_ids = load_existing_proxies_and_state()
    print(f"å·²æœ‰èŠ‚ç‚¹æ•°: {len(existing_proxies)}")

    print("[2/5] æŠ“å– Telegram æ–°è®¢é˜…é“¾æ¥")
    urls, last_message_ids = await scrape_telegram_links(last_message_ids)
    new_proxies = []
    if urls:
        print(f"æŠ“å–åˆ° {len(urls)} ä¸ªè®¢é˜…é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½è§£æ...")
        for url in urls:
            proxies = download_and_parse(url)
            if proxies:
                new_proxies.extend(proxies)
    print(f"æ–°å¢èŠ‚ç‚¹æ•°: {len(new_proxies)}")

    all_proxies_map = {
        get_proxy_key(p): p for p in existing_proxies if is_valid_proxy(p)
    }
    added_count = 0
    for p in new_proxies:
        key = get_proxy_key(p)
        if key not in all_proxies_map:
            all_proxies_map[key] = p
            added_count += 1
    print(f"åˆå¹¶å»é‡åæ€»èŠ‚ç‚¹æ•°: {len(all_proxies_map)}ï¼Œæ–°å¢æœ‰æ•ˆèŠ‚ç‚¹: {added_count}")

    all_nodes = list(all_proxies_map.values())
    if not all_nodes:
        sys.exit("âŒ æ— ä»»ä½•èŠ‚ç‚¹å¯ç”¨ï¼Œç¨‹åºé€€å‡º")
        

    # [3/5] å¼€å§‹èŠ‚ç‚¹æµ‹é€Ÿï¼ˆæ”¯æŒå¤šç§æ¨¡å¼ï¼‰
    print("[3/5] å¼€å§‹èŠ‚ç‚¹æµ‹é€Ÿï¼ˆæ¨¡å¼: %sï¼‰" % SPEEDTEST_MODE)
    clash_path = 'clash_core/clash'
    need_clash = 'clash' in SPEEDTEST_MODE
    if need_clash and not (os.path.isfile(clash_path) and os.access(clash_path, os.X_OK)):
        sys.exit(f"clash æ ¸å¿ƒç¼ºå¤±æˆ–ä¸å¯æ‰§è¡Œ: {clash_path}")

    final_tested_nodes = all_nodes.copy()
    clash_path = './xcspeedtest'  # ä½ çš„ speedtest-clash äºŒè¿›åˆ¶çš„è·¯å¾„

    if SPEEDTEST_MODE == "tcp_only":
        print("ä½¿ç”¨ã€çº¯ TCP æµ‹é€Ÿã€‘æ¨¡å¼")
        final_tested_nodes = batch_tcp_test(all_nodes)
    elif SPEEDTEST_MODE == "clash_only":
        print("ä½¿ç”¨ã€çº¯ speedtest-clash æµ‹é€Ÿã€‘æ¨¡å¼")
        final_tested_nodes = batch_test_proxies_speedtest(
            clash_path,
            all_nodes,
            max_workers=MAX_TEST_WORKERS,
            debug=ENABLE_SPEEDTEST_LOG
        )
    elif SPEEDTEST_MODE == "tcp_first":
        print("ä½¿ç”¨ã€TCP ç²—ç­› â†’ speedtest-clash ç²¾æµ‹ã€‘ä¸¤é˜¶æ®µæ¨¡å¼")
        print("é˜¶æ®µ1ï¼šTCP è¶…é«˜å¹¶å‘ç²—ç­›...")
        tcp_passed = batch_tcp_test(all_nodes)
        print(f"TCP ç²—ç­›å®Œæˆï¼š{len(all_nodes)} â†’ {len(tcp_passed)}")
        if not tcp_passed:
            print("TCP å…¨æ­»ï¼Œé™çº§ä½¿ç”¨çº¯ speedtest-clash æ¨¡å¼")
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                all_nodes,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
        else:
            print("é˜¶æ®µ2ï¼šå¯¹ TCP å­˜æ´»èŠ‚ç‚¹è¿›è¡Œ speedtest-clash ç²¾å‡†æµ‹é€Ÿ...")
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                tcp_passed,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
    elif SPEEDTEST_MODE == "clash_first":
        print("ä½¿ç”¨ã€speedtest-clash å…ˆæµ‹ â†’ TCP åéªŒã€‘æ¨¡å¼")
        clash_passed = batch_test_proxies_speedtest(
            clash_path,
            all_nodes,
            max_workers=MAX_TEST_WORKERS,
            debug=ENABLE_SPEEDTEST_LOG
        )
        final_tested_nodes = [p for p in clash_passed if tcp_ping(p) is not None]
    else:
        print("æœªçŸ¥æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤ tcp_first")
        tcp_passed = batch_tcp_test(all_nodes)
        if not tcp_passed:
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                all_nodes,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
        else:
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                tcp_passed,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )

    # æµ‹é€Ÿç»“æœç»Ÿè®¡
    success_count = len(final_tested_nodes)
    print(f"æµ‹é€Ÿå®Œæˆï¼Œæœ€ç»ˆå­˜æ´»ä¼˜è´¨èŠ‚ç‚¹ï¼š{success_count} ä¸ª")

    # ä¿åº•å›é€€æœºåˆ¶
    if success_count == 0:
        print("æµ‹é€Ÿå…¨æ­»ï¼Œå¯åŠ¨ä¿åº•å›é€€ç­–ç•¥ï¼ˆçƒ­é—¨åœ°åŒºæœªæµ‹é€Ÿä¿ç•™ï¼‰")
        fallback_regions = [
            'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡',
            'ç¾å›½', 'éŸ©å›½', 'å¾·å›½', 'è‹±å›½', 'åŠ æ‹¿å¤§'
        ]
        candidates = identify_regions_only(all_nodes)
        selected = []
        grouped = defaultdict(list)
        for p in candidates:
            region = p.get('region_info', {}).get('name')
            if region in fallback_regions:
                grouped[region].append(p)
        for r in fallback_regions:
            selected.extend(grouped[r][:30])
        final_tested_nodes = selected[:500]
        print(f"å›é€€ä¿ç•™ {len(final_tested_nodes)} ä¸ªçƒ­é—¨åœ°åŒºèŠ‚ç‚¹ï¼ˆæœªæµ‹é€Ÿï¼‰")

    # [4/5] èŠ‚ç‚¹åç§°ç»Ÿä¸€è§„èŒƒåŒ–å¤„ç†
    print("[4/5] èŠ‚ç‚¹åç§°ç»Ÿä¸€è§„èŒƒåŒ–å¤„ç†")
    normalized_proxies = normalize_proxy_names(final_tested_nodes)
    final_proxies = limit_proxy_counts(normalized_proxies, max_total=600)
    if not final_proxies:
        sys.exit("âŒ èŠ‚ç‚¹é‡å‘½åå’Œé™é‡åæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")

    # [5/5] æœ€ç»ˆæ’åºå¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶
    print("[5/5] æœ€ç»ˆæ’åºå¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶")
    final_proxies.sort(
        key=lambda p: (
            REGION_PRIORITY.index(p['region_info']['name']) if p.get('region_info') and p['region_info']['name'] in REGION_PRIORITY else 99,
            p.get('clash_delay', p.get('tcp_delay', 9999))
        )
    )

    total_count = len(final_proxies)
    update_time = datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S")

    final_config = {
        'proxies': final_proxies,
        'last_message_ids': last_message_ids,
        'update_time': update_time,
        'total_nodes': total_count,
        'note': 'ç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆï¼Œæ¯4å°æ—¶æ›´æ–°ä¸€æ¬¡ï¼Œå·²æŒ‰å»¶è¿Ÿæ’åºå¹¶æ™ºèƒ½é™é‡'
    }

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(f"# TGé¢‘é“èŠ‚ç‚¹è‡ªåŠ¨æŠ“å–+æµ‹å»¶è¿Ÿç²¾é€‰è®¢é˜…\n")
            f.write(f"# æœ€åæ›´æ–°æ—¶é—´ï¼š{update_time} (åŒ—äº¬æ—¶é—´)\n")
            f.write(f"# æœ¬æ¬¡ä¿ç•™èŠ‚ç‚¹æ•°ï¼š{total_count} ä¸ªï¼ˆå»¶è¿Ÿæœ€ä¼˜ï¼‰\n")
            f.write(f"# ç”± GitHub Actions è‡ªåŠ¨æ„å»ºï¼\n\n")
            yaml.dump(final_config, f, allow_unicode=True, sort_keys=False, indent=2, width=4096)
        print(f"âœ… é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³ {OUTPUT_FILE}")
        print(f"   æœ¬æ¬¡å…±ä¿ç•™ {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
        print(f"   æ›´æ–°æ—¶é—´ï¼š{update_time}")
        print("ğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ å†™å‡ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

def main():
    if not ENABLE_SPEED_TEST:
        print("æµ‹é€ŸåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æµ‹é€Ÿã€‚")
        return
    
    ret = run_speedtest(enable_tcp_log=ENABLE_TCP_LOG)
    print(f"æµ‹é€Ÿè¿›ç¨‹è¿”å›ç ï¼š{ret}")   

if __name__ == "__main__":
    asyncio.run(main())
