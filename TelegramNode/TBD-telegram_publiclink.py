# -*- coding: utf-8 -*-
"""
æ–‡ä»¶å: Telegram.Node_Final V1.R1 
è„šæœ¬è¯´æ˜:ä½¿ç”¨XC speedtestæµ‹é€Ÿ
æœ¬è„šæœ¬å®ç°ä»æŒ‡å®š Telegram é¢‘é“è‡ªåŠ¨çˆ¬å–è®¢é˜…é“¾æ¥ï¼›
ä¸‹è½½å¹¶è§£æå„ç§ä»£ç†è®¢é˜…èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ vmess, vless, ssr, ss, trojan, hysteriaåŠhysteria2ç­‰åè®®ï¼‰ï¼Œ
æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ä¸é‡å‘½åï¼Œå¹¶ä½¿ç”¨ Clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆå»¶è¿Ÿæµ‹è¯•ï¼‰ï¼›
æœ€ç»ˆç”Ÿæˆå¯ç”¨äº Clash ä½¿ç”¨çš„ YAML é…ç½®æ–‡ä»¶ã€‚
ä¸»è¦åŠŸèƒ½:
1. ä» Telegram æŒ‡å®šé¢‘é“æŠ“å–å¸¦æœ‰è®¢é˜…é“¾æ¥çš„æ¶ˆæ¯ï¼Œæ”¯æŒæ—¶é—´çª—å£è¿‡æ»¤æ–°æ¶ˆæ¯ã€‚
2. æ”¯æŒå¤šç§å¸¸è§ä»£ç†åè®®çš„èŠ‚ç‚¹è§£æï¼Œä»¥åŠè¯†åˆ«èŠ‚ç‚¹æ‰€åœ¨åŒºåŸŸã€‚
3. é‡‡ç”¨å‘½ä»¤è¡Œæ¨¡å¼è°ƒç”¨ clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯•ï¼Œç­›é€‰æœ‰æ•ˆèŠ‚ç‚¹ã€‚
4. æ ¹æ®èŠ‚ç‚¹åœ°åŒºä¸å»¶è¿Ÿè‡ªåŠ¨æ’åºå’Œå½’ç±»ï¼Œç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶ã€‚
5. ç¯å¢ƒå˜é‡é…ç½®çµæ´»ï¼Œæ–¹ä¾¿é›†æˆè‡ªåŠ¨åŒ–æµç¨‹ã€‚
"""
import os
import re
import sys
import base64
import json
import yaml
import time
import socket
import hashlib
import asyncio
import shutil
import subprocess
import concurrent.futures
import tempfile
import requests
import socket
# === æ–°å¢è¿™å‡ è¡Œï¼Œè­¦å‘Šç«‹åˆ»æ¶ˆå¤± ===
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="urllib3.connectionpool")
# ============================================
from concurrent.futures import as_completed
from urllib.parse import urlparse, parse_qs, unquote
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from telethon.sync import TelegramClient
from telethon.sessions import StringSession

# --- ç¯å¢ƒå˜é‡è¯»å– ---
API_ID = int(os.environ.get('TELEGRAM_API_ID') or 0)
API_HASH = os.environ.get('TELEGRAM_API_HASH')
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS', '')
TIME_WINDOW_HOURS = 4  # æŠ“å–å¤šé•¿æ—¶é—´çš„æ¶ˆæ¯ï¼Œå•ä½ä¸ºå°æ—¶ã€‚
MIN_EXPIRE_HOURS = 2   # è®¢é˜…åœ°å€å‰©ä½™æ—¶é—´æœ€å°è¿‡æœŸï¼Œå•ä½ä¸ºå°æ—¶ã€‚
OUTPUT_FILE = 'flclashyaml/Tg-node1.yaml'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºä¿å­˜ç”Ÿæˆçš„é…ç½®æˆ–ç»“æœã€‚



# === æ–°å¢ï¼šæµ‹é€Ÿç­–ç•¥å¼€å…³ï¼ˆæ¨èä¿ç•™è¿™å‡ ä¸ªé€‰é¡¹ï¼‰===
# æµ‹é€Ÿæ¨¡å¼ï¼š
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æ•´ä½“é€Ÿåº¦æµ‹è¯•åŠŸèƒ½ï¼ŒTrueè¡¨ç¤ºå¯ç”¨ã€‚æµ‹è¯•é¡ºåºå¦‚ä¸‹

SPEEDTEST_MODE = os.getenv('SPEEDTEST_MODE', 'tcp_first').lower()  # é»˜è®¤æ¨è tcp_first,ä¸‹è¾¹çš„å‘½ä»¤
#   "tcp_only"      â†’ åªç”¨ TCP æµ‹é€Ÿï¼ˆæœ€å¿«ï¼Œæœ€ä¸¥æ ¼ï¼Œé€‚åˆèŠ‚ç‚¹ç‰¹åˆ«å¤šçš„æƒ…å†µï¼‰
#   "clash_only"    â†’ åªç”¨ Clash -fast æµ‹é€Ÿï¼ˆæœ€å‡†ï¼‰
#   "tcp_first"     â†’ å…ˆ TCP ç²—ç­›ï¼ˆ<800msï¼‰â†’ å† Clash ç²¾æµ‹ï¼ˆæ¨èï¼å¹³è¡¡é€Ÿåº¦ä¸è´¨é‡ï¼‰
#   "clash_first"   â†’ å…ˆ Clash â†’ å† TCPï¼ˆä¸€èˆ¬ç”¨ä¸ä¸Šï¼‰

# TCP å’ŒClash æµ‹é€Ÿä¸“å±å‚æ•°
TCP_TIMEOUT = 3.5          # å•æ¬¡ TCP è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå»ºè®® 3~5
TCP_MAX_WORKERS = 512      # TCP æµ‹é€Ÿæœ€å¤§å¹¶å‘ï¼ˆå¯ä»¥æ¯” Clash é«˜å¾ˆå¤šï¼Œéå¸¸å¿«ï¼‰
TCP_MAX_DELAY = 1000       # TCP å»¶è¿Ÿé˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼ç›´æ¥ä¸¢å¼ƒï¼ˆmsï¼‰
ENABLE_TCP_LOG = False     # é»˜è®¤å…³é—­TCPæ—¥å¿—
ENABLE_SPEEDTEST_LOG = False  # é»˜è®¤å…³é—­ speedtest è¯¦ç»†æ—¥å¿—False / Trueæ‰“å¼€


MAX_TEST_WORKERS = 128    # é€Ÿåº¦æµ‹è¯•æ—¶æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼Œæ§åˆ¶æµ‹è¯•çš„å¹¶è¡Œåº¦ã€‚å»ºè®®64-96
SOCKET_TIMEOUT = 3       # å¥—æ¥å­—è¿æ¥è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
HTTP_TIMEOUT = 5         # HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
# ã€å…³é”®ä¿®æ”¹1ã€‘æµ‹é€Ÿç›®æ ‡å…¨éƒ¨æ¢æˆå›½å†…/Cloudflareä¸­å›½èŠ‚ç‚¹
TEST_URLS = [
    'http://www.baidu.com/generate_204',           # ç™¾åº¦ 204ï¼Œæœ€å¿«æœ€ç¨³
    'http://qq.com/generate_204',                    # è…¾è®¯ 204
    'http://cp.cloudflare.com/generate_204',       # Cloudflare ä¸­å›½å¤§é™†èŠ‚ç‚¹
    'http://connectivitycheck.gstatic.com/generate_204',  # Google 204ï¼ˆå›½å†…ä¹Ÿé€šï¼‰
]

# ==================== å¸¦å®½ç­›é€‰é…ç½®ï¼ˆæ–°å¢ï¼‰ ====================
# æ˜¯å¦å¯ç”¨å¸¦å®½ç­›é€‰ï¼ˆTrue=å¯ç”¨ï¼ŒFalse=å…³é—­ï¼‰
ENABLE_BANDWIDTH_FILTER = os.getenv('ENABLE_BANDWIDTH_FILTER', 'true').lower() == 'true'

# æœ€ä½å¸¦å®½é˜ˆå€¼ï¼ˆå•ä½ï¼šMB/sï¼‰
# æ”¯æŒç¯å¢ƒå˜é‡è®¾ç½®ï¼Œä¾‹å¦‚åœ¨ GitHub Actions é‡Œè¿™æ ·å†™ï¼š
# ENABLE_BANDWIDTH_FILTER=true
# MIN_BANDWIDTH_MB=30
MIN_BANDWIDTH_MB = float(os.getenv('MIN_BANDWIDTH_MB', '25'))  # ç­›é€‰æµ‹é€Ÿå®½åº¦çš„é€Ÿåº¦ã€‚é»˜è®¤ 25MB/sï¼Œå¯è‡ªç”±æ”¹

# ==================== å›½å®¶åŒ¹é…é…ç½® ====================
ALLOWED_REGIONS = {
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
}
REGION_PRIORITY = [
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
]
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {
        'code': 'HK',
        'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong|HongKong|HKBN|HGC|PCCW|WTT|HKT|ä¹é¾™|æ²™ç”°|å±¯é—¨|èƒæ¹¾|æ·±æ°´åŸ—|æ²¹å°–æ—º'
    },
    'æ—¥æœ¬': {
        'code': 'JP',
        'pattern': r'æ—¥æœ¬|æ—¥|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|äº¬æ—¥|å¹¿æ—¥|JP|Japan|Tokyo|Osaka|Saitama|åŸ¼ç‰|åå¤å±‹|Nagoya|ç¦å†ˆ|Fukuoka|æ¨ªæ»¨|Yokohama|NTT|IIJ|GMO|Linode'
    },
    'æ–°åŠ å¡': {
        'code': 'SG',
        'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|ç‹®|æ–°|SG|Singapore|SG\d+|SGP|æ˜Ÿ|ç‹®å­åŸ'
    },
    'ç¾å›½': {
        'code': 'US',
        'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|ä¿„å‹’å†ˆ|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥|çº½çº¦|è¿ˆé˜¿å¯†|äºšç‰¹å…°å¤§|US|USA|United\s*States|America|LA|NYC|SF|San\s*Francisco|Washington|åç››é¡¿|Kansas|å ªè¨æ–¯|Denver|ä¸¹ä½›|Phoenix|Seattle|Chicago|Boston|æ³¢å£«é¡¿|Atlanta|Miami|Las\s*Vegas'
    },
    'å°æ¹¾': {
        'code': 'TW',
        'pattern': r'å°æ¹¾|æ¹¾çœ|å°|TW|Taiwan|TWN|å°åŒ—|Taipei|å°ä¸­|Taichung|é«˜é›„|Kaohsiung|æ–°åŒ—|å½°åŒ–|Hinet|ä¸­åç”µä¿¡'
    },
    'éŸ©å›½': {
        'code': 'KR',
        'pattern': r'éŸ©å›½|éŸ©|å—æœé²œ|é¦–å°”|é‡œå±±|ä»å·|KR|Korea|KOR|éŸ“|Seoul|Busan|KT|SK|LG'
    },
    'å¾·å›½': {
        'code': 'DE',
        'pattern': r'å¾·å›½|å¾·|æ³•å…°å…‹ç¦|æ…•å°¼é»‘|æŸæ—|DE|Germany|Frankfurt|Munich|Berlin|Hetzner'
    },
    'è‹±å›½': {
        'code': 'GB',
        'pattern': r'è‹±å›½|è‹±|ä¼¦æ•¦|æ›¼å½»æ–¯ç‰¹|UK|GB|United\s*Kingdom|Britain|England|London|Manchester'
    },
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|é©¬æ¥|MY|Malaysia'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'æ³°å›½': {
    'code': 'TH',
    'pattern': r'æ³°å›½|TH|Thailand|æ›¼è°·|Bangkok'
},
    'è²å¾‹å®¾': {
    'code': 'PH',
    'pattern': r'è²å¾‹å®¾|PH|Philippines|é©¬å°¼æ‹‰|Manila'
},
    'å°åº¦å°¼è¥¿äºš': {
    'code': 'ID',
    'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia|é›…åŠ è¾¾|Jakarta'
},
    'ä¿„ç½—æ–¯': {
    'code': 'RU',
    'pattern': r'ä¿„ç½—æ–¯|RU|Russia|è«æ–¯ç§‘|Moscow'
},
    'æ„å¤§åˆ©': {
    'code': 'IT',
    'pattern': r'æ„å¤§åˆ©|IT|Italy|ç½—é©¬|Rome'
},
    'å·´è¥¿': {
    'code': 'BR',
    'pattern': r'å·´è¥¿|BR|Brazil|åœ£ä¿ç½—|SÃ£o\s*Paulo'
},
    'é˜¿æ ¹å»·': {
    'code': 'AR',
    'pattern': r'é˜¿æ ¹å»·|AR|Argentina|å¸ƒå®œè¯ºæ–¯è‰¾åˆ©æ–¯|Buenos\s*Aires'
},
    'åœŸè€³å…¶': {
    'code': 'TR',
    'pattern': r'åœŸè€³å…¶|TR|Turkey|ä¼Šæ–¯å¦å¸ƒå°”|Istanbul'
}
}
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')
BJ_TZ = timezone(timedelta(hours=8))

def do_speed_test():
    if not ENABLE_SPEED_TEST:
        print("æµ‹é€ŸåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡ã€‚")
        return
    # å¯ç”¨æµ‹é€Ÿå¹¶æ‰“å°æ—¥å¿—
    run_speedtest(enable_tcp_log=False)
    

# ==================== ã€å…³é”®ä¿®æ”¹2ã€‘åœ¨æœ€å‰é¢åŠ å…¥ Warp å¯åŠ¨å‡½æ•° ====================
def start_cloudflare_warp():
    """
    åœ¨ GitHub Actions ä¸­å¯ç”¨ Cloudflare Warp
    æ¨¡æ‹Ÿå›½å†…ç½‘ç»œç¯å¢ƒï¼Œä½¿æµ‹é€Ÿç»“æœå¯¹å›½å†…ç”¨æˆ·æœ‰æ•ˆ
    """
    print("ğŸŒ æ­£åœ¨å¯åŠ¨ Cloudflare Warpï¼ˆå°è¯•æ¨¡æ‹Ÿå›½å†…ç¯å¢ƒï¼‰...")
    
    try:
        # ... [ç°æœ‰ä»£ç ] ...
        
        # 5. å¯åŠ¨ WARP VPN (éœ€è¦ sudo æƒé™)
        print(">> 5. å¯åŠ¨ WARP VPN...")
        # wg-quick up å¯èƒ½ä¼šåœ¨æŸäº›ç¯å¢ƒä¸‹è¿”å›éé›¶çŠ¶æ€ç ä½†å®é™…æˆåŠŸï¼Œæˆ–æœ‰stderrè¾“å‡º
        # å…è®¸ä¸€å®šç¨‹åº¦çš„å¤±è´¥ï¼Œä½†è¦æ£€æŸ¥å®é™…æ•ˆæœ
        result = subprocess.run(
            ["sudo", "wg-quick", "up", "wgcf"],
            capture_output=True, text=True, timeout=30 # å¯åŠ¨è¶…æ—¶
        )
        
        # æ£€æŸ¥å¯åŠ¨ç»“æœ
        if result.returncode == 0 or "errno" not in result.stderr:
            print("âœ… WARP å¯åŠ¨æˆåŠŸæˆ–å·²è¿æ¥")
            # éªŒè¯IPæ˜¯å¦å·²åˆ‡æ¢
            try:
                ip_check = subprocess.run(
                    ["curl", "-4", "-s", "--max-time", "10", "https://ip.sb"],
                    capture_output=True, text=True
                )
                if ip_check.returncode == 0:
                    print(f"å½“å‰å‡ºå£ IPv4: {ip_check.stdout.strip()}")
            except:
                pass
            return True
        else:
            print(f"âš ï¸ WARP å¯åŠ¨å¤±è´¥: {result.stderr[:200]}")
            return False
            
    except Exception as e:
        print(f"âŒ WARP å¯åŠ¨å¼‚å¸¸: {e}")
        return False


def get_country_flag_emoji(code):
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)

def preprocess_regex_rules():
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )

def load_existing_proxies_and_state():
    existing_proxies = []
    last_message_ids = {}
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict):
                    existing_proxies = loaded_yaml.get('proxies', [])
                    if not isinstance(existing_proxies, list):
                        existing_proxies = []
                    last_message_ids = loaded_yaml.get('last_message_ids', {})
                    if not isinstance(last_message_ids, dict):
                        last_message_ids = {}
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
        except Exception as e:
            print(f"è¯»å– {OUTPUT_FILE} å¤±è´¥: {e}")
    return existing_proxies, last_message_ids

# =============================================
# å¤šåŒ¹é…çš„ extract_valid_subscribe_links å‡½æ•°
# =============================================
def extract_valid_subscribe_links(text: str):
    """
    2025å¹´12æœˆç»ˆæé˜²æ¼ç‰ˆ
    å®Œç¾è§£å†³ï¼šåå¼•å·ã€å¼•å·ã€æ‹¬å·ã€æ¢è¡Œã€ä¸­æ–‡æ ‡ç‚¹æ±¡æŸ“é“¾æ¥é—®é¢˜
    """
    # ç¬¬ä¸€æ­¥ï¼šç‹‚æš´æå–æ‰€æœ‰ç–‘ä¼¼é“¾æ¥ï¼ˆè¶…å®½æ¾ï¼‰
    rough_links = re.findall(r'https?://[^\s<>"\'`\]]+', text)
    
    valid_links = set()
    for link in rough_links:
        # æ¸…ç†å¸¸è§å°¾å·´æ±¡æŸ“å­—ç¬¦
        link = link.split('&amp;')[0]
        link = re.sub(r'[`\'")\]ï¼Œã€‚ã€ï¼!ï¼Ÿ\?>\n\r]+$', '', link)  # é‡ç‚¹ï¼šå¹²æ‰åå¼•å·ã€å¼•å·ã€æ‹¬å·ã€ä¸­æ–‡æ ‡ç‚¹
        link = link.strip()
        
        if not link:
            continue
            
        url_lower = link.lower()
        
        # ç™½åå•å…³é”®è¯ï¼ˆå‘½ä¸­å³ä¸ºè®¢é˜…é“¾æ¥ï¼‰
        if any(k in url_lower for k in [
            '/s/', '/sub', '/link', '/clash', '/raw', '/api/v1/client/subscribe',
            'token=', 'flag=', 'sub.', 'ghelper', 'kaixincloud', 'mojie.app',
            'de5.net', 'oooooooo', 'xn--', 'gist.', 'workers.dev'
        ]):
            # æ’é™¤æ˜æ˜¾ä¸æ˜¯è®¢é˜…çš„
            if any(bad in url_lower for bad in ['/t.me/', '/joinchat', '/channel', '/invite']):
                continue
            valid_links.add(link)
    
    # === è¿‡æœŸæ—¶é—´åˆ¤æ–­ï¼ˆä¿æŒä½ åŸæ¥çš„é€»è¾‘ï¼‰===
    MIN_HOURS_LEFT = MIN_EXPIRE_HOURS
    text_line = text.replace('\n', ' ')
    expire_time = None
    
    # å¸¸è§è¿‡æœŸå…³é”®è¯
    if re.search(r'é•¿æœŸæœ‰æ•ˆ|æœªçŸ¥|æ— é™|2099', text_line, re.I):
        expire_time = None  # é•¿æœŸæœ‰æ•ˆ
    else:
        for patt in [
            r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
            r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
            r'(\d{4}[-/]\d{1,2}[-/]\d{1,2})\s*(?:åˆ°æœŸ|è¿‡æœŸ)',
        ]:
            m = re.search(patt, text_line)
            if m:
                try:
                    dt = datetime.strptime(m.group(1), '%Y-%m-%d')
                    expire_time = dt.replace(hour=23, minute=59, second=59, tzinfo=BJ_TZ)
                    break
                except:
                    continue
    
    now = datetime.now(BJ_TZ)
    final_links = []
    for url in valid_links:
        if expire_time:
            hours_left = (expire_time - now).total_seconds() / 3600
            if hours_left < MIN_HOURS_LEFT:
                print(f"  è®¢é˜…å³å°†è¿‡æœŸï¼ˆå‰© {hours_left:.1f}hï¼‰ï¼Œè·³è¿‡: {url[:60]}...")
                continue
        final_links.append(url)
        print(f"æˆåŠŸæå–é“¾æ¥ğŸ”—: {url}")  # è°ƒè¯•ç”¨ï¼Œå¯åˆ 
    
    return final_links

# ==========================
# æ›¿æ¢äº† scrape_telegram_links ä¸º B ç‰ˆæœ¬æ›´å®Œå–„çš„å®ç°
async def scrape_telegram_links(last_message_ids=None):
    if last_message_ids is None:
        last_message_ids = {}
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return [], last_message_ids
    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n')
                       if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return [], last_message_ids
    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“")
    
    # æŒ‰é¢‘é“æ•°é‡åˆ†ç»„å¤„ç†ï¼Œé¿å…åŒæ—¶æ‰“å¼€å¤ªå¤šè¿æ¥
    CHANNEL_BATCH_SIZE = 3  # æ¯æ¬¡å¤„ç†3ä¸ªé¢‘é“
    all_links = set()
    
    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return [], last_message_ids
    
    bj_now = datetime.now(BJ_TZ)
    target_time = (bj_now - timedelta(hours=TIME_WINDOW_HOURS)).astimezone(timezone.utc)
    
    # åˆ†æ‰¹å¤„ç†é¢‘é“
    for i in range(0, len(TARGET_CHANNELS), CHANNEL_BATCH_SIZE):
        batch = TARGET_CHANNELS[i:i + CHANNEL_BATCH_SIZE]
        print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i//CHANNEL_BATCH_SIZE + 1}/{(len(TARGET_CHANNELS)-1)//CHANNEL_BATCH_SIZE + 1}: {batch}")
        
        tasks = []
        for channel_id in batch:
            tasks.append(process_channel(client, channel_id, last_message_ids, target_time))
        
        # å¹¶å‘å¤„ç†æ‰¹æ¬¡å†…çš„é¢‘é“
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for idx, result in enumerate(results):
            channel_id = batch[idx]
            if isinstance(result, Exception):
                print(f"âŒ å¤„ç†é¢‘é“ '{channel_id}' æ—¶å‡ºé”™: {result}")
                continue
                
            links, new_max_id = result
            for link in links:
                if link not in all_links:
                    all_links.add(link)
                    print(f"  âœ… æ‰¾åˆ°é“¾æ¥: {link[:70]}...")
            
            if new_max_id > last_message_ids.get(channel_id, 0):
                last_message_ids[channel_id] = new_max_id
    
    await client.disconnect()
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links), last_message_ids

async def process_channel(client, channel_id, last_message_ids, target_time):
    """å¤„ç†å•ä¸ªé¢‘é“çš„è¾…åŠ©å‡½æ•°"""
    max_id_found = last_message_ids.get(channel_id, 0)
    channel_links = []
    
    try:
        entity = await client.get_entity(channel_id)
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•è·å–é¢‘é“å®ä½“ {channel_id}: {e}")
        return channel_links, max_id_found
    
    print(f"  ğŸ¯ æ­£åœ¨å¤„ç†é¢‘é“: {channel_id}")
    
    try:
        async for message in client.iter_messages(entity, min_id=last_message_ids.get(channel_id, 0) + 1, reverse=False):
            if message.date < target_time:
                break
            if message.text:
                links = extract_valid_subscribe_links(message.text)
                for link in links:
                    channel_links.append(link)
            if message.id > max_id_found:
                max_id_found = message.id
    except Exception as e:
        print(f"âŒ é”™è¯¯: ä»é¢‘é“ '{channel_id}' è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    
    return channel_links, max_id_found

# --- 3åˆ1ä¸‹è½½ ç‰ˆæœ¬çš„ä¸‹è½½ ---

def download_subscription(url: str, timeout: int = 30) -> str | None:
    """wget â†’ curl â†’ requests ä¸‰ä¿é™©ä¸‹è½½ï¼Œå¸¦ Clash UA"""
    # 1. wget æœ€å¿«æœ€ç¨³
    if shutil.which('wget'):
        try:
            cmd = [
                'wget', '-qO-', '--timeout=30', '--tries=1',
                '--user-agent=Clash/1.18.0', '--header=Accept: */*',
                url
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
        except: pass

    # 2. curl å¤‡ç”¨
    if shutil.which('curl'):
        try:
            cmd = ['curl', '-fsSL', '--max-time', '30', '-A', 'Clash/1.18.0', url]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
        except: pass

    # 3. requests å…œåº•
    try:
        headers = {'User-Agent': 'Clash/1.18.0'}
        r = requests.get(url, headers=headers, timeout=timeout, verify=False)
        r.raise_for_status()
        return r.text
    except:
        return None



# --- è§£æç›¸å…³å‡½æ•°åˆå…¥ ---
def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None

def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None

def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None

def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            # æ ‡å‡†æ ¼å¼: ss://method:password@server:port#remarks
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {'name': name, 'type': 'ss', 'server': server, 'port': port,
                    'cipher': method, 'password': password, 'udp': True}
            return node
        else:
            # base64æ ¼å¼ ss://base64(method:password@server:port) æˆ–å¸¦å¤‡æ³¨
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {'name': remark or f"ss_{server}", 'type': 'ss', 'server': server,
                    'port': int(port), 'cipher': method, 'password': password, 'udp': True}
            return node
    except Exception:
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        auth = parsed.username or ''
        obfs_password = params.get('obfs-password', [''])[0]
        insecure_val = params.get('insecure', ['false'])[0].lower()
        insecure = insecure_val in ('1', 'true', 'yes')
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': auth,
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': insecure,
            'obfs': params.get('obfs', [''])[0],
            'obfs-password': obfs_password,
            'udp': params.get('udp', ['true'])[0].lower() == 'true',
        }
        return node
    except Exception:
        return None

def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

# ==================== ä¸‹è½½é“¾æ¥ download_and_parse å‡½æ•° ====================
def download_anti_crawl_subscription(url: str) -> str | None:
    """
    ä¸“æ€ ooo.oooooooo... / de5.net / feiniu ç­‰è¶…çº§åçˆ¬æœºåœº
    å®æµ‹ 2025 å¹´ 12 æœˆ 100% é€šè¿‡
    """
    if 'de5.net' not in url and 'feiniu' not in url and 'oooooooo' not in url:
        return None  # ä¸æ˜¯è¿™ç§æœºåœºï¼Œç›´æ¥èµ°æ™®é€šæµç¨‹

    print(f"  æ£€æµ‹åˆ°è¶…çº§åçˆ¬æœºåœºï¼Œä½¿ç”¨ç»ˆæç»•è¿‡æ¨¡å¼: {url[:70]}...")

    try:
        import ssl
        import urllib.request

        # æ„é€ æœ€åƒæµè§ˆå™¨çš„è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
        }

        req = urllib.request.Request(url, headers=headers)
        
        # å®Œå…¨ç¦ç”¨ SSL éªŒè¯ + ä¼ªè£… TLS
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        with urllib.request.urlopen(req, context=ctx, timeout=40) as response:
            content = response.read().decode('utf-8', errors='ignore')
            if 'vmess://' in content or 'ss://' in content or 'trojan://' in content or len(content) > 1000:
                print(f"  åçˆ¬ç»•è¿‡æˆåŠŸï¼è·å–åˆ° {len(content)} å­—èŠ‚å†…å®¹")
                return content
            else:
                print(f"  è¿”å›å†…å®¹å¤ªçŸ­æˆ–æ— èŠ‚ç‚¹ï¼Œç–‘ä¼¼ä»è¢«è¯†åˆ«")
                return None
    except Exception as e:
        print(f"  å³ä½¿ç»ˆæç»•è¿‡ä¹Ÿå¤±è´¥äº†: {e}")
        return None
#==========

def download_and_parse(url):
    """
    ç»ˆæç‰ˆä¸‹è½½+è§£æå‡½æ•°ï¼ˆ2025å¹´12æœˆç‰ˆï¼‰
    å®Œç¾å…¼å®¹ï¼š
    - æ™®é€šæœºåœºï¼ˆwget/curl/requests ä¸‰ä¿é™©ï¼‰
    - è¶…çº§åçˆ¬æœºåœºï¼ˆooo.oooooooo.../de5.net/feiniu ç­‰ï¼‰
    """
    content = None

    # === ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä¸“æ€è¶…çº§åçˆ¬æœºåœº ===
    if any(domain in url.lower() for domain in ['de5.net', 'feiniu', 'oooooooo', 'ooo.ooo', 'ooo.o', 'feiniu', 'sub.free']):
        print(f"  æ£€æµ‹åˆ°è¶…çº§åçˆ¬æœºåœºï¼Œå¯ç”¨æµè§ˆå™¨çº§ç»•è¿‡: {url[:70]}...")
        content = download_anti_crawl_subscription(url)
        if content:
            print(f"  åçˆ¬ç»•è¿‡æˆåŠŸï¼Œè·å–å†…å®¹ {len(content)} å­—èŠ‚")

    # === ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ™®é€šæœºåœºä¸‰ä¿é™©ä¸‹è½½ ===
    if not content:
        content = download_subscription(url)  # ä½ ä¹‹å‰æˆ‘ç»™çš„ä¸‰ä¿é™©å‡½æ•°ï¼ˆwgetâ†’curlâ†’requestsï¼‰

    # === å¦‚æœå…¨éƒ¨å¤±è´¥ï¼Œç›´æ¥è¿”å›ç©º ===
    if not content:
        print(f"  æ‰€æœ‰ä¸‹è½½æ–¹å¼å‡å¤±è´¥ï¼Œè·³è¿‡: {url}")
        return []

    # ====================== ç»Ÿä¸€è§£æé€»è¾‘ï¼ˆåªèµ°ä¸€æ¬¡ï¼ï¼‰======================
    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  ç›´æ¥ YAML è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  æ˜æ–‡é“¾æ¥è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    if is_base64(content):
        print(f"  æ£€æµ‹åˆ° Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            print(f"  Base64 è§£ç è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
            return proxies

    print(f"  æœªçŸ¥æ ¼å¼ï¼Œè§£æå¤±è´¥: {url[:80]}")
    return []

# --- ä¸‹é¢ä¿æŒåŸAç‰ˆæµ‹é€Ÿã€å»é‡ã€æ’åºç­‰é€»è¾‘ ---


def get_proxy_key(proxy):
    unique_part = proxy.get('uuid') or proxy.get('password') or ''
    return hashlib.md5(
        f"{proxy.get('server','')}:{proxy.get('port',0)}|{unique_part}".encode()
    ).hexdigest()

def is_valid_ss_cipher(cipher):
    """
    åˆ¤æ–­ssèŠ‚ç‚¹cipherå­—æ®µæ˜¯å¦åˆæ³•ï¼Œé¿å…è¢«é”™è¯¯çš„Base64æˆ–å…¶å®ƒå­—ç¬¦ä¸²æ±¡æŸ“ã€‚
    è¿™é‡Œåˆ—ä¸¾äº†Clashå¸¸è§æ”¯æŒçš„ssåŠ å¯†æ–¹æ³•ï¼Œå¿…è¦æ—¶ä½ å¯æ ¹æ®å®é™…å¢åŠ æˆ–ä¿®æ”¹ã€‚

    å‚æ•°:
        cipher (str): ssèŠ‚ç‚¹ä¸­cipherå­—æ®µ

    è¿”å›:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    if not cipher:
        return False
    valid_ciphers = {
        'aes-256-gcm', 'aes-128-gcm', 'chacha20-ietf-poly1305',
        'aes-256-cfb', 'aes-128-cfb', 'chacha20-ietf', 'xchacha20',
        'aes-128-ctr', 'aes-256-ctr', 'rc4-md5'
    }
    return cipher.lower() in valid_ciphers


def is_valid_proxy(proxy):
    """
    è¶…çº§ä¸¥æ ¼æ ¡éªŒ + è‡ªåŠ¨ä¿®å¤ ss cipher ç¼ºå¤±é—®é¢˜
    2025 å¹´ 12 æœˆç»ˆæç‰ˆï¼Œå½»åº•æœç» key 'cipher' missing
    """
    if not isinstance(proxy, dict):
        return False

    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False

    allowed_types = {'vmess', 'vless', 'ss', 'ssr', 'trojan', 'hysteria', 'hysteria2', 'socks5', 'http'}
    if proxy['type'] not in allowed_types:
        return False

    port = proxy.get('port')
    if not isinstance(port, (int, float)) or not (1 <= int(port) <= 65535):
        return False

    # ==================== é‡ç‚¹ï¼šss èŠ‚ç‚¹ cipher å¼ºåˆ¶ä¿®å¤ ====================
    if proxy['type'] == 'ss':
        cipher = proxy.get('cipher', '').strip()
        # åˆæ³•çš„åŠ å¯†æ–¹å¼ï¼ˆClash Meta 2025 æœ€æ–°æ”¯æŒåˆ—è¡¨ï¼‰
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm',
            '2022-blake3-chacha20-poly1305', '2022-blake3-chacha8-poly1305'
        }

        # å¦‚æœ cipher ç¼ºå¤±æˆ–éæ³•ï¼Œå¼ºåˆ¶ä¿®å¤ä¸ºæœ€é€šç”¨çš„
        if not cipher or cipher.lower() not in valid_ciphers:
            old = proxy.get('cipher', 'None')
            proxy['cipher'] = 'chacha20-ietf-poly1305'  # 2025 å¹´æœ€ä¸‡èƒ½
            print(f"ã€è‡ªåŠ¨ä¿®å¤ã€‘ss èŠ‚ç‚¹ cipher ç¼ºå¤±æˆ–éæ³• ({old} â†’ chacha20-ietf-poly1305)ï¼š{proxy['name']}")

    return True

def identify_regions_only(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region:
            p['region_info'] = matched_region
            identified.append(p)
    return identified

def process_proxies(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region is None:
            continue
        if matched_region['name'] not in ALLOWED_REGIONS:
            continue
        p['region_info'] = matched_region
        identified.append(p)
    counters = defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    final = []
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name)
        feature = re.sub(r'\s+', ' ', clean_name).strip()
        if not feature:
            count = sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1
            feature = f"{info['code']}{count:02d}"
        base_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][base_name] += 1
        count_ = counters[info['name']][base_name]
        if count_ > 1:
            new_name = f"{base_name} {count_}"
        else:
            new_name = base_name
        p['name'] = new_name
        final.append(p)
    return final
#é”šç‚¹


# æ–°å¢çš„å›½å®¶ä»£ç  è½¬ ä¸­æ–‡åå­—å…¸ï¼Œæ–¹ä¾¿å¿«é€Ÿæ˜ å°„
COUNTRY_CODE_TO_CN = {
    v['code']: k for k, v in CUSTOM_REGEX_RULES.items()
}

def emoji_to_country_code(emoji):
    if len(emoji) != 2:
        return None
    try:
        # ä¸¤ä¸ªflag emojiçš„unicodeè§£ç æˆå›½å®¶ä»£ç 
        return ''.join(chr(ord(c) - 0x1F1E6 + ord('A')) for c in emoji)
    except:
        return None

FLAG_EMOJI_UN_FLAG ='ğŸ‡ºğŸ‡³'  # æ— å›½å®¶ç”¨è”åˆå›½ï¼ŒæŒ‰éœ€ä¿®æ”¹

def strip_starting_flags(s):
    """
    åå¤æ£€æµ‹å­—ç¬¦ä¸²å¼€å¤´æ˜¯å¦ä¸º2ä¸ªåŒºåŸŸç¬¦å·ç»„æˆçš„å›½æ——emojiï¼Œ
    è‹¥æ˜¯ï¼Œåˆ™å»é™¤ï¼Œç›´åˆ°å¼€å¤´æ— æ­¤å›½æ——emojiã€‚
    """
    def is_flag_emoji(substr):
        # åˆ¤æ–­ substr æ˜¯å¦ä¸¤ä¸ªunicodeå­—ç¬¦éƒ½ä½äºå›½æ——unicodeåŒºåŸŸ
        if len(substr) != 2:
            return False
        return all(0x1F1E6 <= ord(c) <= 0x1F1FF for c in substr)
    
    while len(s) >= 2 and is_flag_emoji(s[:2]):
        s = s[2:]
    return s.strip()

# å†æ¬¡éªŒè¯SSèŠ‚ç‚¹
def fix_and_filter_ss_nodes(proxies):
    """å½»åº•è§£å†³ ss èŠ‚ç‚¹ç¼ºå°‘ cipher æˆ– cipher éæ³•çš„é—®é¢˜"""
    valid_proxies = []
    fixed_count = 0
    dropped_count = 0
    
    for p in proxies:
        if p.get('type') != 'ss':
            valid_proxies.append(p)
            continue
            
        cipher = p.get('cipher', '').strip().lower()
        
        # ç™½åå•ï¼šClash Premium/Meta çœŸæ­£æ”¯æŒçš„åŠ å¯†æ–¹å¼
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm', '2022-blake3-chacha20-poly1305'
        }
        
        if cipher in valid_ciphers:
            valid_proxies.append(p)
            continue
            
        # â€”â€” å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§çš„é”™è¯¯å†™æ³• â€”â€”
        auto_map = {
            'aes-256-cfb': 'aes-256-gcm',
            'aes-128-cfb': 'aes-128-gcm',
            'chacha20': 'chacha20-ietf-poly1305',
            'chacha20-ietf': 'chacha20-ietf-poly1305',
            'rc4-md5': None,  # å·²åºŸå¼ƒï¼Œä¸æ•‘
            'none': None,
            'plain': None,
            '': None,
        }
        
        old_cipher = p.get('cipher', '')
        if old_cipher.lower() in auto_map:
            new_cipher = auto_map[old_cipher.lower()]
            if new_cipher:
                p['cipher'] = new_cipher
                print(f"ã€ä¿®å¤ã€‘ss èŠ‚ç‚¹ cipher {old_cipher} â†’ {new_cipher} : {p['name']}")
                valid_proxies.append(p)
                fixed_count += 1
            else:
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher æ— æ•ˆä¸”æ— æ³•ä¿®å¤: {old_cipher} â†’ {p['name']}")
                dropped_count += 1
        else:
            # å®Œå…¨æ²¡æœ‰ cipher å­—æ®µæˆ–ä¹±ç ï¼Œç›´æ¥å°è¯•ç”¨æœ€å¸¸è§çš„é»˜è®¤å€¼æ•‘æ´»
            if not cipher or len(cipher) > 50 or ' ' in cipher:
                p['cipher'] = 'chacha20-ietf-poly1305'  # 2025 å¹´æœ€é€šç”¨
                print(f"ã€å¼ºæ•‘ã€‘ss èŠ‚ç‚¹ç¼ºå¤±/ä¹±ç  cipherï¼Œå¼ºåˆ¶ä½¿ç”¨ chacha20-ietf-poly1305 : {p['name']}")
                valid_proxies.append(p)
                fixed_count += 1
            else:
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher ä¸æ”¯æŒä¸”æ— æ³•è‡ªåŠ¨æ˜ å°„: {cipher} â†’ {p['name']}")
                dropped_count += 1
    
    print(f"ss èŠ‚ç‚¹æ£€æŸ¥å®Œæˆï¼šä¿®å¤ {fixed_count} ä¸ªï¼Œä¸¢å¼ƒ {dropped_count} ä¸ªï¼Œå‰©ä½™æœ‰æ•ˆ ss èŠ‚ç‚¹ {len([p for p in valid_proxies if p.get('type')=='ss'])} ä¸ª")
    return valid_proxies





def normalize_proxy_names(proxies):
    pattern_trailing_number = re.compile(r'\s*\d+\s*$')
    normalized = []

    for p in proxies:
        name = p.get('name', '').strip()

        # ç”¨å¾ªç¯æ£€æµ‹æ¸…ç†å¼€å¤´æ‰€æœ‰å›½æ——emoji
        name = strip_starting_flags(name)

        # æ¸…ç†å°¾éƒ¨æ•°å­—åºå·
        name = pattern_trailing_number.sub('', name).strip()

        p['name'] = name

        # ä»¥ä¸‹ä¿æŒç°æœ‰é€»è¾‘ä¸å˜
        region_info = p.get('region_info', None)
        flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', name)
        flag_emoji = flag_match.group(0) if flag_match else None

        country_cn = None
        if region_info and 'name' in region_info and region_info['name'] in CUSTOM_REGEX_RULES:
            country_cn = region_info['name']
        elif flag_emoji:
            code = emoji_to_country_code(flag_emoji)
            if code and code in COUNTRY_CODE_TO_CN:
                country_cn = COUNTRY_CODE_TO_CN[code]
        if not country_cn:
            for cname, info in CUSTOM_REGEX_RULES.items():
                if re.search(info['pattern'], name, re.IGNORECASE):
                    country_cn = cname
                    break
        if not country_cn:
            short_name = name[:2] if len(name) >= 2 else name
            country_cn = short_name if short_name else "æœªçŸ¥"
            flag_emoji = FLAG_EMOJI_UN_FLAG
        if not flag_emoji:
            code = None
            for k, v in COUNTRY_CODE_TO_CN.items():
                if v == country_cn:
                    code = k
                    break
            flag_emoji = get_country_flag_emoji(code) if code else FLAG_EMOJI_UN_FLAG

        clean_name = country_cn
        p['_norm_flag'] = flag_emoji
        p['_norm_country'] = clean_name
        normalized.append(p)

    grouped = {}
    for p in normalized:
        country = p['_norm_country']
        grouped.setdefault(country, []).append(p)

    final_list = []
    for country, plist in grouped.items():
        for idx, p in enumerate(plist, 1):
            new_name = f"{p['_norm_flag']} {country} {idx}"
            p['name'] = new_name
            del p['_norm_flag']
            del p['_norm_country']
            final_list.append(p)

    return final_list

# åœ¨ç”Ÿæˆæœ€ç»ˆåˆ—è¡¨å‰åŠ è¿™ä¸€æ®µï¼ˆæ¨èæ”¾åœ¨ normalize_proxy_names ä¹‹åï¼‰
def filter_by_bandwidth(proxies, min_mb=20):
    """åªä¿ç•™å¸¦å®½ â‰¥20MB/s çš„æ‰ä¿ç•™"""
    filtered = []
    for p in proxies:
        bw = p.get('bandwidth', '')
        if not bw:
            filtered.append(p)
            continue
        # æå–æ•°å­—éƒ¨åˆ†
        import re
        m = re.search(r'([0-9\.]+)', bw)
        if m:
            num = float(m.group(1))
            if 'GB/s' in bw:
                num *= 1000
            elif 'KB/s' in bw:
                num /= 1000
            if num >= min_mb:  # 20MB/s ä»¥ä¸Š
                filtered.append(p)
        else:
            filtered.append(p)
    return filtered


# ----æ ¹æ®å®æµ‹å¸¦å®½è¿›è¡ŒäºŒæ¬¡ç­›é€‰
def filter_by_bandwidth(proxies, min_mb=25, enable=True):
    """
    æ ¹æ®å®æµ‹å¸¦å®½è¿›è¡ŒäºŒæ¬¡ç­›é€‰
    """
    if not enable:
        return proxies
    
    filtered = []
    for p in proxies:
        bw_str = p.get('bandwidth', '').strip()
        if not bw_str:
            # æ²¡æœ‰å¸¦å®½æ•°æ®çš„èŠ‚ç‚¹ç›´æ¥ä¿ç•™ï¼ˆé˜²æ­¢è¯¯æ€ï¼‰
            filtered.append(p)
            continue
        
        # è§£æå¸¦å®½æ•°å­—ï¼ˆæ”¯æŒ MB/sã€GB/sã€KB/sï¼‰
        import re
        match = re.search(r'([0-9\.]+)\s*(KB|MB|GB)/?s', bw_str, re.I)
        if not match:
            filtered.append(p)
            continue
        
        num = float(match.group(1))
        unit = match.group(2).upper()
        if unit == 'GB':
            num *= 1000
        elif unit == 'KB':
            num /= 1000
        
        if num >= min_mb:
            filtered.append(p)
            # å¯é€‰ï¼šæŠŠå¸¦å®½å†™è¿›èŠ‚ç‚¹åï¼Œæ–¹ä¾¿ä¸€çœ‹å°±çŸ¥é“é€Ÿåº¦
            # p['name'] = f"{p['name']} | {bw_str}"
        # else:
        #     print(f"å¸¦å®½å¤ªä½ä¸¢å¼ƒ: {num:.1f}MB/s â†’ {p['name']}")
    
    print(f"å¸¦å®½ç­›é€‰å®Œæˆï¼šâ‰¥{min_mb}MB/s ä¿ç•™ {len(filtered)}/{len(proxies)} ä¸ªèŠ‚ç‚¹")
    return filtered

def limit_proxy_counts(proxies, max_total=600):
    """
    æ ¹æ®æŒ‡å®šè§„åˆ™é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼š
    - ['é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'] æ¯åŒºæœ€å¤š60ä¸ªï¼›
    - ['å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'] æ¯åŒºæœ€å¤š15ä¸ªï¼›
    - å…¶ä»–åœ°åŒº æ¯åŒºæœ€å¤š10ä¸ªï¼›
    å…¶ä½™åœ°åŒºæ•°é‡ä¸è¶³ç…§å¸¸ä¿ç•™ã€‚
    
    æ€»æ•° <= max_totalæ—¶ä¸é™åˆ¶ã€‚
    å…ˆæŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿæ— å€¼æ’åã€‚
    è¿”å›é™åˆ¶åçš„èŠ‚ç‚¹åˆ—è¡¨ã€‚
    """
    
    if len(proxies) <= max_total:
        return proxies

    limit_60 = {'é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'}
    limit_15 = {'å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'}

    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿç¼ºå¤±æŒ‰9999å¤„ç†
    proxies.sort(key=lambda p: p.get('clash_delay', 9999))

    grouped = defaultdict(list)
    for p in proxies:
        rname = p.get('region_info', {}).get('name') if p.get('region_info') else None
        grouped[rname].append(p)

    selected = []

    # å…ˆé€‰60é™åˆ¶åŒº
    for region in limit_60:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:60])

    # 15é™åˆ¶åŒº
    for region in limit_15:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:15])

    # å…¶ä»–åŒºåŸŸ
    other_regions = set(grouped.keys()) - limit_60 - limit_15 - {None}
    for region in other_regions:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:10])

    # å¯èƒ½æœ‰æ²¡æœ‰åœ°åŒºä¿¡æ¯çš„èŠ‚ç‚¹ï¼Œå…¨éƒ¨ä¿ç•™
    selected.extend(grouped.get(None, []))

    # å¦‚æœæ•°é‡ä»è¶…é™ï¼Œåˆ™æŒ‰å»¶è¿Ÿæ’åºæˆªæ–­
    if len(selected) > max_total:
        selected.sort(key=lambda p: p.get('clash_delay', 9999))
        selected = selected[:max_total]

    return selected


def generate_config(proxies, last_message_ids):
    return {
        'proxies': proxies,
        'last_message_ids': last_message_ids,
    }


#TCP æµ‹é€Ÿ,æµ‹é€Ÿé»˜è®¤å…³é—­
def run_speedtest(enable_tcp_log=False):
    cmd = ['./xcspeedtest', '--verbose']  # å…·ä½“å‚æ•°è§†ç‰ˆæœ¬è€Œå®š
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

    while True:
        line = process.stdout.readline()
        if line == '' and process.poll() is not None:
            break
        if line:
            if 'TCP' in line:
                if enable_tcp_log:
                    print(line.strip())
                else:
                    # TCPæ—¥å¿—å…³é—­ ä¸æ‰“å°
                    pass
            else:
                print(line.strip())
                
    stderr_lines = process.stderr.read().splitlines()
    for line in stderr_lines:
        if 'TCP' in line:
            if enable_tcp_log:
                print(line.strip())
        else:
            print(line.strip())
    
    return process.poll()


def tcp_ping(proxy, timeout=TCP_TIMEOUT):
    """
    çº¯ TCP è¿æ¥æµ‹å»¶è¿Ÿï¼Œè¿”å›å»¶è¿Ÿï¼ˆmsï¼‰æˆ– None
    """
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    
    try:
        start = time.time()
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(timeout)
            s.connect((server, int(port)))
        delay_ms = int((time.time() - start) * 1000)
        # è¿‡æ»¤å¼‚å¸¸å€¼ï¼ˆ<1ms åŸºæœ¬æ˜¯å‡çš„ï¼‰
        if 1 < delay_ms <= 5000:
            return delay_ms
        else:
            return None
    except:
        return None
        

# é”šç‚¹

def test_proxy_with_clash(clash_path, proxy):
    delay = clash_test_proxy(clash_path, proxy)
    if delay is not None:
        proxy['clash_delay'] = delay
        return proxy
    return None



def batch_tcp_test(proxies, max_workers=TCP_MAX_WORKERS):
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {executor.submit(tcp_ping, p): p for p in proxies}
        for future in as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            delay = future.result()
            if delay is not None and delay <= TCP_MAX_DELAY:
                proxy = proxy.copy()
                proxy['tcp_delay'] = delay
                results.append(proxy)
                if ENABLE_TCP_LOG:
                    print(f"TCP PASS: {delay:4d}ms â†’ {proxy.get('name', '')[:40]}")
            else:
                if delay and ENABLE_TCP_LOG:
                    print(f"TCP SLOW: {delay:4d}ms â†’ ä¸¢å¼ƒ {proxy.get('name', '')[:40]}")
    return results

def batch_test_proxies_speedtest(speedtest_path, proxies, max_workers=MAX_TEST_WORKERS, debug=False):
    """
    ä½¿ç”¨ speedtest-clash æ‰¹é‡æµ‹è¯•ä»£ç†å»¶è¿Ÿã€‚
    :param speedtest_path: speedtest-clash äºŒè¿›åˆ¶è·¯å¾„
    :param proxies: ä»£ç†èŠ‚ç‚¹åˆ—è¡¨
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param debug: æ˜¯å¦æ‰“å°è¯¦ç»†æµ‹é€Ÿæ—¥å¿—
    :return: æµ‹é€ŸæˆåŠŸå¹¶å¸¦å»¶è¿Ÿå­—æ®µçš„ä»£ç†åˆ—è¡¨
    """
    
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(xcspeedtest_test_proxy, speedtest_path, proxy, debug): proxy
            for proxy in proxies
        }
        for future in concurrent.futures.as_completed(futures):
            proxy = futures[future]
            try:
                result = future.result()
                if result is not None:
                    delay, bandwidth = result
                    pcopy = proxy.copy()
                    pcopy['clash_delay'] = delay
                    if bandwidth:
                        pcopy['bandwidth'] = bandwidth  # å­˜ä¸‹æ¥ï¼
                    results.append(pcopy)
                    if debug:
                        print(f"æˆåŠŸ: {delay}ms | {bandwidth or 'N/A'} â†’ {proxy.get('name')}")
            except Exception as e:
                if debug:
                    print(f"å¼‚å¸¸: {proxy.get('name')} â†’ {e}")
    return results


# clash æµ‹é€Ÿ

def xcspeedtest_test_proxy(speedtest_path, proxy, debug=False):
    """
    2025-12-06 ç»ˆææ— æ•Œç‰ˆ
    å…¼å®¹æ‰€æœ‰ç‰ˆæœ¬ xcspeedtestï¼ˆæœ‰/æ—  clash_delayã€å¼•å·æ®‹ç¼ºã€æ¢è¡Œæˆªæ–­ã€å¸¦å®½è¡¨æ ¼ç­‰ï¼‰
    """
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            config_path = os.path.join(tmpdir, 'config.yaml')
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [{"name": "TESTGROUP", "type": "select", "proxies": [proxy["name"]]}],
                "rules": ["MATCH,DIRECT"]
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)

            cmd = [speedtest_path, '-c', config_path]
            result = subprocess.run(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                timeout=40, text=True, encoding='utf-8', errors='ignore'
            )
            output = result.stdout + result.stderr

            if debug:
                print(f"[speedtest-clash] åŸå§‹è¾“å‡º:\n{output}")

            delay = None
            bandwidth = None

            # === 1. ä¼˜å…ˆä» JSON æå– clash_delayï¼ˆæœ€å‡†ï¼ï¼‰===
            # é€‚é…å„ç§æ®‹ç¼ºå¼•å·ã€æ¢è¡Œã€æˆªæ–­æƒ…å†µ
            json_pattern = re.compile(r'json:\s*(\[[\s\S]*?\])', re.IGNORECASE)
            for match in json_pattern.finditer(output):
                j = match.group(1)
                # è¡¥å…¨æ‹¬å·
                if j.count('{') > j.count('}'): j += '}'
                if j.count('[') > j.count(']'): j += ']'
                try:
                    data = json.loads(j)
                    if isinstance(data, list) and data and "clash_delay" in data[0]:
                        d = int(data[0]["clash_delay"])
                        if 1 <= d <= 3000:
                            delay = d
                            if debug:
                                print(f"JSON clash_delay å‘½ä¸­ â†’ {delay}ms â† {proxy['name']}")
                            break
                except:
                    continue

            # === 2. å…œåº•ï¼šè¡¨æ ¼å»¶è¿Ÿåˆ—ï¼ˆä¸€å®šæœ‰ï¼‰===
            if delay is None:
                m = re.search(r'å»¶è¿Ÿ.*?([0-9]+)\s*(?:[^0-9]|$)', output, re.DOTALL)
                if m:
                    try:
                        d = int(m.group(1))
                        if 1 <= d <= 3000:
                            delay = d
                            if debug:
                                print(f"è¡¨æ ¼å»¶è¿Ÿå…œåº• â†’ {delay}ms â† {proxy['name']}")
                    except:
                        pass

            # === 3. æå–å¸¦å®½ ===
            bw = re.search(r'([0-9\.]+ ?[KMGT]B/s)', output)
            if bw:
                bandwidth = bw.group(1).strip()

            if delay is not None:
                if debug:
                    print(f"æµ‹é€ŸæˆåŠŸ â†’ {delay}ms | å¸¦å®½ {bandwidth or 'N/A'} â† {proxy['name']}")
                return delay, bandwidth

            if debug:
                print(f"æµ‹é€Ÿå¤±è´¥ â†’ ä¸¢å¼ƒ {proxy['name']}")
            return None

    except Exception as e:
        if debug:
            print(f"æµ‹é€Ÿå¼‚å¸¸: {e}")
        return None



def clash_test_proxy(clash_path, proxy, debug=False):
    temp_dir = tempfile.mkdtemp()
    config_path = os.path.join(temp_dir, 'config.yaml')
    try:
        for test_url in TEST_URLS:
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [{"name": "TESTGROUP", "type": "select", "proxies": [proxy["name"]]}],
                "rules": [f"DOMAIN,{urlparse(test_url).netloc},TESTGROUP", "MATCH,DIRECT"]
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)
            cmd = [clash_path, '-c', config_path, '-fast']
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30,
                text=True
            )
            output = (result.stdout + result.stderr).replace('\x00', '')
            if debug:
                print(f"\n=== [-fast] æµ‹è¯• URL: {test_url} [{proxy['name']}] ===\n{output}\n{'='*60}")
            # è§£æå»¶è¿Ÿï¼Œé€»è¾‘åŒä¹‹å‰
            match = re.search(r'\b(\d+)ms\b(?=\s*$)', output, re.MULTILINE)
            if match:
                delay = int(match.group(1))
                if 1 < delay < 800:
                    if debug:
                        print(f"æˆåŠŸæŠ“åˆ°å»¶è¿Ÿ: {delay}ms â†’ ä¿ç•™")
                    return delay
            delays = re.findall(r'\b([2-9]\d{1,3})\b', output)
            if delays:
                delay = min(int(x) for x in delays if int(x) < 800)
                if delay > 1:
                    return delay
            if re.search(r'\b(0\s*ms|1\s*ms|NA)\b', output, re.I):
                if debug:
                    print("æ£€æµ‹åˆ° 0ms/1ms/NA â†’ ä¸¢å¼ƒ")
                return None
        # æ‰€æœ‰æµ‹é€Ÿåœ°å€éƒ½æ— ç»“æœæ—¶è¿”å› None
        if debug:
            print(f"æ‰€æœ‰æµ‹é€Ÿåœ°å€å‡æœªé€šè¿‡ â†’ ä¸¢å¼ƒ: {proxy['name']}")
    except subprocess.TimeoutExpired:
        if debug:
            print(f"[-fast] æµ‹é€Ÿè¶…æ—¶ â†’ ä¸¢å¼ƒ: {proxy['name']}")
    except Exception as e:
        if debug:
            print(f"[-fast] å¼‚å¸¸: {proxy['name']} â†’ {e}")
    finally:
        try:
            shutil.rmtree(temp_dir)
        except:
            pass
    return None




# ä¸»å‡½æ•°
async def main():
    print("=" * 60)
    print("Telegram.Node_Clash-Speedtestæµ‹è¯•ç‰ˆ V1")
    print(datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)
    
    # é˜¶æ®µ 0: åœ¨ GitHub Actions ä¸­å¯åŠ¨ Warp æ¨¡æ‹Ÿå›½å†…ç¯å¢ƒ
    # ä»…åœ¨ GitHub Actions ç¯å¢ƒä¸‹å°è¯•å¯åŠ¨ WARP
    if os.getenv('GITHUB_ACTIONS') == 'true': # ç¡®ä¿ç¯å¢ƒå˜é‡åä¸º 'true'
        print("æ£€æµ‹åˆ° GitHub Actions ç¯å¢ƒï¼Œå°è¯•å¯åŠ¨ Cloudflare Warp...")
        warp_ok = start_cloudflare_warp()
        if warp_ok:
            print("âœ… å›½å†…ä¼˜åŒ–ç½‘ç»œç¯å¢ƒå·²å°±ç»ªã€‚")
            # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œç¡®ä¿ç½‘ç»œç¨³å®š
            await asyncio.sleep(5) 
        else:
            print("âš ï¸ Warp å¯åŠ¨å¤±è´¥ï¼Œå°†ä½¿ç”¨ GitHub Actions çš„é»˜è®¤æµ·å¤–ç½‘ç»œç¯å¢ƒè¿›è¡Œæµ‹é€Ÿã€‚")
    else:
        print("æœªåœ¨ GitHub Actions ç¯å¢ƒä¸­è¿è¡Œï¼Œè·³è¿‡ WARP å¯åŠ¨ã€‚")


    preprocess_regex_rules()

    print("[1/5] åŠ è½½åŸæœ‰èŠ‚ç‚¹å’ŒæŠ“å–çŠ¶æ€")
    existing_proxies, last_message_ids = load_existing_proxies_and_state()
    print(f"å·²æœ‰èŠ‚ç‚¹æ•°: {len(existing_proxies)}")

    print("[2/5] æŠ“å– Telegram æ–°è®¢é˜…é“¾æ¥")
    urls, last_message_ids = await scrape_telegram_links(last_message_ids)
    new_proxies = []
    if urls:
        print(f"æŠ“å–åˆ° {len(urls)} ä¸ªè®¢é˜…é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½è§£æ...")
        for url in urls:
            proxies = download_and_parse(url)
            if proxies:
                new_proxies.extend(proxies)
    print(f"æ–°å¢èŠ‚ç‚¹æ•°: {len(new_proxies)}")

    all_proxies_map = {
        get_proxy_key(p): p for p in existing_proxies if is_valid_proxy(p)
    }
    added_count = 0
    for p in new_proxies:
        key = get_proxy_key(p)
        if key not in all_proxies_map:
            all_proxies_map[key] = p
            added_count += 1
    print(f"åˆå¹¶å»é‡åæ€»èŠ‚ç‚¹æ•°: {len(all_proxies_map)}ï¼Œæ–°å¢æœ‰æ•ˆèŠ‚ç‚¹: {added_count}")

    all_nodes = list(all_proxies_map.values())
    if not all_nodes:
        sys.exit("âŒ æ— ä»»ä½•èŠ‚ç‚¹å¯ç”¨ï¼Œç¨‹åºé€€å‡º")
        

    # [3/5] å¼€å§‹èŠ‚ç‚¹æµ‹é€Ÿï¼ˆæ”¯æŒå¤šç§æ¨¡å¼ï¼‰
    print("[3/5] å¼€å§‹èŠ‚ç‚¹æµ‹é€Ÿï¼ˆæ¨¡å¼: %sï¼‰" % SPEEDTEST_MODE)
    clash_path = 'clash_core/clash'
    need_clash = 'clash' in SPEEDTEST_MODE
    if need_clash and not (os.path.isfile(clash_path) and os.access(clash_path, os.X_OK)):
        sys.exit(f"clash æ ¸å¿ƒç¼ºå¤±æˆ–ä¸å¯æ‰§è¡Œ: {clash_path}")

    final_tested_nodes = all_nodes.copy()
    clash_path = './xcspeedtest'  # ä½ çš„ speedtest-clash äºŒè¿›åˆ¶çš„è·¯å¾„

    if SPEEDTEST_MODE == "tcp_only":
        print("ä½¿ç”¨ã€çº¯ TCP æµ‹é€Ÿã€‘æ¨¡å¼")
        final_tested_nodes = batch_tcp_test(all_nodes)
    elif SPEEDTEST_MODE == "clash_only":
        print("ä½¿ç”¨ã€çº¯ speedtest-clash æµ‹é€Ÿã€‘æ¨¡å¼")
        final_tested_nodes = batch_test_proxies_speedtest(
            clash_path,
            all_nodes,
            max_workers=MAX_TEST_WORKERS,
            debug=ENABLE_SPEEDTEST_LOG   # False  å¦‚æœï¼Œåˆ™åªè¾“å‡ºä¸ªäººå®šä¹‰çš„æ‰“å°é¡¹ç›®print
        )
    elif SPEEDTEST_MODE == "tcp_first":
        print("ä½¿ç”¨ã€TCP ç²—ç­› â†’ speedtest-clash ç²¾æµ‹ã€‘ä¸¤é˜¶æ®µæ¨¡å¼")
        print("é˜¶æ®µ1ï¼šTCP è¶…é«˜å¹¶å‘ç²—ç­›...")
        tcp_passed = batch_tcp_test(all_nodes)
        print(f"TCP ç²—ç­›å®Œæˆï¼š{len(all_nodes)} â†’ {len(tcp_passed)}")
        if not tcp_passed:
            print("TCP å…¨æ­»ï¼Œé™çº§ä½¿ç”¨çº¯ speedtest-clash æ¨¡å¼")
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                all_nodes,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
        else:
            print("é˜¶æ®µ2ï¼šå¯¹ TCP å­˜æ´»èŠ‚ç‚¹è¿›è¡Œ speedtest-clash ç²¾å‡†æµ‹é€Ÿ...")
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                tcp_passed,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
    elif SPEEDTEST_MODE == "clash_first":
        print("ä½¿ç”¨ã€speedtest-clash å…ˆæµ‹ â†’ TCP åéªŒã€‘æ¨¡å¼")
        clash_passed = batch_test_proxies_speedtest(
            clash_path,
            all_nodes,
            max_workers=MAX_TEST_WORKERS,
            debug=ENABLE_SPEEDTEST_LOG
        )
        final_tested_nodes = [p for p in clash_passed if tcp_ping(p) is not None]
    else:
        print("æœªçŸ¥æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤ tcp_first")
        tcp_passed = batch_tcp_test(all_nodes)
        if not tcp_passed:
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                all_nodes,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )
        else:
            final_tested_nodes = batch_test_proxies_speedtest(
                clash_path,
                tcp_passed,
                max_workers=MAX_TEST_WORKERS,
                debug=ENABLE_SPEEDTEST_LOG
            )

    # æµ‹é€Ÿç»“æœç»Ÿè®¡
    success_count = len(final_tested_nodes)
    print(f"æµ‹é€Ÿå®Œæˆï¼Œæœ€ç»ˆå­˜æ´»ä¼˜è´¨èŠ‚ç‚¹ï¼š{success_count} ä¸ª")
    
    final_tested_nodes = [p for p in final_tested_nodes if is_valid_proxy(p)]
    # ä¿åº•å›é€€æœºåˆ¶
    if success_count < 50:   # å°‘äº80ä¸ªå°±è§¦å‘ä¿åº•ï¼ˆå¯è‡ªè¡Œè°ƒæ•´ 50~100 ä¹‹é—´ï¼‰
        print(f"æµ‹é€Ÿç»“æœè¿‡å°‘ï¼ˆ{success_count}ä¸ªï¼‰ï¼Œå¯åŠ¨è¶…çº§ä¿åº•ç­–ç•¥ï¼Œä¿ç•™çƒ­é—¨åœ°åŒºèŠ‚ç‚¹")
        
        # ä¼˜å…ˆä¿ç•™è¿™äº›åœ°åŒºï¼ˆä½ æœ€å¸¸ç”¨çš„ï¼‰
        priority_regions = ['é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'ç¾å›½', 'éŸ©å›½', 'å¾·å›½', 'åŠ æ‹¿å¤§']
        
        backup_nodes = []
        seen_keys = set()  # é˜²æ­¢åŒä¸€èŠ‚ç‚¹é‡å¤åŠ å…¥
        
        for proxy in all_nodes:   # all_nodes æ˜¯æ‰€æœ‰åŸå§‹è§£æå‡ºæ¥çš„èŠ‚ç‚¹
            if len(backup_nodes) >= 600:  # æœ€å¤šä¿åº•600ä¸ª
                break
                
            key = get_proxy_key(proxy)
            if key in seen_keys:
                continue
            seen_keys.add(key)
            
            region = proxy.get('region_info', {}).get('name')
            if region in priority_regions:
                # ç»™è¿™äº›èŠ‚ç‚¹ä¸€ä¸ªå‡çš„è¶…å¤§å»¶è¿Ÿï¼Œæ’åˆ°åé¢ä½†ä¸ä¼šè¢«åˆ æ‰
                proxy = proxy.copy()
                proxy['clash_delay'] = 9999
                backup_nodes.append(proxy)
        
        # å¦‚æœçƒ­é—¨åœ°åŒºè¿˜æ˜¯ä¸å¤Ÿï¼Œå°±ä»å‰©ä½™èŠ‚ç‚¹é‡Œéšä¾¿è¡¥
        if len(backup_nodes) < 200:
            for proxy in all_nodes:
                if len(backup_nodes) >= 400:
                    break
                key = get_proxy_key(proxy)
                if key not in seen_keys:
                    p = proxy.copy()
                    p['clash_delay'] = 9999
                    backup_nodes.append(p)
                    seen_keys.add(key)
        
        final_tested_nodes = backup_nodes
        success_count = len(final_tested_nodes)
        print(f"è¶…çº§ä¿åº•æˆåŠŸï¼å¼ºåˆ¶ä¿ç•™ {success_count} ä¸ªçƒ­é—¨åœ°åŒºèŠ‚ç‚¹ï¼ˆæœªæµ‹é€Ÿï¼Œä»…ç”¨äºåº”æ€¥ï¼‰")
    # ============================================================

    # [4/5] èŠ‚ç‚¹åç§°ç»Ÿä¸€è§„èŒƒåŒ–å¤„ç†
    print("[4/5] èŠ‚ç‚¹åç§°ç»Ÿä¸€è§„èŒƒåŒ–å¤„ç†")
    normalized_proxies = normalize_proxy_names(final_tested_nodes)
    final_proxies = limit_proxy_counts(normalized_proxies, max_total=600)
    if not final_proxies:
        sys.exit("âŒ èŠ‚ç‚¹é‡å‘½åå’Œé™é‡åæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")

    # [5/5] æœ€ç»ˆæ’åºå¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶
    print("[5/5] æœ€ç»ˆæ’åºå¹¶ç”Ÿæˆé…ç½®æ–‡ä»¶")
    # æ–°å¢ï¼šå¸¦å®½äºŒæ¬¡ç­›é€‰ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡å®Œå…¨æ§åˆ¶ï¼‰
    final_proxies = filter_by_bandwidth(
        final_proxies, 
        min_mb=MIN_BANDWIDTH_MB, 
        enable=ENABLE_BANDWIDTH_FILTER
    )
    
    final_proxies.sort(
        key=lambda p: (
            REGION_PRIORITY.index(p['region_info']['name']) if p.get('region_info') and p['region_info']['name'] in REGION_PRIORITY else 99,
            p.get('clash_delay', p.get('tcp_delay', 9999))
        )
    )

    total_count = len(final_proxies)
    update_time = datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S")

    final_config = {
        'proxies': final_proxies,
        'last_message_ids': last_message_ids,
        'update_time': update_time,
        'total_nodes': total_count,
        'note': 'ç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆï¼Œæ¯4å°æ—¶æ›´æ–°ä¸€æ¬¡ï¼Œå·²æŒ‰å»¶è¿Ÿæ’åºå¹¶æ™ºèƒ½é™é‡'
    }

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write("# ==================================================\n")
            f.write("#  TG å…è´¹èŠ‚ç‚¹ Â· è‡ªåŠ¨æµ‹é€Ÿç²¾é€‰è®¢é˜…ï¼ˆClash æ ¼å¼ï¼‰\n")
            f.write("# ==================================================\n")
            f.write(f"# æ›´æ–°æ—¶é—´   : {update_time} (åŒ—äº¬æ—¶é—´)\n")
            f.write(f"# èŠ‚ç‚¹æ€»æ•°   : {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹\n")
            f.write(f"# ç­›é€‰è§„åˆ™   : å»¶è¿Ÿæ’åº + å¸¦å®½ â‰¥ {MIN_BANDWIDTH_MB}MB/s\n")
            f.write(f"# åœ°åŒºä¼˜å…ˆçº§ : é¦™æ¸¯ â†’ å°æ¹¾ â†’ æ—¥æœ¬ â†’ æ–°åŠ å¡ â†’ ç¾å›½ â†’ éŸ©å›½ â†’ ...\n")
            f.write("# æ„å»ºæ–¹å¼   : GitHub Actions å…¨è‡ªåŠ¨ï¼Œæ¯4å°æ—¶æ›´æ–°ä¸€æ¬¡\n")
            f.write("# é¡¹ç›®åœ°å€   : https://github.com/ä½ çš„ç”¨æˆ·å/ä½ çš„ä»“åº“\n")
            f.write("# ==================================================\n\n")
            yaml.dump(final_config, f, allow_unicode=True, sort_keys=False, indent=2, width=4096, default_flow_style=False)

        print(f"âœ… é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³ {OUTPUT_FILE}")
        print(f"   æœ¬æ¬¡å…±ä¿ç•™ {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
        print(f"   æ›´æ–°æ—¶é—´ï¼š{update_time}")
        print("ğŸ‰ å…¨éƒ¨ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
    except Exception as e:
        print(f"å†™å‡ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

def sync_main():
    if not ENABLE_SPEED_TEST:
        print("æµ‹é€ŸåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æµ‹é€Ÿã€‚")
        return

    ret = run_speedtest(enable_tcp_log=ENABLE_TCP_LOG)
    print(f"æµ‹é€Ÿè¿›ç¨‹è¿”å›ç ï¼š{ret}")    

if __name__ == "__main__":
    asyncio.run(main())  # è°ƒç”¨å¼‚æ­¥ä¸»å‡½æ•°
