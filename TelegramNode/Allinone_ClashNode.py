"""
FlClashèŠ‚ç‚¹è·å–è„šæœ¬ V1.r3 å¤šåŒºå—æ‰¹å¤„ç†
-----------------------------------------
åŠŸèƒ½è¯´æ˜ï¼š
æœ¬è„šæœ¬ç”¨äºä» URL.TXT æ–‡ä»¶ä¸­è¯»å–å¤šä¸ªä»¥â€œ#â€å¼€å¤´åˆ’åˆ†çš„è®¢é˜…åŒºå—ï¼Œæ¯ä¸ªåŒºå—åŒ…å«è‹¥å¹²è®¢é˜…é“¾æ¥ã€‚
è„šæœ¬ä¼šï¼š
1. è‡ªåŠ¨è¯†åˆ«å¹¶æ‹†åˆ†å¤šä¸ªè®¢é˜…åŒºå—ï¼›
2. é’ˆå¯¹æ¯ä¸ªåŒºå—ï¼Œæå–æ‰€æœ‰ HTTP/HTTPS è®¢é˜…é“¾æ¥ï¼›
3. ä¾æ¬¡ä¸‹è½½è®¢é˜…å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨ wgetï¼Œå¤±è´¥åä½¿ç”¨ requestsï¼‰ï¼›
4. è‡ªåŠ¨è¯†åˆ« YAML ç›´æ¥è§£æï¼Œæˆ– Base64 è§£ç å¹¶æ”¯æŒå¤šåè®®èŠ‚ç‚¹è§£æï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰ï¼›
5. åˆå¹¶å»é‡æ‰€æœ‰èŠ‚ç‚¹ï¼ŒåŒæ—¶æ”¯æŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆé€šè¿‡çº¯ Python socketï¼‰ç­›é€‰å¯ç”¨èŠ‚ç‚¹ï¼›
6. æ™ºèƒ½ä¸ºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ ç¬¦åˆè§„åˆ™çš„åŒºåŸŸæ ‡è¯†å’Œå›½æ—— Emojiï¼Œå¹¶é‡å‘½åï¼›
7. æŒ‰åœ°åŒºä¼˜å…ˆçº§åŠæµ‹é€Ÿç»“æœæ’åºèŠ‚ç‚¹ï¼›
8. ä¸ºæ¯ä¸ªåŒºå—ç”Ÿæˆç‹¬ç«‹çš„ Clash é…ç½® YAML æ–‡ä»¶ï¼Œæ–‡ä»¶ä¿å­˜åœ¨ output_yaml ç›®å½•ä¸­ã€‚


ä½¿ç”¨è¯´æ˜ï¼š
- åœ¨ URL.TXT ä¸­æ·»åŠ è®¢é˜…ï¼Œä½¿ç”¨â€œ# åŒºå—åç§°:â€æ ¼å¼åˆ’åˆ†å¤šä¸ªåŒºå—ï¼Œæ¯å—ä¸‹æ–¹ä¸ºç›¸å…³è®¢é˜…é“¾æ¥åˆ—è¡¨
- è¿è¡Œè„šæœ¬ï¼Œå³å¯åœ¨ output_yaml ç›®å½•ä¸­å¾—åˆ°åˆ†å—ç”Ÿæˆçš„ YAML é…ç½®æ–‡ä»¶
"""


import os
import re
import sys
import yaml
import base64
import json
import socket
import shutil
import hashlib
import subprocess
import requests
import concurrent.futures
from datetime import datetime
from collections import defaultdict
from urllib.parse import urlparse, parse_qs, unquote

# ========== åŸºç¡€é…ç½® ==========
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))  # è·å–å½“å‰è„šæœ¬æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•è·¯å¾„
URL_FILE = os.path.join(SCRIPT_DIR, "URL.TXT")  # å®šä¹‰è®¢é˜…é“¾æ¥æ–‡ä»¶çš„è·¯å¾„ï¼Œæ–‡ä»¶åä¸º URL.TXT
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output_yaml")  # å®šä¹‰è¾“å‡º YAML é…ç½®æ–‡ä»¶çš„ç›®å½•è·¯å¾„
os.makedirs(OUTPUT_DIR, exist_ok=True)  # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œ

# ========== æµ‹é€Ÿé…ç½® ==========
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨èŠ‚ç‚¹æµ‹é€ŸåŠŸèƒ½ (Trueä¸ºå¯ç”¨, Falseä¸ºç¦ç”¨)
SOCKET_TIMEOUT = 10  # æµ‹é€Ÿæ—¶ç½‘ç»œè¿æ¥çš„è¶…æ—¶æ—¶é—´ï¼ˆå•ä½ï¼šç§’ï¼‰
MAX_TEST_WORKERS = 256  # æ‰§è¡Œæµ‹é€Ÿæ—¶çš„æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°

# ========== åŒºåŸŸæ˜ å°„ä¸è§„åˆ™ ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'æ—¥æœ¬', 'ç‹®åŸ', 'ç¾å›½', 'æ¹¾çœ', 'éŸ©å›½', 'å¾·å›½', 'è‹±å›½', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš']
CHINESE_COUNTRY_MAP = {
    'US': 'ç¾å›½', 'United States': 'ç¾å›½', 'USA': 'ç¾å›½',
    'JP': 'æ—¥æœ¬', 'Japan': 'æ—¥æœ¬',
    'HK': 'é¦™æ¸¯', 'Hong Kong': 'é¦™æ¸¯',
    'SG': 'ç‹®åŸ', 'Singapore': 'ç‹®åŸ',
    'TW': 'æ¹¾çœ', 'Taiwan': 'æ¹¾çœ',
    'KR': 'éŸ©å›½', 'Korea': 'éŸ©å›½', 'KOR': 'éŸ©å›½',
    'DE': 'å¾·å›½', 'Germany': 'å¾·å›½',
    'GB': 'è‹±å›½', 'United Kingdom': 'è‹±å›½', 'UK': 'è‹±å›½',
    'CA': 'åŠ æ‹¿å¤§', 'Canada': 'åŠ æ‹¿å¤§',
    'AU': 'æ¾³å¤§åˆ©äºš', 'Australia': 'æ¾³å¤§åˆ©äºš',
}

COUNTRY_NAME_TO_CODE_MAP = {
    "é˜¿æ ¹å»·": "AR", "æ¾³å¤§åˆ©äºš": "AU", "å¥¥åœ°åˆ©": "AT", "å­ŸåŠ æ‹‰å›½": "BD", "æ¯”åˆ©æ—¶": "BE",
    "å·´è¥¿": "BR", "ä¿åŠ åˆ©äºš": "BG", "åŠ æ‹¿å¤§": "CA", "æ™ºåˆ©": "CL", "å“¥ä¼¦æ¯”äºš": "CO",
    "å…‹ç½—åœ°äºš": "HR", "æ·å…‹": "CZ", "ä¸¹éº¦": "DK", "åŸƒåŠ": "EG", "çˆ±æ²™å°¼äºš": "EE",
    "èŠ¬å…°": "FI", "æ³•å›½": "FR", "å¾·å›½": "DE", "å¸Œè…Š": "GR", "é¦™æ¸¯": "HK", "åŒˆç‰™åˆ©": "HU",
    "å†°å²›": "IS", "å°åº¦": "IN", "å°åº¦å°¼è¥¿äºš": "ID", "çˆ±å°”å…°": "IE", "ä»¥è‰²åˆ—": "IL",
    "æ„å¤§åˆ©": "IT", "æ—¥æœ¬": "JP", "å“ˆè¨å…‹æ–¯å¦": "KZ", "éŸ©å›½": "KR", "æ‹‰è„±ç»´äºš": "LV",
    "ç«‹é™¶å®›": "LT", "å¢æ£®å ¡": "LU", "æ¾³é—¨": "MO", "é©¬æ¥è¥¿äºš": "MY", "å¢¨è¥¿å“¥": "MX",
    "æ‘©å°”å¤šç“¦": "MD", "è·å…°": "NL", "æ–°è¥¿å…°": "NZ", "å°¼æ—¥åˆ©äºš": "NG", "æŒªå¨": "NO",
    "å·´åŸºæ–¯å¦": "PK", "è²å¾‹å®¾": "PH", "æ³¢å…°": "PL", "è‘¡è„ç‰™": "PT", "ç½—é©¬å°¼äºš": "RO",
    "ä¿„ç½—æ–¯": "RU", "æ²™ç‰¹é˜¿æ‹‰ä¼¯": "SA", "å¡å°”ç»´äºš": "RS", "æ–°åŠ å¡": "SG", "æ–¯æ´›ä¼å…‹": "SK",
    "æ–¯æ´›æ–‡å°¼äºš": "SI", "å—é": "ZA", "è¥¿ç­ç‰™": "ES", "ç‘å…¸": "SE", "ç‘å£«": "CH",
    "å°æ¹¾": "TW", "æ³°å›½": "TH", "åœŸè€³å…¶": "TR", "ä¹Œå…‹å…°": "UA", "é˜¿è”é…‹": "AE",
    "è‹±å›½": "GB", "ç¾å›½": "US", "è¶Šå—": "VN", "é˜¿æ›¼": "OM", "æŸ¬åŸ”å¯¨": "KH",
    "ç§˜é²": "PE", "é˜¿å¡æ‹œç–†": "AZ", "å·´æ—": "BH"
}

JUNK_PATTERNS = re.compile(
    r"(ä¸“çº¿|IPLC|IEPL|BGP|ä½“éªŒ|å®˜ç½‘|å€ç‡|x\d[\.\d]*|Rate|æµé‡|Relay|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*)",
    re.IGNORECASE
)
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong Kong|HKBN|HGC|PCCW|WTT'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|JP|Japan'},
    'ç‹®åŸ': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|SG|Singapore'},
    'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥'},
    'æ¹¾çœ': {'code': 'TW', 'pattern': r'å°æ¹¾|æ¹¾çœ|å°|æ–°åŒ—|å½°åŒ–|TW|Taiwan'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|éŸ©|é¦–å°”|KR|Korea|KOR|éŸ“'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
    'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|è‹±|UK|GB|United Kingdom|England'},
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
}
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')

def preprocess_regex_rules():
    for region, rules in CUSTOM_REGEX_RULES.items():
        parts = rules['pattern'].split('|')
        sorted_parts = sorted(parts, key=len, reverse=True)
        escaped_parts = [re.escape(p) for p in sorted_parts]
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(escaped_parts)
preprocess_regex_rules()

def sanitize_filename(name: str) -> str:
    """æå–æ–‡ä»¶åï¼Œåªå–#å’Œå†’å·é—´æ–‡å­—ï¼Œå»é™¤ç©ºæ ¼å’Œéæ³•å­—ç¬¦"""
    match = re.match(r"#\s*(.*?)\s*:", name, re.IGNORECASE)
    if match:
        title = match.group(1)
    else:
        title = name.lstrip('#').strip()
    title = re.sub(r'\s+', '', title)
    title = re.sub(r'[\\/:"*?<>|]+', '_', title)
    return title or 'default'

def get_country_flag_emoji(country_code):
    if not country_code or len(country_code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in country_code)

def safe_b64decode(data):
    data = data.encode() if isinstance(data, str) else data
    missing_padding = (-len(data)) % 4
    data += b'=' * missing_padding
    return base64.urlsafe_b64decode(data)

# ----- ä¸‹è½½å‡½æ•° -----
def attempt_download_using_wget(url):
    print(f"  â¬‡ï¸ wget ä¸‹è½½: {url[:80]}")
    if not shutil.which("wget"):
        print("  âœ— æœªå®‰è£… wget")
        return None
    try:
        proc = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        )
        return proc.stdout if proc.stdout else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget å¤±è´¥: {e.stderr.strip()}")
        return None

def attempt_download_using_requests(url):
    print(f"  â¬‡ï¸ requests ä¸‹è½½: {url[:80]}")
    try:
        headers = {'User-Agent': 'Clash'}
        r = requests.get(url, headers=headers, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding or 'utf-8'
        return r.text
    except Exception as e:
        print(f"  âœ— requests å¤±è´¥: {e}")
        return None

def download_subscription(url):
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        return []
    proxies = parse_proxies_from_content(content)
    if proxies:
        return proxies
    if is_base64(content):
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        print("  - Base64 è§£ç æ— æ•ˆèŠ‚ç‚¹")
    else:
        print("  - å†…å®¹é Base64")
    return []

# ----- è§£æå‡½æ•° -----
def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        for line in decoded.splitlines():
            line = line.strip()
            proxy = None
            if line.startswith('vmess://'):
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

# ---- åè®®è§£æå‡½æ•° -- åŒä¸Šæ–‡ï¼Œè¯·ç¡®ä¿å®ç° ----

# ----- åˆå¹¶å»é‡ -----
def get_proxy_key(proxy):
    try:
        key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}|"
        if 'uuid' in proxy:
            key += proxy['uuid']
        elif 'password' in proxy:
            key += proxy['password']
        else:
            key += proxy.get('name', '')
        return hashlib.md5(key.encode('utf-8')).hexdigest()
    except:
        return None

def merge_and_deduplicate_proxies(proxies):
    unique = {}
    for proxy in proxies:
        if not isinstance(proxy, dict) or 'name' not in proxy:
            continue
        k = get_proxy_key(proxy)
        if k and k not in unique:
            unique[k] = proxy
    return list(unique.values())

# ----- é‡å‘½åæ’åº -----
def process_and_rename_proxies(proxies):
    country_counters = defaultdict(lambda: defaultdict(int))
    final_proxies = []
    all_names = set()
    for rules in CUSTOM_REGEX_RULES.values():
        all_names.update(rules['pattern'].split('|'))
    for k, v in CHINESE_COUNTRY_MAP.items():
        all_names.add(k)
        all_names.add(v)
    for k in COUNTRY_NAME_TO_CODE_MAP.keys():
        all_names.add(k)
    sorted_names = sorted(all_names, key=len, reverse=True)
    master_pattern = re.compile('|'.join(map(re.escape, sorted_names)), re.IGNORECASE)
    
    for p in proxies:
        name_orig = p.get('name', '')
        name_clean = FLAG_EMOJI_PATTERN.sub('', name_orig)
        name_clean = JUNK_PATTERNS.sub('', name_clean).strip()
        for eng, chn in CHINESE_COUNTRY_MAP.items():
            name_clean = re.sub(r'\b' + re.escape(eng) + r'\b', chn, name_clean, flags=re.IGNORECASE)
        p['region'] = 'æœªçŸ¥'
        for region_name, rules in CUSTOM_REGEX_RULES.items():
            if re.search(rules['pattern'], name_clean, re.IGNORECASE):
                p['region'] = region_name
                break
        if p['region'] == 'æœªçŸ¥':
            for cname in COUNTRY_NAME_TO_CODE_MAP.keys():
                if re.search(r'\b' + re.escape(cname) + r'\b', name_clean, re.IGNORECASE):
                    p['region'] = cname
                    break

    for p in proxies:
        orig_name = p.get('name', '')
        region = p.get('region', 'æœªçŸ¥')
        region_code = COUNTRY_NAME_TO_CODE_MAP.get(region) or CUSTOM_REGEX_RULES.get(region, {}).get('code', '')
        flag = ""
        mf = FLAG_EMOJI_PATTERN.search(orig_name)
        if mf:
            flag = mf.group(0)
            feature_name = FLAG_EMOJI_PATTERN.sub('', orig_name, 1)
        else:
            flag = get_country_flag_emoji(region_code)
            feature_name = orig_name
        
        feature_name = master_pattern.sub(' ', feature_name)
        feature_name = JUNK_PATTERNS.sub(' ', feature_name)
        feature_name = feature_name.replace('-', ' ').strip()
        feature_name = re.sub(r'\s+', ' ', feature_name).strip()
        if not feature_name:
            idx = sum(1 for fp in final_proxies if fp.get('region') == region) + 1
            feature_name = f"{idx:02d}"

        new_name = f"{flag} {region} {feature_name}".strip()
        country_counters[region][new_name] += 1
        c = country_counters[region][new_name]
        if c > 1:
            new_name = f"{new_name} {c}"
        p['name'] = new_name
        final_proxies.append(p)

    return final_proxies

# ----- æµ‹é€Ÿ -----
def test_single_proxy_socket(proxy):
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(SOCKET_TIMEOUT)
        start = time.time()
        sock.connect((str(server), int(port)))
        end = time.time()
        proxy['delay'] = int((end - start) * 1000)
        return proxy
    except Exception:
        return None
    finally:
        if 'sock' in locals():
            sock.close()

def speed_test_proxies(proxies):
    print(f"å¼€å§‹æµ‹é€Ÿ: å…± {len(proxies)} ä¸ªèŠ‚ç‚¹")
    fast_proxies = []
    total = len(proxies)
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_TEST_WORKERS) as executor:
        futures = {executor.submit(test_single_proxy_socket, p): p for p in proxies}
        for i, f in enumerate(concurrent.futures.as_completed(futures), 1):
            result = f.result()
            if i % 100 == 0 or i == total:
                print(f"\ræµ‹é€Ÿè¿›åº¦: {i}/{total}", end='', flush=True)
            if result:
                fast_proxies.append(result)
    print()
    print(f"æµ‹é€Ÿå®Œæˆ: æœ‰æ•ˆèŠ‚ç‚¹ {len(fast_proxies)}")
    return fast_proxies

# ----- é…ç½®æ–‡ä»¶ç”Ÿæˆ -----
def generate_config(proxies):
    if not proxies:
        return None
    proxy_names = [p['name'] for p in proxies]
    clean_proxies = [{k: v for k, v in p.items() if k not in ['region', 'delay']} for p in proxies]
    return {
        'mixed-port': 7890,
        'allow-lan': True,
        'bind-address': '*',
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': clean_proxies,
        'proxy-groups': [
            {'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'type': 'select', 'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + proxy_names},
            {'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'type': 'url-test', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
            {'name': 'ğŸ”¯ æ•…éšœè½¬ç§»', 'type': 'fallback', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300}
        ],
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

# ------------------ å¤šåŒºå—è¯»å–ä¸å¤„ç† ------------------

def parse_url_txt_to_blocks():
    if not os.path.exists(URL_FILE):
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {URL_FILE}")
        return []

    with open(URL_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    blocks = []
    current_block = {'title': None, 'lines': []}
    for line in lines:
        stripped = line.strip()
        if stripped.startswith('#'):
            if current_block['title']:
                blocks.append(current_block)
            current_block = {'title': stripped, 'lines': []}
        else:
            current_block['lines'].append(stripped)
    if current_block['title']:
        blocks.append(current_block)
    return blocks

def extract_urls_from_lines(lines):
    url_pattern = re.compile(r'https?://[^\s]+', re.IGNORECASE)
    urls = []
    for line in lines:
        urls.extend(url_pattern.findall(line))
    return urls

def process_block_to_yaml(block):
    title = block['title']
    lines = block['lines']
    urls = extract_urls_from_lines(lines)
    if not urls:
        print(f"{title} åŒºå—æ— æœ‰æ•ˆè®¢é˜…ï¼Œè·³è¿‡ã€‚")
        return

    print(f"\nå¤„ç†åŒºå—ï¼š{title} | {len(urls)} ä¸ªè®¢é˜…é“¾æ¥")

    all_proxies = []
    for url in urls:
        all_proxies.extend(download_subscription(url))

    if not all_proxies:
        print(f"{title} è®¢é˜…ä¸‹è½½å¤±è´¥æˆ–æ— èŠ‚ç‚¹ï¼Œè·³è¿‡ã€‚")
        return

    unique_proxies = merge_and_deduplicate_proxies(all_proxies)

    if ENABLE_SPEED_TEST:
        tested_proxies = speed_test_proxies(unique_proxies)
        if not tested_proxies:
            print(f"{title} æµ‹é€Ÿæ— å¯ç”¨èŠ‚ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ã€‚")
            tested_proxies = unique_proxies
    else:
        tested_proxies = unique_proxies

    region_order = {r: i for i, r in enumerate(REGION_PRIORITY)}
    tested_proxies.sort(key=lambda p: (region_order.get(p.get('region', 'æœªçŸ¥'), 999), p.get('delay', 9999)))

    final_proxies = process_and_rename_proxies(tested_proxies)

    config = generate_config(final_proxies)
    if not config:
        print(f"{title} é…ç½®ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚")
        return

    filename = sanitize_filename(title) + ".yaml"
    filepath = os.path.join(OUTPUT_DIR, filename)

    with open(filepath, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2)

    print(f"{title} é…ç½®å·²ç”Ÿæˆï¼š{filepath}ï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(final_proxies)}")

def main():
    print("="*60)
    print("FlClashèŠ‚ç‚¹è·å–è„šæœ¬ V1.r2 å¤šåŒºå—æ‰¹å¤„ç†")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

    blocks = parse_url_txt_to_blocks()
    if not blocks:
        print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆåŒºå—ï¼Œé€€å‡ºã€‚")
        return

    for block in blocks:
        process_block_to_yaml(block)

    print(f"\nå…¨éƒ¨åŒºå—å¤„ç†å®Œæˆï¼Œé…ç½®æ–‡ä»¶å­˜æ”¾äºï¼š{OUTPUT_DIR}")

if __name__ == "__main__":
    main()
