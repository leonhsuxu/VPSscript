# -*- coding: utf-8 -*-
# =====================================================================
# Clash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V4 - 20251204 Clashæµ‹é€Ÿç‰ˆ
#
# åŠŸèƒ½ï¼š
# 1. ä» Telegram é¢‘é“åŠ¨æ€æŠ“å–è®¢é˜…é“¾æ¥
# 2. æ”¯æŒä¸¤ç§ä¸‹è½½æ–¹å¼ï¼ˆwgetä¼˜å…ˆï¼Œrequestså¤‡ç”¨ï¼‰
# 3. è®¢é˜…å†…å®¹è‡ªåŠ¨åˆ¤æ–­å¹¶è§£æï¼š
#    - YAML æ ¼å¼ç›´æ¥æå– proxies å­—æ®µ
#    - æ˜æ–‡åè®®é“¾æ¥ï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰é€è¡Œè§£æ
#    - Base64 ç¼–ç çš„æ··åˆåè®®èŠ‚ç‚¹è§£æ
# 4. è§£æè¿‡ç¨‹ä¸­ç»Ÿè®¡å„åè®®æˆåŠŸå’Œå¤±è´¥èŠ‚ç‚¹æ•°é‡ï¼Œç»Ÿä¸€æ‰“å°
# 5. æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ï¼ˆå«emojiå›½æ——ï¼‰ã€Clashæ ¸å¿ƒæµ‹é€Ÿä¸æ’åºã€æ—§èŠ‚ç‚¹æµ‹é€Ÿå»é‡
# 6. ç”ŸæˆClashå…¼å®¹é…ç½®æ–‡ä»¶ï¼Œé‡Œè¾¹åŒ…å«çˆ¬å–æ¶ˆæ¯æˆªæ­¢id
# =====================================================================
import os
import re
import asyncio
import yaml
import base64
import json
import time
import requests
from datetime import datetime, timedelta, timezone
import sys
from collections import defaultdict
import socket
import concurrent.futures
import hashlib
import subprocess
import shutil
from urllib.parse import urlparse, parse_qs, unquote
import tempfile # For creating temporary directories
import platform # To detect OS for Clash core executable name
# --- Telethon ---
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
# ========================== Telegram ä¸ªäººèµ„æ–™é…ç½® ==========================
API_ID = os.environ.get('TELEGRAM_API_ID')  # è·å– Telegram API ID
API_HASH = os.environ.get('TELEGRAM_API_HASH')  # è·å– Telegram API HASH
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')  # è·å– Telegram ä¼šè¯å­—ç¬¦ä¸²
# ========================== é…ç½®åŒº =========================================
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS')  # Telegramé¢‘é“IDï¼Œå¤šè¡Œå­—ç¬¦ä¸²ï¼Œä»ymlå¼•å…¥
TIME_WINDOW_HOURS = 8  # æŠ“å–æ—¶é—´çª—å£ï¼Œå•ä½å°æ—¶
MIN_EXPIRE_HOURS = 2  # è®¢é˜…é“¾æ¥æœ€ä½å‰©ä½™æœ‰æ•ˆæœŸï¼Œå•ä½å°æ—¶
OUTPUT_FILE = 'flclashyaml/telegram_scraper.yaml'  # è¾“å‡ºYAMLè·¯å¾„
# ========================== æµ‹é€Ÿå‚æ•° =========================================
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æµ‹é€Ÿ  Trueå¼€å¯ï¼ŒFalseå…³é—­
# SOCKET_TIMEOUT = 3  # TCPæµ‹é€Ÿè¶…æ—¶æ—¶é—´(ç§’) - å·²ç§»é™¤ï¼Œå› ä¸ºä¸å†è¿›è¡Œ TCP ç›´æ¥æµ‹é€Ÿ
MAX_TEST_WORKERS = 5  # å¹¶å‘æµ‹é€Ÿçº¿ç¨‹æ•° (æ³¨æ„: ä½¿ç”¨Clashæ ¸å¿ƒæµ‹é€Ÿæ—¶ï¼Œè¿‡é«˜çš„å¹¶å‘æ•°ä¼šæ˜¾è‘—å¢åŠ èµ„æºæ¶ˆè€—)
HTTP_TIMEOUT = 5          # HTTP è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œç”¨äºClashæ ¸å¿ƒæµ‹é€Ÿæ—¶çš„è¯·æ±‚
HTTP_TEST_URL = 'http://www.gstatic.com/generate_204'  # è½»é‡æ— å†…å®¹å“åº”URLï¼Œç”¨äºHTTPæµ‹é€Ÿ
# Clash æ ¸å¿ƒæµ‹é€Ÿç›¸å…³é…ç½®
# è¯·æ ¹æ®æ‚¨çš„æ“ä½œç³»ç»Ÿå’ŒClashæ ¸å¿ƒçš„å®é™…ä½ç½®è¿›è¡Œä¿®æ”¹
# ç¤ºä¾‹: Linux ä¸º './clash_core/clash', Windows ä¸º 'C:\\clash_core\\clash.exe'
# æˆ–è€…å¦‚æœæ‚¨å·²å°†Clashæ ¸å¿ƒæ·»åŠ åˆ°ç³»ç»ŸPATHä¸­ï¼Œå¯ä»¥ç›´æ¥å†™ 'clash'
CLASH_CORE_PATH = './clash_core/clash'
CLASH_CONFIG_PORT_HTTP = 7890  # Clash æ ¸å¿ƒç›‘å¬çš„ HTTP ä»£ç†ç«¯å£
CLASH_CONFIG_PORT_SOCKS = 7891 # Clash æ ¸å¿ƒç›‘å¬çš„ SOCKS5 ä»£ç†ç«¯å£
CLASH_SECRET = "your_clash_secret" # Clash API çš„å¯é€‰å¯†ç ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥ç•™ç©ºæˆ–åˆ é™¤
# ========== åœ°åŒºè¿‡æ»¤é…ç½® ==========
ALLOWED_REGIONS = {'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
                   'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½',
                   'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'}
# ========== æ’åºä¼˜å…ˆçº§é…ç½® ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½', 'å°åº¦', 'è²å¾‹å®¾',
                   'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©',
                   'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš']
# ========== å›½å®¶/åœ°åŒºæ˜ å°„è¡¨ ==========
CHINESE_COUNTRY_MAP = {
    'HK': 'é¦™æ¸¯', 'TW': 'å°æ¹¾', 'JP': 'æ—¥æœ¬', 'SG': 'æ–°åŠ å¡', 'KR': 'éŸ©å›½', 'MY': 'é©¬æ¥è¥¿äºš',
    'TH': 'æ³°å›½', 'IN': 'å°åº¦', 'PH': 'è²å¾‹å®¾', 'ID': 'å°åº¦å°¼è¥¿äºš', 'VN': 'è¶Šå—', 'US': 'ç¾å›½',
    'CA': 'åŠ æ‹¿å¤§', 'FR': 'æ³•å›½', 'GB': 'è‹±å›½', 'DE': 'å¾·å›½', 'RU': 'ä¿„ç½—æ–¯', 'IT': 'æ„å¤§åˆ©',
    'BR': 'å·´è¥¿', 'AR': 'é˜¿æ ¹å»·', 'TR': 'åœŸè€³å…¶', 'AU': 'æ¾³å¤§åˆ©äºš'
}
# ========== åœ°åŒºè¯†åˆ«æ­£åˆ™è§„åˆ™ ==========
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong'},
    'å°æ¹¾': {'code': 'TW', 'pattern': r'å°æ¹¾|å°|TW|Taiwan'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|æ—¥|JP|Japan'},
    'æ–°åŠ å¡': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|SG|Singapore'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|å—æœé²œ|KR|Korea'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|MY|Malaysia'},
    'æ³°å›½': {'code': 'TH', 'pattern': r'æ³°å›½|TH|Thailand'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'è²å¾‹å®¾': {'code': 'PH', 'pattern': r'è²å¾‹å®¾|PH|Philippines'},
    'å°åº¦å°¼è¥¿äºš': {'code': 'ID', 'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|US|USA|United States'},
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|CA|Canada'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|GB|UK|United Kingdom'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
    'ä¿„ç½—æ–¯': {'code': 'RU', 'pattern': r'ä¿„ç½—æ–¯|RU|Russia'},
    'æ„å¤§åˆ©': {'code': 'IT', 'pattern': r'æ„å¤§åˆ©|IT|Italy'},
    'å·´è¥¿': {'code': 'BR', 'pattern': r'å·´è¥¿|BR|Brazil'},
    'é˜¿æ ¹å»·': {'code': 'AR', 'pattern': r'é˜¿æ ¹å»·|AR|Argentina'},
    'åœŸè€³å…¶': {'code': 'TR', 'pattern': r'åœŸè€³å…¶|TR|Turkey'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|AU|Australia'},
}
JUNK_PATTERNS = re.compile(r"(?:ä¸“çº¿|IPLC|ä½“éªŒ|å®˜ç½‘|å€ç‡|x\d[\.\d]*|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)", re.IGNORECASE)
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')
BJ_TZ = timezone(timedelta(hours=8))
# =================================================================================
# Part 2: å‡½æ•°å®šä¹‰
# =================================================================================
def process_proxies(proxies):
    """
    è¿‡æ»¤èŠ‚ç‚¹ï¼Œä»…ä¿ç•™åœ°åŒºåœ¨ ALLOWED_REGIONS çš„èŠ‚ç‚¹ï¼Œ
    å¹¶æ·»åŠ  region_infoï¼Œæœ€åé‡å‘½åèŠ‚ç‚¹ã€‚
    """
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            pattern = info['pattern']
            if re.search(pattern, p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region is None:
            continue
        if matched_region['name'] not in ALLOWED_REGIONS:
            continue
        p['region_info'] = matched_region
        identified.append(p)
    print(f"  - èŠ‚ç‚¹è¿‡æ»¤: æ€»æ•° {len(proxies)} -> æœ‰æ•ˆåœ°åŒºè¯†åˆ«å {len(identified)}")
    counters = defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    final = []
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name)
        feature = re.sub(r'\s+', ' ', clean_name).strip()
        if not feature:
            count = sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1
            feature = f"{info['code']}{count:02d}"
        base_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][base_name] += 1
        count_ = counters[info['name']][base_name]
        if count_ > 1:
            new_name = f"{base_name} {count_}"
        else:
            new_name = base_name
        p['name'] = new_name
        final.append(p)
    return final

# --- è¯»å–æœ¬åœ°å·²æœ‰èŠ‚ç‚¹åŠæŠ“å–çŠ¶æ€ ---
def load_existing_proxies_and_state():
    existing_proxies = []
    last_message_ids = {}
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict):
                    existing_proxies = loaded_yaml.get('proxies', [])
                    if not isinstance(existing_proxies, list):
                        existing_proxies = []
                    last_message_ids = loaded_yaml.get('last_message_ids', {})
                    if not isinstance(last_message_ids, dict):
                        last_message_ids = {}
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
        except Exception as e:
            print(f"  - è¯»å–æˆ–è§£æ {OUTPUT_FILE} å¤±è´¥: {e}")
    return existing_proxies, last_message_ids

def extract_valid_subscribe_links(text):
    """
    ä»å•æ¡æ¶ˆæ¯æ–‡æœ¬ä¸­æå–æœ‰æ•ˆè®¢é˜…é“¾æ¥ï¼Œ
    å¿½ç•¥æœºåœºåé“¾æ¥ï¼Œæ ¹æ®åˆ°æœŸæ—¶é—´è¿‡æ»¤å‰©ä½™æ—¶é—´<2å°æ—¶çš„é“¾æ¥ã€‚
    """
    MIN_HOURS_LEFT = MIN_EXPIRE_HOURS
    BJ_TZ = timezone(timedelta(hours=8))
    link_pattern = re.compile(
        r'(?:è®¢é˜…é“¾æ¥|è®¢é˜…åœ°å€|è®¢é˜…)[\s:ï¼š]*?[^hH]*?(https?://[^\s<>"*`]+)'
    )
    links = link_pattern.findall(text)
    expire_time = None
    expire_patterns = [
        r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¯¥è®¢é˜…å°†äº(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})(?:\s*\+\d{4}\s*[A-Za-z]{3})?è¿‡æœŸ',
        r'è¿‡æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'åˆ°æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'è¯¥è®¢é˜…å°†äºæœªçŸ¥è¿‡æœŸ',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*é•¿æœŸæœ‰æ•ˆ',
        r'è¿‡æœŸ[:ï¼š]\s*æœªçŸ¥/æ— é™',
    ]
    text_single_line = text.replace('\n', ' ')
    for patt in expire_patterns:
        match = re.search(patt, text_single_line)
        if match:
            if 'æœªçŸ¥' in match.group(0) or 'é•¿æœŸæœ‰æ•ˆ' in match.group(0) or 'æ— é™' in match.group(0):
                expire_time = None
                break
            if match.lastindex:
                dt_str = match.group(1)
                fmt_candidates = ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%Y-%m-%d', '%Y/%m/%d']
                for fmt in fmt_candidates:
                    try:
                        dt = datetime.strptime(dt_str, fmt)
                        if fmt in ('%Y-%m-%d', '%Y/%m/%d'):
                            dt = dt.replace(hour=23, minute=59, second=59)
                        expire_time = dt.replace(tzinfo=BJ_TZ)
                        break
                    except:
                        continue
            break
    now = datetime.now(BJ_TZ)
    valid_links = []
    for url in links:
        if expire_time is not None:
            hours_left = (expire_time - now).total_seconds() / 3600
            if hours_left < MIN_HOURS_LEFT:
                continue
        valid_links.append(url)
    return valid_links

async def scrape_telegram_links(last_message_ids=None):
    if last_message_ids is None:
        last_message_ids = {}
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return [], last_message_ids
    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n')
                       if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return [], last_message_ids
    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“: {TARGET_CHANNELS}")
    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return [], last_message_ids
    bj_now = datetime.now(BJ_TZ)
    bj_prior_time = bj_now - timedelta(hours=TIME_WINDOW_HOURS)
    target_time = bj_prior_time.astimezone(timezone.utc)
    all_links = set()
    for channel_id in TARGET_CHANNELS:
        print(f"\nğŸ“¢  æ­£åœ¨å¤„ç†é¢‘é“: {channel_id} ...")
        try:
            entity = await client.get_entity(channel_id)
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•è·å–é¢‘é“å®ä½“ {channel_id}: {e}")
            continue
        last_id = last_message_ids.get(channel_id, 0)
        max_id_found = last_id
        try:
            async for message in client.iter_messages(entity, min_id=last_id + 1, reverse=False):
                if message.date < target_time:
                    break
                if message.text:
                    links = extract_valid_subscribe_links(message.text)
                    for link in links:
                        all_links.add(link)
                        print(f"  âœ… æ‰¾åˆ°é“¾æ¥: {link[:70]}...")
                if message.id > max_id_found:
                    max_id_found = message.id
            last_message_ids[channel_id] = max_id_found
        except Exception as e:
            print(f"âŒ é”™è¯¯: ä»é¢‘é“ '{channel_id}' è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
    await client.disconnect()
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links), last_message_ids

def preprocess_regex_rules():
    """é¢„å¤„ç†æ­£åˆ™è§„åˆ™ï¼šæŒ‰é•¿åº¦æ’åºä»¥ä¼˜åŒ–åŒ¹é…æ•ˆç‡"""
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )

def get_country_flag_emoji(code):
    """æ ¹æ®å›½å®¶ä»£ç ç”Ÿæˆæ——å¸œ Emoji"""
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)

def attempt_download_using_wget(url):
    """ä½¿ç”¨ wget ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ wget ä¸‹è½½: {url[:80]}...")
    if not shutil.which("wget"):
        print("  âœ— é”™è¯¯: wget æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œä¸‹è½½ã€‚")
        return None
    try:
        # ä½¿ç”¨ --no-check-certificate é¿å…è¯ä¹¦é—®é¢˜
        content = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", "--no-check-certificate", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        ).stdout
        return content if content else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget ä¸‹è½½å¤±è´¥: {e.stderr}")
        return None

def attempt_download_using_requests(url):
    """ä½¿ç”¨ requests ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ requests ä¸‹è½½: {url[:80]}...")
    try:
        headers = {'User-Agent': 'Clash'}
        response = requests.get(url, headers=headers, timeout=30, verify=False) # verify=False å¿½ç•¥SSLè¯ä¹¦é”™è¯¯
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'utf-8'
        return response.text
    except requests.RequestException as e:
        print(f"  âœ— requests ä¸‹è½½å¤±è´¥: {e}")
        return None

def parse_proxies_from_content(content):
    """ä»ä¸‹è½½çš„å†…å®¹ä¸­è§£æä»£ç†èŠ‚ç‚¹"""
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ Base64 ç¼–ç """
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        # Relaxed check for URL-safe base64, common in some subs
        if not re.match(r'^[A-Za-z0-9+/=\-_]+$', s): # Added - and _
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

# ---------------- åè®®èŠ‚ç‚¹è§£æ ----------------
def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None

def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None

def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None

def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {'name': name, 'type': 'ss', 'server': server, 'port': port,
                    'cipher': method, 'password': password, 'udp': True}
            return node
        else:
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {'name': remark or f"ss_{server}", 'type': 'ss', 'server': server,
                    'port': int(port), 'cipher': method, 'password': password, 'udp': True}
            return node
    except Exception:
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None

def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        auth = parsed.username or ''
        obfs_password = params.get('obfs-password', [''])[0]
        insecure_val = params.get('insecure', ['false'])[0].lower()
        insecure = insecure_val in ('1', 'true', 'yes')
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': auth,
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': insecure,
            'obfs': params.get('obfs', [''])[0],
            'obfs-password': obfs_password,
            'udp': params.get('udp', ['true'])[0].lower() == 'true',
        }
        return node
    except Exception as e:
        return None

# ---------------- è®¢é˜…è§£æä¸»é€»è¾‘ ----------------
def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

def download_subscription(url):
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        print(f"  âŒ ä¸‹è½½å¤±è´¥: {url}")
        return []
    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  - ç›´æ¥ YAML è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies
    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  - æ˜æ–‡å†…å®¹è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies
    if is_base64(content):
        print(f"  - å†…å®¹ä¸º Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç è§£æ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        else:
            print(f"  - Base64 è§£ç æ— æœ‰æ•ˆèŠ‚ç‚¹")
            return []
    print(f"  - å†…å®¹ä¸ç¬¦åˆå·²çŸ¥æ ¼å¼ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
    return []

# ç§»é™¤äº† test_single_proxy_tcp å‡½æ•°ï¼Œå› ä¸ºä¸å†è¿›è¡Œç›´æ¥ TCP æµ‹é€Ÿ

def generate_clash_config_for_proxy(proxy, config_path, http_port, socks_port):
    """
    Generates a minimal Clash config file for a single proxy.
    Accepts http_port and socks_port to configure Clash listener ports.
    """
    # Ensure proxy has a name for the Clash config
    if 'name' not in proxy:
        proxy['name'] = f"{proxy.get('type', 'unknown')}_{proxy.get('server', 'unknown')}_{proxy.get('port', 'unknown')}_{hashlib.md5(str(proxy).encode()).hexdigest()[:6]}"

    config_data = {
        'port': http_port, # <--- ä½¿ç”¨åŠ¨æ€åˆ†é…çš„ HTTP ç«¯å£
        'socks-port': socks_port, # <--- ä½¿ç”¨åŠ¨æ€åˆ†é…çš„ SOCKS ç«¯å£
        'allow-lan': False, # é€šå¸¸åœ¨æµ‹é€Ÿæ—¶è®¾ç½®ä¸º False
        'mode': 'rule', # or 'direct'
        'log-level': 'silent', # è®¾ç½®ä¸º silent å‡å°‘æ—¥å¿—è¾“å‡ºï¼Œå¦‚æœéœ€è¦è¯¦ç»†æ—¥å¿—å¯ä»¥æ”¹ä¸º info æˆ– debug
        'secret': CLASH_SECRET, # Clash API çš„å¯é€‰å¯†ç 
        'proxies': [proxy], # å°†å•ä¸ªä»£ç†æ·»åŠ åˆ° proxies åˆ—è¡¨ä¸­
        'proxy-groups': [
            {
                'name': 'Proxy',
                'type': 'select',
                'proxies': [proxy['name']] # ä»£ç†ç»„å¼•ç”¨è¯¥ä»£ç†
            },
            {
                'name': 'DIRECT', # ç›´è¿ç­–ç•¥ç»„ï¼Œè™½ç„¶æ­¤å¤„æœªä½¿ç”¨ï¼Œä½†Clashé…ç½®é€šå¸¸åŒ…å«
                'type': 'direct'
            }
        ],
        'rules': [
            'MATCH,Proxy' # æ‰€æœ‰æµé‡éƒ½é€šè¿‡ 'Proxy' ç»„ï¼Œç¡®ä¿æµ‹é€Ÿæµé‡èµ°ä»£ç†
        ]
    }
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, allow_unicode=True, sort_keys=False, indent=2)
    except Exception as e:
        print(f"  âœ— Failed to write Clash config to {config_path}: {e}")
        raise # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…çŸ¥é“é…ç½®ç”Ÿæˆå¤±è´¥

def wait_for_clash_startup(port, timeout=10):
    """Waits for Clash to start listening on the given port."""
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            # Try to establish a connection to the Clash HTTP proxy port
            with socket.create_connection(('127.0.0.1', port), timeout=1):
                return True
        except (socket.timeout, ConnectionRefusedError, OSError):
            time.sleep(0.5)
    return False

def test_single_proxy_with_clash_core(proxy):
        proxy['http_delay'] = None
        return proxy
    except Exception as e:
        # æ•è·å…¶ä»–ä»»ä½•æ„å¤–é”™è¯¯
        print(f"  âœ— An unexpected error occurred during Clash core testing for {original_proxy_name}: {e}")
        proxy['http_delay'] = None
        return proxy
    finally:
        # æ¢å¤ä»£ç†çš„åŸå§‹åç§°ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨å‡½æ•°å¼€å§‹æ—¶ä¿®æ”¹äº†å®ƒ
        if 'name' in proxy and proxy['name'].endswith(f"_{unique_id}"):
            proxy['name'] = original_proxy_name

        # ç»ˆæ­¢ Clash æ ¸å¿ƒè¿›ç¨‹
        if clash_process and clash_process.poll() is None: # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
            clash_process.terminate() # å°è¯•æ­£å¸¸ç»ˆæ­¢
            try:
                clash_process.wait(timeout=5) # ç­‰å¾…å‡ ç§’é’Ÿè®©è¿›ç¨‹å…³é—­
            except subprocess.TimeoutExpired:
                clash_process.kill() # å¦‚æœè¶…æ—¶æœªå…³é—­ï¼Œåˆ™å¼ºåˆ¶æ€æ­»è¿›ç¨‹
        
        # ****** ä»…åœ¨ http_delay ä¸º None æ—¶ï¼ˆå³æµ‹é€Ÿå¤±è´¥ï¼‰æ‰“å° Clash æ ¸å¿ƒçš„æ—¥å¿— ******
        if proxy.get('http_delay') is None:
            print(f"  --- Clash Core Logs for {original_proxy_name} ---")
            if os.path.exists(log_file_stdout):
                with open(log_file_stdout, 'r', encoding='utf-8') as f:
                    stdout_content = f.read()
                    if stdout_content:
                        print(f"  Clash STDOUT:\n{stdout_content}")
            if os.path.exists(log_file_stderr):
                with open(log_file_stderr, 'r', encoding='utf-8') as f:
                    stderr_content = f.read()
                    if stderr_content:
                        print(f"  Clash STDERR:\n{stderr_content}")
            print(f"  --- End Clash Core Logs ---")
        # ****** è°ƒè¯•æ—¥å¿—è¾“å‡ºç»“æŸ ******

        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except Exception as e:
                print(f"  âœ— Failed to clean up temp directory {temp_dir}: {e}")

# --- ä¸»æ§æµç¨‹ ---
def get_proxy_key(p):
    """ç”Ÿæˆä»£ç†èŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†"""
    # ä¼˜å…ˆä½¿ç”¨ uuid/passwordï¼Œç„¶åæ˜¯ server/port ç»„åˆ
    unique_part = p.get('uuid') or p.get('password') or ''
    return hashlib.md5(
        f"{p.get('server','')}:{p.get('port',0)}|{unique_part}".encode()
    ).hexdigest()

def is_valid_proxy(proxy):
    """éªŒè¯ä»£ç†èŠ‚ç‚¹çš„åè®®æ ¼å¼å’Œæœ‰æ•ˆæ€§"""
    if not isinstance(proxy, dict):
        return False
    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False
    # è¿›ä¸€æ­¥æ£€æŸ¥åè®®ç±»å‹
    allowed_types = {'http', 'socks5', 'trojan', 'vless', 'ss', 'vmess', 'ssr', 'hysteria', 'hysteria2'}
    if 'type' in proxy and proxy['type'] not in allowed_types:
        return False
    # ç¡®ä¿ç«¯å£èŒƒå›´åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if not isinstance(proxy['port'], int) or not (1 <= proxy['port'] <= 65535):
        return False
    return True

def delete_old_yaml():
    """æ¯å‘¨ä¸€æ™šä¸Š23:00åˆ é™¤æ—§çš„ YAML æ–‡ä»¶"""
    now = datetime.now(timezone(timedelta(hours=8)))  # åŒ—äº¬æ—¶é—´
    # å‘¨ä¸€(weekday()==0), 23:00-23:59
    if now.weekday() == 0 and now.hour == 23:
        if os.path.exists(OUTPUT_FILE):
            try:
                os.remove(OUTPUT_FILE)
                print(f"âœ… å·²æ ¹æ®è®¡åˆ’åˆ é™¤æ—§çš„é…ç½®æ–‡ä»¶: {OUTPUT_FILE}")
            except OSError as e:
                print(f"âŒ åˆ é™¤æ—§é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def generate_config(proxies):
    """æ ¹æ®ä»£ç†èŠ‚ç‚¹åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„ Clash é…ç½®å­—å…¸"""
    if not proxies:
        return None
    config = {
        'proxies': proxies,
    }
    return config

async def main():
                    if p.get('region_info') and p['region_info']['name'] in fallback_regions:
                        # For fallback, if http_delay is None, use tcp_delay for sorting
                        p['http_delay'] = p.get('tcp_delay', 9999) # Assign tcp_delay if http_delay is None
                        region_grouped_fallback_nodes[p['region_info']['name']].append(p)
                
                for region in fallback_regions:
                    # Sort by http_delay (which is tcp_delay for fallback nodes)
                    sorted_region_nodes = sorted(region_grouped_fallback_nodes[region], key=lambda x: x.get('http_delay', 9999))
                    selected_fallback_nodes.extend(sorted_region_nodes[:fallback_count_per_region])
                
                print(f"  - å›é€€ç­–ç•¥å·²é€‰æ‹© {len(selected_fallback_nodes)} ä¸ªèŠ‚ç‚¹ã€‚")
                nodes_to_process_after_speed_test = selected_fallback_nodes
            elif not http_passed_nodes and not http_failed_nodes: # This means tcp_successful_proxies_raw was empty
                print("âš ï¸ æ— ä»»ä½•èŠ‚ç‚¹é€šè¿‡ TCP æµ‹é€Ÿæˆ– HTTP æµ‹é€Ÿã€‚")
                nodes_to_process_after_speed_test = []
            
    else: # ENABLE_SPEED_TEST is False
        nodes_to_process_after_speed_test = all_nodes
        print("æµ‹é€Ÿå…³é—­ï¼Œä½¿ç”¨å…¨éƒ¨èŠ‚ç‚¹ç»§ç»­å¤„ç†")

    if not nodes_to_process_after_speed_test:
        sys.exit("âŒ æ— ä»»ä½•å¯ç”¨èŠ‚ç‚¹é€šè¿‡æµ‹é€Ÿæˆ–å›é€€é€‰æ‹©ï¼Œç¨‹åºç»ˆæ­¢ã€‚")

    # 5. èŠ‚ç‚¹åœ°åŒºè¯†åˆ«åŠé‡å‘½å (å¯¹æœ€ç»ˆé€‰å®šçš„èŠ‚ç‚¹é›†è¿›è¡Œå¤„ç†)
    print("[4/5] èŠ‚ç‚¹åœ°åŒºè¯†åˆ«åŠé‡å‘½å")
    processed_proxies = process_proxies(nodes_to_process_after_speed_test)
    
    if not processed_proxies:
        sys.exit("âŒ è¯†åˆ«æœ‰æ•ˆèŠ‚ç‚¹å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
    
    # 6. æ’åº (ä¼˜å…ˆä½¿ç”¨ http_delay è¿›è¡Œæ’åº)
    processed_proxies.sort(
        key=lambda p: (
            REGION_PRIORITY.index(p['region_info']['name']) if p['region_info']['name'] in REGION_PRIORITY else 99,
            p.get('http_delay', p.get('tcp_delay', 9999)) # Use http_delay first, then tcp_delay if http_delay is missing
        )
    )
    print(f"[5/5] æ’åºå®Œæˆï¼ŒèŠ‚ç‚¹æ•°é‡: {len(processed_proxies)}")

    # 7. è¾“å‡ºæœ€ç»ˆé…ç½®
    final_config = {
        'proxies': processed_proxies,
        'last_message_ids': last_message_ids,
    }
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            yaml.dump(final_config, f, allow_unicode=True, sort_keys=False, indent=2)
        print(f"âœ… é…ç½®æ–‡ä»¶åŠçŠ¶æ€å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}\n\nğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ å†™å…¥æœ€ç»ˆé…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(main())
