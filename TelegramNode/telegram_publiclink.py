# -*- coding: utf-8 -*-
# =====================================================================
# Clash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V3 - 20251203
#
# åŠŸèƒ½ï¼š
# 1. ä» Telegram é¢‘é“åŠ¨æ€æŠ“å–è®¢é˜…é“¾æ¥
# 2. æ”¯æŒä¸¤ç§ä¸‹è½½æ–¹å¼ï¼ˆwgetä¼˜å…ˆï¼Œrequestså¤‡ç”¨ï¼‰
# 3. è®¢é˜…å†…å®¹è‡ªåŠ¨åˆ¤æ–­å¹¶è§£æï¼š
#    - YAML æ ¼å¼ç›´æ¥æå– proxies å­—æ®µ
#    - æ˜æ–‡åè®®é“¾æ¥ï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰é€è¡Œè§£æ
#    - Base64 ç¼–ç çš„æ··åˆåè®®èŠ‚ç‚¹è§£æ
# 4. è§£æè¿‡ç¨‹ä¸­ç»Ÿè®¡å„åè®®æˆåŠŸå’Œå¤±è´¥èŠ‚ç‚¹æ•°é‡ï¼Œç»Ÿä¸€æ‰“å°
# 5. æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ï¼ˆå«emojiå›½æ——ï¼‰ã€TCPæµ‹é€Ÿä¸æ’åºã€æ—§èŠ‚ç‚¹æµ‹é€Ÿå»é‡
# 6. ç”ŸæˆClashå…¼å®¹é…ç½®æ–‡ä»¶ï¼Œé‡Œè¾¹åŒ…å«çˆ¬å–æ¶ˆæ¯æˆªæ­¢id
# =====================================================================
import os
import re
import asyncio
import yaml
import base64
import json
import time
import requests
from datetime import datetime, timedelta, timezone
import sys
from collections import defaultdict
import socket
import concurrent.futures
import hashlib
import subprocess
import shutil
from urllib.parse import urlparse, parse_qs, unquote
# --- Telethon ---
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
# ========================== Telegram ä¸ªäººèµ„æ–™é…ç½® ==========================
API_ID = os.environ.get('TELEGRAM_API_ID')  # è·å– Telegram API ID
API_HASH = os.environ.get('TELEGRAM_API_HASH')  # è·å– Telegram API HASH
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')  # è·å– Telegram ä¼šè¯å­—ç¬¦ä¸²
# ========================== é…ç½®åŒº =========================================
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS')  # Telegramé¢‘é“IDï¼Œå¤šè¡Œå­—ç¬¦ä¸²ï¼Œä»ymlå¼•å…¥
TIME_WINDOW_HOURS = 8  # æŠ“å–æ—¶é—´çª—å£ï¼Œå•ä½å°æ—¶
MIN_EXPIRE_HOURS = 2  # è®¢é˜…é“¾æ¥æœ€ä½å‰©ä½™æœ‰æ•ˆæœŸï¼Œå•ä½å°æ—¶
OUTPUT_FILE = 'flclashyaml/telegram_scraper.yaml'  # è¾“å‡ºYAMLè·¯å¾„
# ========================== æµ‹é€Ÿå‚æ•° =========================================
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æµ‹é€Ÿ  Trueå¼€å¯ï¼ŒFalseå…³é—­
SOCKET_TIMEOUT = 3  # TCPæµ‹é€Ÿè¶…æ—¶æ—¶é—´(ç§’)
MAX_TEST_WORKERS = 256  # å¹¶å‘æµ‹é€Ÿçº¿ç¨‹æ•°
HTTP_TIMEOUT = 5          # HTTP è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
HTTP_TEST_URL = 'http://www.gstatic.com/generate_204'  # è½»é‡æ— å†…å®¹å“åº”URLï¼Œç”¨äºHTTPæµ‹é€Ÿ
# ========== åœ°åŒºè¿‡æ»¤é…ç½® ==========
ALLOWED_REGIONS = {'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
                   'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½',
                   'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'}
# ALLOWED_REGIONS = set(CUSTOM_REGEX_RULES.keys()) # æˆ–å¯ä½¿ç”¨å·²æœ‰çš„ CUSTOM_REGEX_RULES é”®é›†åˆ
# ========== æ’åºä¼˜å…ˆçº§é…ç½® ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½', 'å°åº¦', 'è²å¾‹å®¾',
                   'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©',
                   'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš']
# ========== å›½å®¶/åœ°åŒºæ˜ å°„è¡¨ ==========
CHINESE_COUNTRY_MAP = {
    'HK': 'é¦™æ¸¯', 'TW': 'å°æ¹¾', 'JP': 'æ—¥æœ¬', 'SG': 'æ–°åŠ å¡', 'KR': 'éŸ©å›½', 'MY': 'é©¬æ¥è¥¿äºš',
    'TH': 'æ³°å›½', 'IN': 'å°åº¦', 'PH': 'è²å¾‹å®¾', 'ID': 'å°åº¦å°¼è¥¿äºš', 'VN': 'è¶Šå—', 'US': 'ç¾å›½',
    'CA': 'åŠ æ‹¿å¤§', 'FR': 'æ³•å›½', 'GB': 'è‹±å›½', 'DE': 'å¾·å›½', 'RU': 'ä¿„ç½—æ–¯', 'IT': 'æ„å¤§åˆ©',
    'BR': 'å·´è¥¿', 'AR': 'é˜¿æ ¹å»·', 'TR': 'åœŸè€³å…¶', 'AU': 'æ¾³å¤§åˆ©äºš'
}
# ========== åœ°åŒºè¯†åˆ«æ­£åˆ™è§„åˆ™ ==========
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong'},
    'å°æ¹¾': {'code': 'TW', 'pattern': r'å°æ¹¾|å°|TW|Taiwan'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|æ—¥|JP|Japan'},
    'æ–°åŠ å¡': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|SG|Singapore'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|å—æœé²œ|KR|Korea'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|MY|Malaysia'},
    'æ³°å›½': {'code': 'TH', 'pattern': r'æ³°å›½|TH|Thailand'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'è²å¾‹å®¾': {'code': 'PH', 'pattern': r'è²å¾‹å®¾|PH|Philippines'},
    'å°åº¦å°¼è¥¿äºš': {'code': 'ID', 'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|US|USA|United States'},
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|CA|Canada'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|GB|UK|United Kingdom'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
    'ä¿„ç½—æ–¯': {'code': 'RU', 'pattern': r'ä¿„ç½—æ–¯|RU|Russia'},
    'æ„å¤§åˆ©': {'code': 'IT', 'pattern': r'æ„å¤§åˆ©|IT|Italy'},
    'å·´è¥¿': {'code': 'BR', 'pattern': r'å·´è¥¿|BR|Brazil'},
    'é˜¿æ ¹å»·': {'code': 'AR', 'pattern': r'é˜¿æ ¹å»·|AR|Argentina'},
    'åœŸè€³å…¶': {'code': 'TR', 'pattern': r'åœŸè€³å…¶|TR|Turkey'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|AU|Australia'},
}
JUNK_PATTERNS = re.compile(r"(?:ä¸“çº¿|IPLC|ä½“éªŒ|å®˜ç½‘|å€ç‡|x\d[\.\d]*|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)", re.IGNORECASE)
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')
BJ_TZ = timezone(timedelta(hours=8))
# =========================    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            pattern = info['pattern']
            if re.search(pattern, p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region is None:
            continue
        if matched_region['name'] not in ALLOWED_REGIONS:
            continue
        p['region_info'] = matched_region
        identified.append(p)
    print(f"  - èŠ‚ç‚¹è¿‡æ»¤: æ€»æ•° {len(proxies)} -> æœ‰æ•ˆåœ°åŒºè¯†åˆ«å {len(identified)}")
    counters = defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    final = []
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name)
        feature = re.sub(r'\s+', ' ', clean_name).strip()
        if not feature:
            count = sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1
            feature = f"{info['code']}{count:02d}"
        base_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][base_name] += 1
        count_ = counters[info['name']][base_name]
        if count_ > 1:
            new_name = f"{base_name} {count_}"
        else:
            new_name = base_name
        p['name'] = new_name
        final.append(p)
    return final

# --- è¯»å–æœ¬åœ°å·²æœ‰èŠ‚ç‚¹åŠæŠ“å–çŠ¶æ€ ---
def load_existing_proxies_and_state():
    existing_proxies = []
    last_message_ids = {}
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict):
                    existing_proxies = loaded_yaml.get('proxies', [])
                    if not isinstance(existing_proxies, list):
                        existing_proxies = []
                    last_message_ids = loaded_yaml.get('last_message_ids', {})
                    if not isinstance(last_message_ids, dict):
                        last_message_ids = {}
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
        except Exception as e:
            print(f"  - è¯»å–æˆ–è§£æ {OUTPUT_FILE} å¤±è´¥: {e}")
    return existing_proxies, last_message_ids
    
    
def extract_valid_subscribe_links(text):
    """
    ä»å•æ¡æ¶ˆæ¯æ–‡æœ¬ä¸­æå–æœ‰æ•ˆè®¢é˜…é“¾æ¥ï¼Œ
    å¿½ç•¥æœºåœºåé“¾æ¥ï¼Œæ ¹æ®åˆ°æœŸæ—¶é—´è¿‡æ»¤å‰©ä½™æ—¶é—´<2å°æ—¶çš„é“¾æ¥ã€‚
    """
    MIN_HOURS_LEFT = 2
    BJ_TZ = timezone(timedelta(hours=8))

    # 1. æ‰¾æ‰€æœ‰è®¢é˜…é“¾æ¥ï¼ˆåªåŒ¹é…å¸¦è®¢é˜…å…³é”®å­—çš„é“¾æ¥ï¼Œä¸åŒ¹é…æœºåœºé“¾æ¥ï¼‰
    link_pattern = re.compile(
        r'(?:è®¢é˜…é“¾æ¥|è®¢é˜…åœ°å€|è®¢é˜…)[\s:ï¼š]*?[^hH]*?(https?://[^\s<>"*`]+)'
    )
    links = link_pattern.findall(text)

    expire_time = None
    expire_patterns = [
        r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¯¥è®¢é˜…å°†äº(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})(?:\s*\+\d{4}\s*[A-Za-z]{3})?è¿‡æœŸ',
        r'è¿‡æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'åˆ°æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'è¯¥è®¢é˜…å°†äºæœªçŸ¥è¿‡æœŸ',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*é•¿æœŸæœ‰æ•ˆ',
        r'è¿‡æœŸ[:ï¼š]\s*æœªçŸ¥/æ— é™',
    ]

    # æŠŠæ–‡æœ¬ç»Ÿä¸€æ¢æˆç©ºæ ¼æ›¿æ¢æ¢è¡Œï¼Œé˜²æ­¢åˆ†è¡Œå½±å“æ­£åˆ™æ•è·
    text_single_line = text.replace('\n', ' ')

    for patt in expire_patterns:
        match = re.search(patt, text_single_line)
        if match:
            if 'æœªçŸ¥' in match.group(0) or 'é•¿æœŸæœ‰æ•ˆ' in match.group(0) or 'æ— é™' in match.group(0):
                expire_time = None  # æ— é™æœŸ
                break
            if match.lastindex:
                dt_str = match.group(1)
                fmt_candidates = ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%Y-%m-%d', '%Y/%m/%d']
                for fmt in fmt_candidates:
                    try:
                        dt = datetime.strptime(dt_str, fmt)
                        if fmt in ('%Y-%m-%d', '%Y/%m/%d'):
                            dt = dt.replace(hour=23, minute=59, second=59)
                        expire_time = dt.replace(tzinfo=BJ_TZ)
                        break
                    except:
                        continue
            break

    now = datetime.now(BJ_TZ)
    valid_links = []
    for url in links:
        if expire_time is not None:
            hours_left = (expire_time - now).total_seconds() / 3600
            if hours_left < MIN_HOURS_LEFT:
                continue
        valid_links.append(url)

    return valid_links
    
async def scrape_telegram_links(last_message_ids=None):
    if last_message_ids is None:
        last_message_ids = {}

    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return [], last_message_ids

    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n') 
                       if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return [], last_message_ids

    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“: {TARGET_CHANNELS}")

    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return [], last_message_ids

    from datetime import timezone, timedelta
    BJ_TZ = timezone(timedelta(hours=8))
    bj_now = datetime.now(BJ_TZ)
    bj_prior_time = bj_now - timedelta(hours=TIME_WINDOW_HOURS)
    target_time = bj_prior_time.astimezone(timezone.utc)

    all_links = set()

    for channel_id in TARGET_CHANNELS:
        print(f"\nğŸ“¢  æ­£åœ¨å¤„ç†é¢‘é“: {channel_id} ...")
        try:
            entity = await client.get_entity(channel_id)
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•è·å–é¢‘é“å®ä½“ {channel_id}: {e}")
            continue

        last_id = last_message_ids.get(channel_id, 0)
        max_id_found = last_id

        try:
            async for message in client.iter_messages(entity, min_id=last_id + 1, reverse=False):
                if message.date < target_time:
                    break
                if message.text:
                    links = extract_valid_subscribe_links(message.text)
                    for link in links:
                        all_links.add(link)
                        print(f"  âœ… æ‰¾åˆ°é“¾æ¥: {link[:70]}...")
                if message.id > max_id_found:
                    max_id_found = message.id

            last_message_ids[channel_id] = max_id_found
        except Exception as e:
            print(f"âŒ é”™è¯¯: ä»é¢‘é“ '{channel_id}' è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    await client.disconnect()

    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links), last_message_ids

def preprocess_regex_rules():
    """é¢„å¤„ç†æ­£åˆ™è§„åˆ™ï¼šæŒ‰é•¿åº¦æ’åºä»¥ä¼˜åŒ–åŒ¹é…æ•ˆç‡"""
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )
    
    
def get_country_flag_emoji(code):
    """æ ¹æ®å›½å®¶ä»£ç ç”Ÿæˆæ——å¸œ Emoji"""
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)


def attempt_download_using_wget(url):
    """ä½¿ç”¨ wget ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ wget ä¸‹è½½: {url[:80]}...")
    if not shutil.which("wget"):
        print("  âœ— é”™è¯¯: wget æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œä¸‹è½½ã€‚")
        return None
    try:
        content = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        ).stdout
        return content if content else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget ä¸‹è½½å¤±è´¥: {e.stderr}")
        return None


def attempt_download_using_requests(url):
    """ä½¿ç”¨ requests ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ requests ä¸‹è½½: {url[:80]}...")
    try:
        headers = {'User-Agent': 'Clash'}
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'utf-8'
        return response.text
    except requests.RequestException as e:
        print(f"  âœ— requests ä¸‹è½½å¤±è´¥: {e}")
        return None


def parse_proxies_from_content(content):
    """ä»ä¸‹è½½çš„å†…å®¹ä¸­è§£æä»£ç†èŠ‚ç‚¹"""
    try:
        # å°è¯•è§£æ YAML å†…å®¹
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []


def is_base64(text):
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ Base64 ç¼–ç """
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False


# ---------------- åè®®èŠ‚ç‚¹è§£æ ----------------

def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None


def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None


def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None


def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {'name': name, 'type': 'ss', 'server': server, 'port': port,
                    'cipher': method, 'password': password, 'udp': True}
            return node
        else:
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {'name': remark or f"ss_{server}", 'type': 'ss', 'server': server,
                    'port': int(port), 'cipher': method, 'password': password, 'udp': True}
            return node
    except Exception:
        return None


def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None


def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None


def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None

        params = parse_qs(parsed.query)

        # ç”¨æˆ·IDåœ¨ netloc çš„ç”¨æˆ·åéƒ¨åˆ†
        auth = parsed.username or ''

        # æ··æ·†å¯†ç 
        obfs_password = params.get('obfs-password', [''])[0]

        # insecureåˆ¤æ–­ï¼Œå…¼å®¹ '0', 'false', '1', 'true'
        insecure_val = params.get('insecure', ['false'])[0].lower()
        insecure = insecure_val in ('1', 'true', 'yes')

        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': auth,
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': insecure,
            'obfs': params.get('obfs', [''])[0],
            'obfs-password': obfs_password,
            'udp': params.get('udp', ['true'])[0].lower() == 'true',
        }
        return node
    except Exception as e:
        # é€šå¸¸å»ºè®®æ‰“å°æˆ–è®°å½•å¼‚å¸¸ä»¥æ–¹ä¾¿è°ƒè¯•
        # print(f"Error parsing node: {e}")
        return None
        

# ---------------- è®¢é˜…è§£æä¸»é€»è¾‘ ----------------

def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies


def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

def download_subscription(url):
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        print(f"  âŒ ä¸‹è½½å¤±è´¥: {url}")
        return []

    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  - ç›´æ¥ YAML è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  - æ˜æ–‡å†…å®¹è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    if is_base64(content):
        print(f"  - å†…å®¹ä¸º Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç è§£æ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        else:
            print(f"  - Base64 è§£ç æ— æœ‰æ•ˆèŠ‚ç‚¹")
            return []
    print(f"  - å†…å®¹ä¸ç¬¦åˆå·²çŸ¥æ ¼å¼ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
    return []


def test_single_proxy_tcp(proxy):
        # è¯·æ±‚å¤±è´¥è¿”å›None
        return None

def combined_speed_test(proxy):
    """
    ç»„åˆæµ‹é€Ÿæµç¨‹ï¼š
    1. å…ˆåšTCPè¿æ¥æµ‹è¯•
    2. TCPæˆåŠŸååšHTTPè¯·æ±‚æµ‹è¯•ï¼ˆç›´è¿ï¼Œä¸èµ°ä»£ç†ï¼‰
    3. è¿”å›åŒ…å« tcp_delay å’Œ http_delay ä¿¡æ¯çš„proxyå­—å…¸
    4. å¤±è´¥æ—¶è¿”å›Noneï¼Œæˆ–è€…http_delayè®¾ä¸ºNoneè¡¨ç¤ºHTTPæµ‹è¯•å¤±è´¥ä½†TCPæˆåŠŸ
    """
    p = test_single_proxy_tcp(proxy)    # TCPæµ‹è¯•
    if not p:
        return None  # TCPå¤±è´¥ï¼Œè·³è¿‡HTTPæµ‹è¯•
    
    p = test_single_proxy_http(p)       # HTTPæµ‹è¯•(ç›´è¿)
    if not p:
        # HTTPæµ‹è¯•å¤±è´¥ä½†TCPæˆåŠŸï¼Œä¿ç•™TCPå»¶è¿Ÿï¼ŒHTTPå»¶è¿Ÿè®¾ä¸ºNone
        proxy['http_delay'] = None
        return proxy

    return p  # ä¸¤é¡¹æµ‹é€Ÿéƒ½æˆåŠŸï¼Œè¿”å›åŒ…å«ä¸¤ä¸ªå»¶è¿Ÿä¿¡æ¯çš„èŠ‚ç‚¹

# ------------------ ä¸»æ§æµç¨‹ ------------------

# ä»£ç†èŠ‚ç‚¹ç¤ºä¾‹åˆ—è¡¨ï¼Œæ ¼å¼å¿…é¡»åŒ…å« 'server' å’Œ 'port'
all_nodes = [
    {"server": "1.1.1.1", "port": 8080},
    {"server": "2.2.2.2", "port": 3128},
    # ä½ è‡ªå·±çš„ä»£ç†åˆ—è¡¨...
]

if ENABLE_SPEED_TEST:
    print(f"[3/5] å¼€å§‹ TCP å’Œ HTTP è¿æ¥ç»¼åˆæµ‹é€Ÿï¼ˆè¶…æ—¶ TCP:{SOCKET_TIMEOUT}sï¼ŒHTTP:{HTTP_TIMEOUT}sï¼Œæœ€å¤§çº¿ç¨‹ {MAX_TEST_WORKERS}ï¼‰...")

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æµ‹é€Ÿï¼Œæå‡æµ‹é€Ÿæ•ˆç‡
    with concurrent.futures.ThreadPoolExecutor(MAX_TEST_WORKERS) as pool:
        # å¹¶å‘æ‰§è¡Œç»„åˆæµ‹é€Ÿå‡½æ•°ï¼ˆTCP+HTTPï¼‰
        tested_results = list(pool.map(combined_speed_test, all_nodes))
    
    # ç­›é€‰æµ‹é€ŸæˆåŠŸçš„ä»£ç†èŠ‚ç‚¹ï¼ˆé Noneï¼‰
    tested_proxies = [p for p in tested_results if p]

    print(f"æµ‹é€ŸæˆåŠŸèŠ‚ç‚¹æ•°: {len(tested_proxies)} / {len(all_nodes)}")

else:
    # æµ‹é€Ÿå…³é—­ï¼Œç›´æ¥ä½¿ç”¨å…¨éƒ¨èŠ‚ç‚¹
    tested_proxies = all_nodes
    print("æµ‹é€Ÿå…³é—­ï¼Œä½¿ç”¨å…¨éƒ¨èŠ‚ç‚¹ç»§ç»­å¤„ç†")

# å¦‚æœæ²¡æœ‰ä»»ä½•æµ‹é€ŸæˆåŠŸçš„èŠ‚ç‚¹ï¼Œé€€å›ä½¿ç”¨å…¨éƒ¨èŠ‚ç‚¹ï¼Œä¿è¯ç¨‹åºåç»­å¯æ‰§è¡Œ
if not tested_proxies:
    print("âš ï¸ æ— æµ‹é€ŸæˆåŠŸèŠ‚ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ç»§ç»­å¤„ç†")
    tested_proxies = all_nodes

# æ‰“å°æœ€ç»ˆç»“æœï¼Œæ–¹ä¾¿ç¡®è®¤
for proxy in tested_proxies:
    print(f"ä»£ç† {proxy['server']}:{proxy['port']}, TCPå»¶è¿Ÿ={proxy.get('tcp_delay')}ms, HTTPå»¶è¿Ÿ={proxy.get('http_delay')}")

def get_proxy_key(p):
    """ç”Ÿæˆä»£ç†èŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†"""
    # ä¼˜å…ˆä½¿ç”¨ uuid/passwordï¼Œç„¶åæ˜¯ server/port ç»„åˆ
    unique_part = p.get('uuid') or p.get('password') or ''
    return hashlib.md5(
        f"{p.get('server','')}:{p.get('port',0)}|{unique_part}".encode()
    ).hexdigest()

def is_valid_proxy(proxy):
    """éªŒè¯ä»£ç†èŠ‚ç‚¹çš„åè®®æ ¼å¼å’Œæœ‰æ•ˆæ€§"""
    if not isinstance(proxy, dict):
        return False
    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False
    # è¿›ä¸€æ­¥æ£€æŸ¥åè®®ç±»å‹
    allowed_types = {'http', 'socks5', 'trojan', 'vless', 'ss', 'vmess', 'ssr', 'hysteria', 'hysteria2'}
    if 'type' in proxy and proxy['type'] not in allowed_types:
        return False
    # ç¡®ä¿ç«¯å£èŒƒå›´åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if not isinstance(proxy['port'], int) or not (1 <= proxy['port'] <= 65535):
        return False
    return True



def delete_old_yaml():
    """æ¯å‘¨ä¸€æ™šä¸Š23:00åˆ é™¤æ—§çš„ YAML æ–‡ä»¶"""
    now = datetime.now(timezone(timedelta(hours=8)))  # åŒ—äº¬æ—¶é—´
    # å‘¨ä¸€(weekday()==0), 23:00-23:59
    if now.weekday() == 0 and now.hour == 23:
        if os.path.exists(OUTPUT_FILE):
            try:
                os.remove(OUTPUT_FILE)
                print(f"âœ… å·²æ ¹æ®è®¡åˆ’åˆ é™¤æ—§çš„é…ç½®æ–‡ä»¶: {OUTPUT_FILE}")
            except OSError as e:
                print(f"âŒ åˆ é™¤æ—§é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def generate_config(proxies):
    """æ ¹æ®ä»£ç†èŠ‚ç‚¹åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„ Clash é…ç½®å­—å…¸"""
    if not proxies:
        return None
    # ä»…åŒ…å«proxiesé”®ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæœ‰æ•ˆçš„Clashä»£ç†æä¾›è€…æ–‡ä»¶
    config = {
        'proxies': proxies,
    }
    return config


async def main():
    
    print("=" * 60)
    print("Clash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V3 ")
    print(f"æ—¶é—´: {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    preprocess_regex_rules()
    
    # delete_old_yaml()  # å–æ¶ˆå®šæœŸåˆ é™¤ï¼Œä¿ç•™å†å²æ–‡ä»¶
    

    print("[1/5] è¯»å–å·²æœ‰èŠ‚ç‚¹åŠæŠ“å–çŠ¶æ€æ–‡ä»¶")
    existing_proxies, last_message_ids = load_existing_proxies_and_state()
    print(f"å·²æœ‰èŠ‚ç‚¹æ•°é‡: {len(existing_proxies)}")

    # 2. æŠ“å– Telegram è·å–æ–°è®¢é˜…é“¾æ¥å’Œæ–°èŠ‚ç‚¹
    print("[2/5] æŠ“å– Telegram è®¢é˜…é“¾æ¥")
    urls, last_message_ids = await scrape_telegram_links(last_message_ids)

    new_proxies_list = []
    if urls:
        print(f"å…±æŠ“å– {len(urls)} ä¸ªè®¢é˜…é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½è§£æèŠ‚ç‚¹...")
        for url in urls:
            proxies = download_subscription(url)
            if proxies:
                new_proxies_list.extend(proxies)

    print(f"æŠ“å–æ–°å¢èŠ‚ç‚¹æ•°: {len(new_proxies_list)}")

    # 3. åˆå¹¶åŸæœ‰å’Œæ–°å¢èŠ‚ç‚¹ï¼Œå»é‡
    all_proxies_map = {get_proxy_key(p): p for p in existing_proxies if is_valid_proxy(p)}
    added_new = 0
    for p in new_proxies_list:
        key = get_proxy_key(p)
        if key not in all_proxies_map:
            all_proxies_map[key] = p
            added_new += 1
    print(f"åˆå¹¶å»é‡åæ€»èŠ‚ç‚¹æ•°: {len(all_proxies_map)}, æ–°å¢èŠ‚ç‚¹: {added_new}")

    all_nodes = list(all_proxies_map.values())
    if not all_nodes:
        sys.exit("âŒ æ— ä»»ä½•å¯ç”¨èŠ‚ç‚¹, ç¨‹åºç»ˆæ­¢")

    # 4. TCP æµ‹é€Ÿæ‰€æœ‰èŠ‚ç‚¹ï¼Œä¿ç•™æµ‹é€ŸæˆåŠŸçš„
    if ENABLE_SPEED_TEST:
        print(f"[3/5] å¼€å§‹ TCP è¿æ¥æµ‹é€Ÿï¼ˆè¶…æ—¶ {SOCKET_TIMEOUT}sï¼Œæœ€å¤§çº¿ç¨‹ {MAX_TEST_WORKERS}ï¼‰...")
        with concurrent.futures.ThreadPoolExecutor(MAX_TEST_WORKERS) as pool:
            tested_results = list(pool.map(test_single_proxy_tcp, all_nodes))
        tested_proxies = [p for p in tested_results if p]
        print(f"æµ‹é€ŸæˆåŠŸèŠ‚ç‚¹æ•°: {len(tested_proxies)} / {len(all_nodes)}")
    else:
        tested_proxies = all_nodes
        print("æµ‹é€Ÿå…³é—­ï¼Œä½¿ç”¨å…¨éƒ¨èŠ‚ç‚¹ç»§ç»­å¤„ç†")

    if not tested_proxies:
        print("âš ï¸ æ— æµ‹é€ŸæˆåŠŸèŠ‚ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ç»§ç»­å¤„ç†")
        tested_proxies = all_nodes

    # 5. ä»…é’ˆå¯¹æµ‹é€Ÿé€šè¿‡èŠ‚ç‚¹åšåœ°åŒºè¯†åˆ«å’Œé‡å‘½å
    print("[4/5] èŠ‚ç‚¹åœ°åŒºè¯†åˆ«åŠé‡å‘½å")
    processed_proxies = process_proxies(tested_proxies)
    if not processed_proxies:
        sys.exit("âŒ è¯†åˆ«æœ‰æ•ˆèŠ‚ç‚¹å¤±è´¥ï¼Œç¨‹åºé€€å‡º")

    # 6. æ’åº
    processed_proxies.sort(
        key=lambda p: (
            REGION_PRIORITY.index(p['region_info']['name']) if p['region_info']['name'] in REGION_PRIORITY else 99,
            p.get('delay', 9999)
        )
    )
    print(f"[5/5] æ’åºå®Œæˆï¼ŒèŠ‚ç‚¹æ•°é‡: {len(processed_proxies)}")

    # 7. è¾“å‡ºæœ€ç»ˆé…ç½®
    final_config = {
        'proxies': processed_proxies,
        'last_message_ids': last_message_ids,
    }
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            yaml.dump(final_config, f, allow_unicode=True, sort_keys=False, indent=2)
        print(f"âœ… é…ç½®æ–‡ä»¶åŠçŠ¶æ€å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}\n\nğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ å†™å…¥æœ€ç»ˆé…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(main())
