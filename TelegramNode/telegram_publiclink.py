# æ–‡ä»¶å: TelegramNode/telegram_publiclink.py
# -*- coding: utf-8 -*-
# ============================================================================
# Clash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V1.R3
#
# ç‰ˆæœ¬å†å²:
# V1.R1 (20251130) - åˆå§‹ç‰ˆæœ¬
# V1.R2 (20251201) - å¢åŠ å¤šç§ä¸‹è½½æ–¹å¼ï¼Œä¼˜å…ˆä½¿ç”¨ wget
# V1.R3 (20251202) - æ”¯æŒè§£æBase64ç¼–ç ï¼Œå¯ä»¥å¤„ç†å…¶ä»–æ–‡æœ¬æ ¼å¼
# ============================================================================
import os
import re
import asyncio
import yaml
import base64
import json
import time
import requests  # å¼•å…¥ requests åº“
from datetime import datetime, timedelta, timezone
import sys
from collections import defaultdict
import socket
import concurrent.futures
import hashlib
import subprocess
import shutil
# --- Telethon ---
from telethon.sync import TelegramClient
from telethon.tl.types import MessageMediaWebPage
from telethon.sessions import StringSession

# =================================================================================
# Part 1: é…ç½®
# =================================================================================
API_ID = os.environ.get('TELEGRAM_API_ID')
API_HASH = os.environ.get('TELEGRAM_API_HASH')
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS')
TIME_WINDOW_HOURS = 72
MIN_EXPIRE_HOURS = 7
OUTPUT_FILE = 'flclashyaml/telegram_scraper.yaml'
ENABLE_SPEED_TEST = True
SOCKET_TIMEOUT = 8
MAX_TEST_WORKERS = 128
TEST_URL = 'http://www.gstatic.com/generate_204'
TEST_INTERVAL = 300

# ========== åœ°åŒºè¿‡æ»¤é…ç½® ==========
ALLOWED_REGIONS = {'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
                   'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½',
                   'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'}

# ========== æ’åºä¼˜å…ˆçº§é…ç½® ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½', 'å°åº¦', 'è²å¾‹å®¾',
                   'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©',
                   'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš']

# ========== å›½å®¶/åœ°åŒºæ˜ å°„è¡¨ ==========
CHINESE_COUNTRY_MAP = {
    'HK': 'é¦™æ¸¯', 'TW': 'å°æ¹¾', 'JP': 'æ—¥æœ¬', 'SG': 'æ–°åŠ å¡', 'KR': 'éŸ©å›½', 'MY': 'é©¬æ¥è¥¿äºš',
    'TH': 'æ³°å›½', 'IN': 'å°åº¦', 'PH': 'è²å¾‹å®¾', 'ID': 'å°åº¦å°¼è¥¿äºš', 'VN': 'è¶Šå—', 'US': 'ç¾å›½',
    'CA': 'åŠ æ‹¿å¤§', 'FR': 'æ³•å›½', 'GB': 'è‹±å›½', 'DE': 'å¾·å›½', 'RU': 'ä¿„ç½—æ–¯', 'IT': 'æ„å¤§åˆ©',
    'BR': 'å·´è¥¿', 'AR': 'é˜¿æ ¹å»·', 'TR': 'åœŸè€³å…¶', 'AU': 'æ¾³å¤§åˆ©äºš'
}

# ========== åœ°åŒºè¯†åˆ«æ­£åˆ™è§„åˆ™ ==========
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong'},
    'å°æ¹¾': {'code': 'TW', 'pattern': r'å°æ¹¾|å°|TW|Taiwan'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|æ—¥|JP|Japan'},
    'æ–°åŠ å¡': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|SG|Singapore'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|å—æœé²œ|KR|Korea'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|MY|Malaysia'},
    'æ³°å›½': {'code': 'TH', 'pattern': r'æ³°å›½|TH|Thailand'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'è²å¾‹å®¾': {'code': 'PH', 'pattern': r'è²å¾‹å®¾|PH|Philippines'},
    'å°åº¦å°¼è¥¿äºš': {'code': 'ID', 'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|US|USA|United States'},
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|CA|Canada'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|GB|UK|United Kingdom'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
    'ä¿„ç½—æ–¯': {'code': 'RU', 'pattern': r'ä¿„ç½—æ–¯|RU|Russia'},
    'æ„å¤§åˆ©': {'code': 'IT', 'pattern': r'æ„å¤§åˆ©|IT|Italy'},
    'å·´è¥¿': {'code': 'BR', 'pattern': r'å·´è¥¿|BR|Brazil'},
    'é˜¿æ ¹å»·': {'code': 'AR', 'pattern': r'é˜¿æ ¹å»·|AR|Argentina'},
    'åœŸè€³å…¶': {'code': 'TR', 'pattern': r'åœŸè€³å…¶|TR|Turkey'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|AU|Australia'},
}

JUNK_PATTERNS = re.compile(r"(?:ä¸“çº¿|IPLC|ä½“éªŒ|å®˜ç½‘|å€ç‡|x\d[\.\d]*|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)", re.IGNORECASE)
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')

# =================================================================================
# Part 2: å‡½æ•°å®šä¹‰
# =================================================================================
def parse_expire_time(text):
    """è§£ææ¶ˆæ¯ä¸­çš„åˆ°æœŸæ—¶é—´"""
    match = re.search(r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})', text)
    if match:
        try:
            return datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone(timedelta(hours=8)))
        except ValueError:
            return None
    return None

def is_expire_time_valid(expire_time):
    """æ£€æŸ¥è®¢é˜…é“¾æ¥æ˜¯å¦åœ¨æœ‰æ•ˆæœŸå†…"""
    if expire_time is None:
        return True
    hours_remaining = (expire_time - datetime.now(timezone(timedelta(hours=8)))).total_seconds() / 3600
    if hours_remaining < MIN_EXPIRE_HOURS:
        print(f"  âŒ å·²è·³è¿‡: é“¾æ¥å‰©ä½™æ—¶é—´ ({hours_remaining:.1f} å°æ—¶) å°‘äºæœ€ä½è¦æ±‚ ({MIN_EXPIRE_HOURS} å°æ—¶)")
        return False
    return True

async def scrape_telegram_links():
    """ä» Telegram é¢‘é“æŠ“å–è®¢é˜…é“¾æ¥"""
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return []

    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n') if line.strip() and not line.strip().startswith('#')]
    
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return []

    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“: {TARGET_CHANNELS}")

    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return []

    target_time = datetime.now(timezone.utc) - timedelta(hours=TIME_WINDOW_HOURS)
    all_links = set()

    for channel_id in TARGET_CHANNELS:
        print(f"\n--- æ­£åœ¨å¤„ç†é¢‘é“: {channel_id} ---")
        try:
            async for message in client.iter_messages(await client.get_entity(channel_id), limit=500):
                if message.date < target_time:
                    break
                if message.text and is_expire_time_valid(parse_expire_time(message.text)):
                    for url in re.findall(r'è®¢é˜…é“¾æ¥[:ï¼š]\s*`]*\s*(https?://[^\s<>"*`]+)', message.text):
                        cleaned_url = url.strip().strip('.,*`')
                        if cleaned_url:
                            all_links.add(cleaned_url)
                            print(f"  âœ… æ‰¾åˆ°é“¾æ¥: {cleaned_url[:70]}...")
        except Exception as e:
            print(f"âŒ é”™è¯¯: ä»é¢‘é“ '{channel_id}' è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    await client.disconnect()
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links)

def preprocess_regex_rules():
    """é¢„å¤„ç†æ­£åˆ™è§„åˆ™ï¼šæŒ‰é•¿åº¦æ’åºä»¥ä¼˜åŒ–åŒ¹é…æ•ˆç‡"""
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )

def get_country_flag_emoji(code):
    """æ ¹æ®å›½å®¶ä»£ç ç”Ÿæˆæ——å¸œ Emoji"""
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code) if code and len(code) == 2 else "â“"

def attempt_download_using_wget(url):
    """ä½¿ç”¨ wget ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ wget ä¸‹è½½: {url[:80]}...")
    if not shutil.which("wget"):
        print("  âœ— é”™è¯¯: wget æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œä¸‹è½½ã€‚")
        return None
    try:
        content = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True
        ).stdout
        return content if content else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget ä¸‹è½½å¤±è´¥: {e}")
        return None

def attempt_download_using_requests(url):
    """ä½¿ç”¨ requests ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ requests ä¸‹è½½: {url[:80]}...")
    try:
        headers = {'User-Agent': 'Clash'}
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        return response.text
    except requests.RequestException as e:
        print(f"  âœ— requests ä¸‹è½½å¤±è´¥: {e}")
        return None

def parse_proxies_from_content(content):
    """ä»ä¸‹è½½çš„å†…å®¹ä¸­è§£æä»£ç†èŠ‚ç‚¹"""
    try:
        # å°è¯•è§£æ YAML å†…å®¹
        proxies = yaml.safe_load(content)
        if isinstance(proxies, dict):
            return proxies.get('proxies', [])
        elif isinstance(proxies, list):
            return proxies  # å¦‚æœ content æ˜¯ä¸€ä¸ªç›´æ¥çš„ä»£ç†åˆ—è¡¨
        else:
            print(f"è­¦å‘Š: è§£æçš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ proxies æ ¼å¼: {content[:100]}")
            return []
    except yaml.YAMLError as e:
        print(f"YAML è§£æé”™è¯¯: {e}")
        return []
    except Exception as e:
        print(f"è§£æå†…å®¹æ—¶å…¶ä»–é”™è¯¯: {e}")
        return []

def is_base64(string):
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯ Base64 ç¼–ç """
    try:
        if isinstance(string, str):
            base64.b64decode(string, validate=True)
            return True
    except Exception:
        return False
    return False

def decode_base64_and_parse(base64_str):
    """è§£ç  Base64 å¹¶è§£æä¸º Clash æ ¼å¼çš„èŠ‚ç‚¹"""
    try:
        decoded_content = base64.b64decode(base64_str).decode('utf-8')
        proxies = []
        
        for line in decoded_content.splitlines():
            line = line.strip()
            if line.startswith('vless://') or line.startswith('vmess://'):
                proxies.append(parse_vmess_node(line))
            elif line.startswith('ssr://'):
                proxies.append(parse_ssr_node(line))
            elif line.startswith('ss://'):
                proxies.append(parse_ss_node(line))
            else:
                print(f"è­¦å‘Š: æœªæ”¯æŒçš„èŠ‚ç‚¹æ ¼å¼: {line[:100]}")
        
        return proxies
    except Exception as e:
        print(f"è§£ç  Base64 å¹¶è§£ææ—¶å‡ºé”™: {e}")
        return []

def parse_ssr_node(node_str):
    """è§£æ SSR èŠ‚ç‚¹å­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸º Clash æ ¼å¼"""
    try:
        decoded = base64.urlsafe_b64decode(node_str[5:]).decode('utf-8')
        params = decoded.split(':')
        cipher = params[0]
        password = params[1]
        host = params[2]
        port = params[3]
        obfs = params[4]  # å¯é€‰å­—æ®µ
        protocol = params[5]  # å¯é€‰å­—æ®µ
        # ç»„è£… Clash èŠ‚ç‚¹æ ¼å¼
        proxy = {
            "name": f"SSR {host}:{port}",
            "type": "ssr",
            "server": host,
            "port": int(port),
            "password": password,
            "cipher": cipher,
            "obfs": obfs,  # æ ¹æ®SSRé…ç½®å–å€¼
            "protocol": protocol,  # æ ¹æ®SSRé…ç½®å–å€¼
        }
        return proxy
    except Exception as e:
        print(f"è§£æ SSR èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def parse_vmess_node(node_str):
    """è§£æ Vmess èŠ‚ç‚¹å­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸º Clash æ ¼å¼"""
    try:
        decoded = base64.urlsafe_b64decode(node_str[8:]).decode('utf-8')
        json_data = json.loads(decoded)

        # ç»„è£… Clash èŠ‚ç‚¹æ ¼å¼
        proxy = {
            "name": json_data.get('ps', f"Vmess {json_data.get('add')}:{json_data.get('port')}"),
            "type": "vmess",
            "server": json_data.get('add'),
            "port": int(json_data.get('port')),
            "uuid": json_data.get('id'),
            "alterId": json_data.get('aid'),
            "cipher": json_data.get('net', "none"),
            "tls": (json_data.get('tls') == "tls"),
        }
        return proxy
    except Exception as e:
        print(f"è§£æ Vmess èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def download_subscription(url):
    """ä¸‹è½½å¹¶è§£æè®¢é˜…é“¾æ¥ï¼Œä¼˜å…ˆä½¿ç”¨ wgetï¼Œå¤±è´¥åå°è¯• requests"""
    content = attempt_download_using_wget(url)
    
    if content is None:
        content = attempt_download_using_requests(url)

    if content is None:
        print(f"  âŒ ä¸¤ç§ä¸‹è½½æ–¹å¼å‡å¤±è´¥ï¼Œè·³è¿‡é“¾æ¥: {url}")
        return []

    print(f"  ä¸‹è½½å†…å®¹é•¿åº¦: {len(content)}, å†…å®¹ç¤ºä¾‹: {content[:100]}")  # æ·»åŠ è°ƒè¯•è¾“å‡º

    # åˆ¤æ–­å†…å®¹æ˜¯å¦ä¸º Base64 ç¼–ç 
    if is_base64(content):
        return decode_base64_and_parse(content)

    return parse_proxies_from_content(content)

def get_proxy_key(p):
    """ç”Ÿæˆä»£ç†èŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†"""
    return hashlib.md5(
        f"{p.get('server','')}:{p.get('port',0)}|{p.get('uuid') or p.get('password') or ''}".encode()
    ).hexdigest()

def is_valid_proxy(proxy):
    """éªŒè¯ä»£ç†èŠ‚ç‚¹çš„åè®®æ ¼å¼å’Œæœ‰æ•ˆæ€§"""
    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False

    # è¿›ä¸€æ­¥æ£€æŸ¥åè®®ç±»å‹
    allowed_types = {'http', 'socks5', 'trojan', 'v2ray', 'ss', 'vmess', 'ssr'}
    if 'type' in proxy and proxy['type'] not in allowed_types:
        return False

    # ç¡®ä¿ç«¯å£èŒƒå›´åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if not (1 <= proxy['port'] <= 65535):
        return False

    return True

def process_proxies(proxies):
    """è¿‡æ»¤ã€éªŒè¯ã€è¯†åˆ«åœ°åŒºå¹¶é‡å‘½åèŠ‚ç‚¹"""
    identified = []
    for p in proxies:
        if not is_valid_proxy(p):
            print(f"  âŒ æ— æ•ˆèŠ‚ç‚¹è¢«è¿‡æ»¤: {p.get('name', 'æœªçŸ¥')}")
            continue

        name = JUNK_PATTERNS.sub('', FLAG_EMOJI_PATTERN.sub('', p.get('name', ''))).strip()
        for eng, chn in CHINESE_COUNTRY_MAP.items():
            name = re.sub(r'\b' + re.escape(eng) + r'\b', chn, name, flags=re.IGNORECASE)
        
        for r_name, rules in CUSTOM_REGEX_RULES.items():
            if re.search(rules['pattern'], name, re.IGNORECASE) and r_name in ALLOWED_REGIONS:
                p['region_info'] = {'name': r_name, 'code': rules['code']}
                identified.append(p)
                break

    print(f"  - èŠ‚ç‚¹è¿‡æ»¤: åŸå§‹ {len(proxies)} -> è¯†åˆ«å¹¶ä¿ç•™ {len(identified)}")
    final, counters = [], defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )

    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        if match:
            flag = match.group(0)
        else:
            flag = get_country_flag_emoji(info['code'])

        feature = re.sub(r'\s+', ' ', master_pattern.sub(' ', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).replace('-', ' ')).strip() or f"{sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1:02d}"
        new_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][new_name] += 1
        if counters[info['name']][new_name] > 1:
            new_name += f" {counters[info['name']][new_name]}"
        
        p['name'] = new_name
        final.append(p)

    return final

def test_single_proxy_tcp(proxy):
    """ä½¿ç”¨ TCP è¿æ¥æµ‹é€Ÿï¼ˆå…¼å®¹æ‰€æœ‰åè®®ï¼‰"""
    try:
        start = time.time()
        sock = socket.create_connection(
            (proxy['server'], proxy['port']),
            timeout=SOCKET_TIMEOUT
        )
        sock.close()
        proxy['delay'] = int((time.time() - start) * 1000)
        return proxy
    except Exception:
        return None

def generate_config(proxies):
    """ç”Ÿæˆ Clash é…ç½®æ–‡ä»¶"""
    if not proxies:
        return None
    
    names = [p['name'] for p in proxies]
    clean = [{k: v for k, v in p.items() if k not in ['region_info', 'delay']} for p in proxies]
    
    groups = [
        {
            'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©',
            'type': 'select',
            'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + names,
            'url': TEST_URL,
            'interval': TEST_INTERVAL
        },
        {
            'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©',
            'type': 'url-test',
            'proxies': names,
            'url': TEST_URL,
            'interval': TEST_INTERVAL,
            'tolerance': 50,
            'lazy': True
        },
        {
            'name': 'ğŸ”¯ æ•…éšœè½¬ç§»',
            'type': 'fallback',
            'proxies': names,
            'url': TEST_URL,
            'interval': TEST_INTERVAL,
            'lazy': True
        }
    ]

    return {
        'mixed-port': 7890,
        'allow-lan': True,
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': clean,
        'proxy-groups': groups,
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60 + f"\nClash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V1.R3 @ {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S %Z')}\n" + "=" * 60)
    preprocess_regex_rules()
    print("\n[1/4] ä» Telegram æŠ“å–ã€ä¸‹è½½å¹¶åˆå¹¶èŠ‚ç‚¹...")
    
    urls = await scrape_telegram_links()
    
    if not urls:
        sys.exit("\nâŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆè®¢é˜…é“¾æ¥ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
    
    proxies = {get_proxy_key(p): p for url in urls for p in download_subscription(url) if p}
    
    if not proxies:
        sys.exit("\nâŒ ä¸‹è½½å’Œè§£æåï¼Œæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
    
    print(f"âœ… åˆå¹¶å»é‡åå…± {len(proxies)} ä¸ªèŠ‚ç‚¹ã€‚")
    print("\n[2/4] è¿‡æ»¤ä¸é‡å‘½åèŠ‚ç‚¹...")
    
    processed = process_proxies(list(proxies.values()))
    
    if not processed:
        sys.exit("\nâŒ è¿‡æ»¤åæ— ä»»ä½•å¯ç”¨èŠ‚ç‚¹ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
    
    print("\n[3/4] TCP æµ‹é€Ÿä¸æœ€ç»ˆæ’åº...")
    final = processed
    
    if ENABLE_SPEED_TEST:
        print(f"  - å¼€å§‹ TCP è¿æ¥æµ‹é€Ÿï¼ˆè¶…æ—¶: {SOCKET_TIMEOUT}ç§’ï¼‰...")
        
        with concurrent.futures.ThreadPoolExecutor(MAX_TEST_WORKERS) as executor:
            tested = list(executor.map(test_single_proxy_tcp, processed))
        
        final = [p for p in tested if p]
        print(f"  - æµ‹é€Ÿå®Œæˆ, {len(final)} / {len(processed)} ä¸ªèŠ‚ç‚¹å¯ç”¨ã€‚")
        
        if not final:
            print("\n  âš ï¸ è­¦å‘Š: æµ‹é€Ÿåæ— å¯ç”¨èŠ‚ç‚¹ï¼Œå°†ä½¿ç”¨æ‰€æœ‰è¿‡æ»¤åçš„èŠ‚ç‚¹ã€‚")
            final = processed
    
    final.sort(key=lambda p: (REGION_PRIORITY.index(p['region_info']['name']), p.get('delay', 9999)))
    print(f"âœ… æœ€ç»ˆå¤„ç†å®Œæˆ {len(final)} ä¸ªèŠ‚ç‚¹ã€‚")
    print("\n[4/4] ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶...")
    
    config = generate_config(final)
    
    if not config:
        sys.exit("\nâŒ æ— æ³•ç”Ÿæˆé…ç½®æ–‡ä»¶ã€‚")
    
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2)
    
    print(f"âœ… é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}\n\nğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")

if __name__ == '__main__':
    asyncio.run(main())
