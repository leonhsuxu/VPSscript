# -*- coding: utf-8 -*-
# =====================================================================
# Clash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V2.r1 - 20251203
#
# åŠŸèƒ½ï¼š
# 1. ä» Telegram é¢‘é“åŠ¨æ€æŠ“å–è®¢é˜…é“¾æ¥
# 2. æ”¯æŒä¸¤ç§ä¸‹è½½æ–¹å¼ï¼ˆwgetä¼˜å…ˆï¼Œrequestså¤‡ç”¨ï¼‰
# 3. è®¢é˜…å†…å®¹è‡ªåŠ¨åˆ¤æ–­å¹¶è§£æï¼š
#    - YAML æ ¼å¼ç›´æ¥æå– proxies å­—æ®µ
#    - æ˜æ–‡åè®®é“¾æ¥ï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰é€è¡Œè§£æ
#    - Base64 ç¼–ç çš„æ··åˆåè®®èŠ‚ç‚¹è§£æ
# 4. è§£æè¿‡ç¨‹ä¸­ç»Ÿè®¡å„åè®®æˆåŠŸå’Œå¤±è´¥èŠ‚ç‚¹æ•°é‡ï¼Œç»Ÿä¸€æ‰“å°
# 5. æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ï¼ˆå«emojiå›½æ——ï¼‰ã€TCPæµ‹é€Ÿä¸æ’åºã€æ—§èŠ‚ç‚¹æµ‹é€Ÿå»é‡
# 6. ç”ŸæˆClashå…¼å®¹é…ç½®æ–‡ä»¶
# =====================================================================

import os
import re
import asyncio
import yaml
import base64
import json
import time
import requests
from datetime import datetime, timedelta, timezone
import sys
from collections import defaultdict
import socket
import concurrent.futures
import hashlib
import subprocess
import shutil
from urllib.parse import urlparse, parse_qs, unquote

# --- Telethon ---
from telethon.sync import TelegramClient
from telethon.sessions import StringSession

# ========================== Telegram ä¸ªäººèµ„æ–™é…ç½® ==========================
API_ID = os.environ.get('TELEGRAM_API_ID')  # è·å– Telegram API ID
API_HASH = os.environ.get('TELEGRAM_API_HASH')  # è·å– Telegram API HASH
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')  # è·å– Telegram ä¼šè¯å­—ç¬¦ä¸²

# ========================== é…ç½®åŒº =========================================
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS')  # Telegramé¢‘é“IDï¼Œå¤šè¡Œå­—ç¬¦ä¸²ï¼Œä»ymlå¼•å…¥
TIME_WINDOW_HOURS = 4  # æŠ“å–æ—¶é—´çª—å£ï¼Œå•ä½å°æ—¶
MIN_EXPIRE_HOURS = 3  # è®¢é˜…é“¾æ¥æœ€ä½å‰©ä½™æœ‰æ•ˆæœŸï¼Œå•ä½å°æ—¶
OUTPUT_FILE = 'flclashyaml/telegram_scraper.yaml'  # è¾“å‡ºYAMLè·¯å¾„
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æµ‹é€Ÿ  Trueå¼€å¯ï¼ŒFalseå…³é—­
SOCKET_TIMEOUT = 8  # TCPæµ‹é€Ÿè¶…æ—¶æ—¶é—´(ç§’)
MAX_TEST_WORKERS = 256  # å¹¶å‘æµ‹é€Ÿçº¿ç¨‹æ•°
TEST_URL = 'http://www.gstatic.com/generate_204'  # æµ‹é€Ÿçš„ URL
TEST_INTERVAL = 300  # æµ‹é€Ÿé—´éš”ï¼Œå•ä½ä¸ºç§’


# ========== åœ°åŒºè¿‡æ»¤é…ç½® ==========
ALLOWED_REGIONS = {'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
                   'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½',
                   'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'}
                   
# ALLOWED_REGIONS = set(CUSTOM_REGEX_RULES.keys()) # æˆ–å¯ä½¿ç”¨å·²æœ‰çš„ CUSTOM_REGEX_RULES é”®é›†åˆ


# ========== æ’åºä¼˜å…ˆçº§é…ç½® ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½', 'å°åº¦', 'è²å¾‹å®¾',
                   'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§', 'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©',
                   'å·´è¥¿', 'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš']

# ========== å›½å®¶/åœ°åŒºæ˜ å°„è¡¨ ==========
CHINESE_COUNTRY_MAP = {
    'HK': 'é¦™æ¸¯', 'TW': 'å°æ¹¾', 'JP': 'æ—¥æœ¬', 'SG': 'æ–°åŠ å¡', 'KR': 'éŸ©å›½', 'MY': 'é©¬æ¥è¥¿äºš',
    'TH': 'æ³°å›½', 'IN': 'å°åº¦', 'PH': 'è²å¾‹å®¾', 'ID': 'å°åº¦å°¼è¥¿äºš', 'VN': 'è¶Šå—', 'US': 'ç¾å›½',
    'CA': 'åŠ æ‹¿å¤§', 'FR': 'æ³•å›½', 'GB': 'è‹±å›½', 'DE': 'å¾·å›½', 'RU': 'ä¿„ç½—æ–¯', 'IT': 'æ„å¤§åˆ©',
    'BR': 'å·´è¥¿', 'AR': 'é˜¿æ ¹å»·', 'TR': 'åœŸè€³å…¶', 'AU': 'æ¾³å¤§åˆ©äºš'
}

# ========== åœ°åŒºè¯†åˆ«æ­£åˆ™è§„åˆ™ ==========
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong'},
    'å°æ¹¾': {'code': 'TW', 'pattern': r'å°æ¹¾|å°|TW|Taiwan'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|æ—¥|JP|Japan'},
    'æ–°åŠ å¡': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|SG|Singapore'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|å—æœé²œ|KR|Korea'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|MY|Malaysia'},
    'æ³°å›½': {'code': 'TH', 'pattern': r'æ³°å›½|TH|Thailand'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'è²å¾‹å®¾': {'code': 'PH', 'pattern': r'è²å¾‹å®¾|PH|Philippines'},
    'å°åº¦å°¼è¥¿äºš': {'code': 'ID', 'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|US|USA|United States'},
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|CA|Canada'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|GB|UK|United Kingdom'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
    'ä¿„ç½—æ–¯': {'code': 'RU', 'pattern': r'ä¿„ç½—æ–¯|RU|Russia'},
    'æ„å¤§åˆ©': {'code': 'IT', 'pattern': r'æ„å¤§åˆ©|IT|Italy'},
    'å·´è¥¿': {'code': 'BR', 'pattern': r'å·´è¥¿|BR|Brazil'},
    'é˜¿æ ¹å»·': {'code': 'AR', 'pattern': r'é˜¿æ ¹å»·|AR|Argentina'},
    'åœŸè€³å…¶': {'code': 'TR', 'pattern': r'åœŸè€³å…¶|TR|Turkey'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|AU|Australia'},
}

JUNK_PATTERNS = re.compile(r"(?:ä¸“çº¿|IPLC|ä½“éªŒ|å®˜ç½‘|å€ç‡|x\d[\.\d]*|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)", re.IGNORECASE)
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')



# =================================================================================
# Part 2: å‡½æ•°å®šä¹‰
# =================================================================================

def parse_expire_time(text):
    """è§£ææ¶ˆæ¯ä¸­çš„åˆ°æœŸæ—¶é—´"""
    match = re.search(r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})', text)
    if match:
        try:
            return datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S').replace(tzinfo=timezone(timedelta(hours=8)))
        except ValueError:
            return None
    return None

def is_expire_time_valid(expire_time):
    """æ£€æŸ¥è®¢é˜…é“¾æ¥æ˜¯å¦åœ¨æœ‰æ•ˆæœŸå†…"""
    if expire_time is None:
        return True
    hours_remaining = (expire_time - datetime.now(timezone(timedelta(hours=8)))).total_seconds() / 3600
    if hours_remaining < MIN_EXPIRE_HOURS:
        print(f"  âŒ å·²è·³è¿‡: é“¾æ¥å‰©ä½™æ—¶é—´ ({hours_remaining:.1f} å°æ—¶) å°‘äºæœ€ä½è¦æ±‚ ({MIN_EXPIRE_HOURS} å°æ—¶)")
        return False
    return True

async def scrape_telegram_links():
    """ä» Telegram é¢‘é“æŠ“å–è®¢é˜…é“¾æ¥"""
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return []

    # å¤„ç†é¢‘é“ ID åˆ—è¡¨
    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n') if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return []

    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“: {TARGET_CHANNELS}")

    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return []

    target_time = datetime.now(timezone.utc) - timedelta(hours=TIME_WINDOW_HOURS)
    all_links = set()

    for channel_id in TARGET_CHANNELS:
        print(f"\n--- æ­£åœ¨å¤„ç†é¢‘é“: {channel_id} ---")
        try:
            async for message in client.iter_messages(await client.get_entity(channel_id), limit=500):
                if message.date < target_time:
                    break
                if message.text and is_expire_time_valid(parse_expire_time(message.text)):
                    for url in re.findall(r'(?:è®¢é˜…é“¾æ¥|è®¢é˜…åœ°å€|è®¢é˜…|é“¾æ¥)[\s:ï¼š]*\s*(https?://[^\s<>"*`]+)', message.text):
                        cleaned_url = url.strip().strip('.,*`')
                        if cleaned_url:
                            all_links.add(cleaned_url)
                            print(f"  âœ… æ‰¾åˆ°é“¾æ¥: {cleaned_url[:70]}...")
        except Exception as e:
            print(f"âŒ é”™è¯¯: ä»é¢‘é“ '{channel_id}' è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    await client.disconnect()
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links)

def preprocess_regex_rules():
    """é¢„å¤„ç†æ­£åˆ™è§„åˆ™ï¼šæŒ‰é•¿åº¦æ’åºä»¥ä¼˜åŒ–åŒ¹é…æ•ˆç‡"""
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )


# -------------------- å·¥å…·å‡½æ•° --------------------

def get_country_flag_emoji(code):
    """æ ¹æ®å›½å®¶ä»£ç ç”Ÿæˆæ——å¸œ Emoji"""
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)


def attempt_download_using_wget(url):
    """ä½¿ç”¨ wget ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ wget ä¸‹è½½: {url[:80]}...")
    if not shutil.which("wget"):
        print("  âœ— é”™è¯¯: wget æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œä¸‹è½½ã€‚")
        return None
    try:
        content = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        ).stdout
        return content if content else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget ä¸‹è½½å¤±è´¥: {e.stderr}")
        return None


def attempt_download_using_requests(url):
    """ä½¿ç”¨ requests ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ requests ä¸‹è½½: {url[:80]}...")
    try:
        headers = {'User-Agent': 'Clash'}
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'utf-8'
        return response.text
    except requests.RequestException as e:
        print(f"  âœ— requests ä¸‹è½½å¤±è´¥: {e}")
        return None


def parse_proxies_from_content(content):
    """ä»ä¸‹è½½çš„å†…å®¹ä¸­è§£æä»£ç†èŠ‚ç‚¹"""
    try:
        # å°è¯•è§£æ YAML å†…å®¹
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []


def is_base64(text):
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ Base64 ç¼–ç """
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False


# ---------------- åè®®èŠ‚ç‚¹è§£æ ----------------

def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None


def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None


def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None


def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {'name': name, 'type': 'ss', 'server': server, 'port': port,
                    'cipher': method, 'password': password, 'udp': True}
            return node
        else:
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {'name': remark or f"ss_{server}", 'type': 'ss', 'server': server,
                    'port': int(port), 'cipher': method, 'password': password, 'udp': True}
            return node
    except Exception:
        return None


def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None


def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None


def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception:
        return None


# ---------------- è®¢é˜…è§£æä¸»é€»è¾‘ ----------------

def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies


def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []


def download_subscription(url):
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        print(f"  âŒ ä¸‹è½½å¤±è´¥: {url}")
        return []

    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  - ç›´æ¥ YAML è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  - æ˜æ–‡å†…å®¹è§£æè·å– {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies

    if is_base64(content):
        print(f"  - å†…å®¹ä¸º Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç è§£æ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        else:
            print(f"  - Base64 è§£ç æ— æœ‰æ•ˆèŠ‚ç‚¹")
            return []
    print(f"  - å†…å®¹ä¸ç¬¦åˆå·²çŸ¥æ ¼å¼ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
    return []


def test_single_proxy_tcp(proxy):
    """ä½¿ç”¨ TCP è¿æ¥æµ‹é€Ÿï¼ˆå…¼å®¹æ‰€æœ‰åè®®ï¼‰"""
    try:
        start = time.time()
        with socket.create_connection((proxy['server'], proxy['port']), timeout=SOCKET_TIMEOUT) as sock:
            end = time.time()
            proxy['delay'] = int((end - start) * 1000)
            return proxy
    except Exception:
        return None

def get_proxy_key(p):
    """ç”Ÿæˆä»£ç†èŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†"""
    # ä¼˜å…ˆä½¿ç”¨ uuid/passwordï¼Œç„¶åæ˜¯ server/port ç»„åˆ
    unique_part = p.get('uuid') or p.get('password') or ''
    return hashlib.md5(
        f"{p.get('server','')}:{p.get('port',0)}|{unique_part}".encode()
    ).hexdigest()

def is_valid_proxy(proxy):
    """éªŒè¯ä»£ç†èŠ‚ç‚¹çš„åè®®æ ¼å¼å’Œæœ‰æ•ˆæ€§"""
    if not isinstance(proxy, dict):
        return False
    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False
    # è¿›ä¸€æ­¥æ£€æŸ¥åè®®ç±»å‹
    allowed_types = {'http', 'socks5', 'trojan', 'vless', 'ss', 'vmess', 'ssr', 'hysteria', 'hysteria2'}
    if 'type' in proxy and proxy['type'] not in allowed_types:
        return False
    # ç¡®ä¿ç«¯å£èŒƒå›´åœ¨æœ‰æ•ˆèŒƒå›´å†…
    if not isinstance(proxy['port'], int) or not (1 <= proxy['port'] <= 65535):
        return False
    return True

def process_proxies(proxies):
    """è¿‡æ»¤ã€éªŒè¯ã€è¯†åˆ«åœ°åŒºå¹¶é‡å‘½åèŠ‚ç‚¹"""
    identified = []
    for p in proxies:
        if not is_valid_proxy(p):
            # print(f"  - è¿‡æ»¤æ— æ•ˆèŠ‚ç‚¹: {p.get('name', 'æœªçŸ¥')}")
            continue
        name = JUNK_PATTERNS.sub('', FLAG_EMOJI_PATTERN.sub('', p.get('name', ''))).strip()
        for eng, chn in CHINESE_COUNTRY_MAP.items():
            name = re.sub(r'\b' + re.escape(eng) + r'\b', chn, name, flags=re.IGNORECASE)
        for r_name, rules in CUSTOM_REGEX_RULES.items():
            if re.search(rules['pattern'], name, re.IGNORECASE) and r_name in ALLOWED_REGIONS:
                p['region_info'] = {'name': r_name, 'code': rules['code']}
                identified.append(p)
                break

    print(f"  - èŠ‚ç‚¹è¿‡æ»¤: åŸå§‹ {len(proxies)} -> è¯†åˆ«å¹¶ä¿ç•™ {len(identified)}")
    
    final, counters = [], defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        
        # æ¸…ç†åç§°ä»¥æå–ç‰¹å¾
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name) # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„éå­—æ¯æ•°å­—å­—ç¬¦
        feature = re.sub(r'\s+', ' ', clean_name).strip() or f"{info['code']}{sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1:02d}"
        
        new_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][new_name] += 1
        if counters[info['name']][new_name] > 1:
            new_name += f" {counters[info['name']][new_name]}"
        
        p['name'] = new_name
        final.append(p)
    return final

def delete_old_yaml():
    """æ¯å‘¨ä¸€æ™šä¸Š23:00åˆ é™¤æ—§çš„ YAML æ–‡ä»¶"""
    now = datetime.now(timezone(timedelta(hours=8)))  # åŒ—äº¬æ—¶é—´
    # å‘¨ä¸€(weekday()==0), 23:00-23:59
    if now.weekday() == 0 and now.hour == 23:
        if os.path.exists(OUTPUT_FILE):
            try:
                os.remove(OUTPUT_FILE)
                print(f"âœ… å·²æ ¹æ®è®¡åˆ’åˆ é™¤æ—§çš„é…ç½®æ–‡ä»¶: {OUTPUT_FILE}")
            except OSError as e:
                print(f"âŒ åˆ é™¤æ—§é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def generate_config(proxies):
    """æ ¹æ®ä»£ç†èŠ‚ç‚¹åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„ Clash é…ç½®å­—å…¸"""
    if not proxies:
        return None
    # ä»…åŒ…å«proxiesé”®ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæœ‰æ•ˆçš„Clashä»£ç†æä¾›è€…æ–‡ä»¶
    config = {
        'proxies': proxies,
    }
    return config

async def main():
    print("=" * 60)
    print("Clash è®¢é˜…è‡ªåŠ¨ç”Ÿæˆè„šæœ¬ V2.r1")
    print(f"æ—¶é—´: {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

   
    preprocess_regex_rules()
    # å‘¨ä¸€åˆ é™¤æ—§æ–‡ä»¶
    # delete_old_yaml()  # å–æ¶ˆå®šæœŸåˆ é™¤ï¼Œä¿ç•™å†å²æ–‡ä»¶
    
    # --- æ­¥éª¤ 1: ä» Telegram æŠ“å–æ–°èŠ‚ç‚¹ ---
    print("\n[1/5] ä» Telegram æŠ“å–æ–°èŠ‚ç‚¹...")
    urls = await scrape_telegram_links()
    new_proxies_list = [p for url in urls for p in download_subscription(url) if p] if urls else []
    
    # å»é‡æŠ“å–åˆ°çš„æ–°èŠ‚ç‚¹
    new_proxies_map = {}
    for p in new_proxies_list:
        key = get_proxy_key(p)
        if key not in new_proxies_map:
            new_proxies_map[key] = p
    print(f"âœ… ä» Telegram æŠ“å–å¹¶å»é‡åï¼Œè·å¾— {len(new_proxies_map)} ä¸ªæ–°èŠ‚ç‚¹ã€‚")
    
    # --- æ­¥éª¤ 2: è¯»å–ç°æœ‰èŠ‚ç‚¹ ---
    print("\n[2/5] è¯»å–ç°æœ‰èŠ‚ç‚¹...")
    existing_proxies = []
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict) and 'proxies' in loaded_yaml:
                    if isinstance(loaded_yaml['proxies'], list):
                        existing_proxies = [p for p in loaded_yaml['proxies'] if isinstance(p, dict)]
                        print(f"  - æˆåŠŸè¯»å– {len(existing_proxies)} ä¸ªç°æœ‰èŠ‚ç‚¹ã€‚")
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
                    print(f"  - æˆåŠŸè¯»å– {len(existing_proxies)} ä¸ªç°æœ‰èŠ‚ç‚¹ (æ¥è‡ªæ—§çš„åˆ—è¡¨æ ¼å¼)ã€‚")
        except Exception as e:
            print(f"  - è­¦å‘Š: è¯»å–æˆ–è§£æ {OUTPUT_FILE} å¤±è´¥: {e}ã€‚")

    # æ–°å¢ï¼šå…ˆå¯¹ç°æœ‰(æ—§)èŠ‚ç‚¹æµ‹é€Ÿï¼Œè·å–æœ€æ–°å»¶è¿Ÿä¿¡æ¯
    if ENABLE_SPEED_TEST and existing_proxies:
        print(f"  - å¯¹ç°æœ‰èŠ‚ç‚¹è¿›è¡Œ TCP è¿æ¥æµ‹é€Ÿï¼Œæ•°é‡: {len(existing_proxies)}")
        with concurrent.futures.ThreadPoolExecutor(MAX_TEST_WORKERS) as executor:
            tested_existing = list(executor.map(test_single_proxy_tcp, existing_proxies))
        existing_proxies = [p for p in tested_existing if p]
        print(f"  - ç°æœ‰èŠ‚ç‚¹æµ‹é€Ÿå®Œæˆï¼Œå¯ç”¨èŠ‚ç‚¹æ•°: {len(existing_proxies)}")
    
    # --- æ­¥éª¤ 3: åˆå¹¶å¹¶å»é‡æ‰€æœ‰èŠ‚ç‚¹ ---
    print("\n[3/5] åˆå¹¶å¹¶å»é‡èŠ‚ç‚¹...")
    all_proxies_map = {get_proxy_key(p): p for p in existing_proxies}
    added_count = 0
    for key, p in new_proxies_map.items():
        if key not in all_proxies_map:
            all_proxies_map[key] = p
            added_count += 1
    
    all_proxies_list = list(all_proxies_map.values())
    print(f"âœ… åˆå¹¶å®Œæˆ: æ–°å¢ {added_count} ä¸ªèŠ‚ç‚¹ï¼Œæ€»è®¡ {len(all_proxies_list)} ä¸ªä¸é‡å¤èŠ‚ç‚¹ã€‚")
    
    if not all_proxies_list:
        sys.exit("\nâŒ æ— ä»»ä½•å¯ç”¨èŠ‚ç‚¹ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
    
    # --- æ­¥éª¤ 4: è¿‡æ»¤ã€é‡å‘½åã€æµ‹é€Ÿä¸æ’åº ---
    print("\n[4/5] å¤„ç†ã€æµ‹é€Ÿä¸æ’åºèŠ‚ç‚¹...")
    processed = process_proxies(all_proxies_list)
    if not processed:
        sys.exit("\nâŒ è¿‡æ»¤å’Œé‡å‘½ååæ— ä»»ä½•å¯ç”¨èŠ‚ç‚¹ï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
    final = processed
    if ENABLE_SPEED_TEST:
        print(f"  - å¼€å§‹ TCP è¿æ¥æµ‹é€Ÿï¼ˆè¶…æ—¶: {SOCKET_TIMEOUT}ç§’, å¹¶å‘: {MAX_TEST_WORKERS}ï¼‰...")
        with concurrent.futures.ThreadPoolExecutor(MAX_TEST_WORKERS) as executor:
            tested = list(executor.map(test_single_proxy_tcp, processed))
        
        final = [p for p in tested if p]
        print(f"  - æµ‹é€Ÿå®Œæˆ, {len(final)} / {len(processed)} ä¸ªèŠ‚ç‚¹å¯ç”¨ã€‚")
        
        if not final:
            print("\n  âš ï¸ è­¦å‘Š: æµ‹é€Ÿåæ— å¯ç”¨èŠ‚ç‚¹ï¼Œå°†ä½¿ç”¨æ‰€æœ‰è¿‡æ»¤åçš„èŠ‚ç‚¹ã€‚")
            final = processed
    
    # æ’åº
    final.sort(key=lambda p: (REGION_PRIORITY.index(p['region_info']['name']) if p['region_info']['name'] in REGION_PRIORITY else 99, p.get('delay', 9999)))
    print(f"âœ… æœ€ç»ˆå¤„ç†å®Œæˆ {len(final)} ä¸ªèŠ‚ç‚¹ã€‚")
    
    # --- æ­¥éª¤ 5: ç”Ÿæˆå¹¶å†™å…¥æœ€ç»ˆé…ç½®æ–‡ä»¶ ---
    print("\n[5/5] ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶...")
    config = generate_config(final)
    if not config:
        sys.exit("\nâŒ æ— æ³•ç”Ÿæˆé…ç½®æ–‡ä»¶ã€‚")
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2)
        print(f"âœ… é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}\n\nğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ å†™å…¥æœ€ç»ˆé…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

if __name__ == '__main__':
    asyncio.run(main())
