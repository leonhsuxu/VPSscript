# -*- coding: utf-8 -*-
"""
æ–‡ä»¶å: Telegram.ä¸‰åˆä¸€ R2 
è„šæœ¬è¯´æ˜:ä½¿ç”¨XC speedtestæµ‹é€Ÿ
æœ¬è„šæœ¬å®ç°ä»æŒ‡å®š Telegram é¢‘é“è‡ªåŠ¨çˆ¬å–è®¢é˜…é“¾æ¥ï¼›
ä¸‹è½½å¹¶è§£æå„ç§ä»£ç†è®¢é˜…èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ vmess, vless, ssr, ss, trojan, hysteriaåŠhysteria2ç­‰åè®®ï¼‰ï¼Œ
æ”¯æŒèŠ‚ç‚¹å»é‡ã€åœ°åŒºè¯†åˆ«ä¸é‡å‘½åï¼Œå¹¶ä½¿ç”¨ Clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆå»¶è¿Ÿæµ‹è¯•ï¼‰ï¼›
æœ€ç»ˆç”Ÿæˆå¯ç”¨äº Clash ä½¿ç”¨çš„ YAML é…ç½®æ–‡ä»¶ã€‚
ä¸»è¦åŠŸèƒ½:
1. ä» Telegram æŒ‡å®šé¢‘é“æŠ“å–å¸¦æœ‰è®¢é˜…é“¾æ¥çš„æ¶ˆæ¯ï¼Œæ”¯æŒæ—¶é—´çª—å£è¿‡æ»¤æ–°æ¶ˆæ¯ã€‚
2. æ”¯æŒå¤šç§å¸¸è§ä»£ç†åè®®çš„èŠ‚ç‚¹è§£æï¼Œä»¥åŠè¯†åˆ«èŠ‚ç‚¹æ‰€åœ¨åŒºåŸŸã€‚
3. é‡‡ç”¨å‘½ä»¤è¡Œæ¨¡å¼è°ƒç”¨ clash æ ¸å¿ƒç¨‹åºè¿›è¡ŒèŠ‚ç‚¹å»¶è¿Ÿæµ‹è¯•ï¼Œç­›é€‰æœ‰æ•ˆèŠ‚ç‚¹ã€‚
4. æ ¹æ®èŠ‚ç‚¹åœ°åŒºä¸å»¶è¿Ÿè‡ªåŠ¨æ’åºå’Œå½’ç±»ï¼Œç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶ã€‚
5. ç¯å¢ƒå˜é‡é…ç½®çµæ´»ï¼Œæ–¹ä¾¿é›†æˆè‡ªåŠ¨åŒ–æµç¨‹ã€‚
"""
import os
import re
import sys
import base64
import json
import yaml
import time
import socket
import hashlib
import asyncio
import shutil
import subprocess
import concurrent.futures
import tempfile
import requests
import socket
# === æ–°å¢è¿™å‡ è¡Œï¼Œè­¦å‘Šç«‹åˆ»æ¶ˆå¤± ===
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="urllib3.connectionpool")
# ============================================
from concurrent.futures import as_completed
from urllib.parse import urlparse, parse_qs, unquote
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
BJ_TZ = timezone(timedelta(hours=8)) 
last_message_id_timestamps = {}
# --- ç¯å¢ƒå˜é‡è¯»å– ---
API_ID = int(os.environ.get('TELEGRAM_API_ID') or 0)
API_HASH = os.environ.get('TELEGRAM_API_HASH')
STRING_SESSION = os.environ.get('TELEGRAM_STRING_SESSION')
TELEGRAM_CHANNEL_IDS_STR = os.environ.get('TELEGRAM_CHANNEL_IDS', '')
TIME_WINDOW_HOURS = 10  # æŠ“å–å¤šé•¿æ—¶é—´çš„æ¶ˆæ¯ï¼Œå•ä½ä¸ºå°æ—¶ã€‚
MIN_EXPIRE_HOURS = 2   # è®¢é˜…åœ°å€å‰©ä½™æ—¶é—´æœ€å°è¿‡æœŸï¼Œå•ä½ä¸ºå°æ—¶ã€‚
OUTPUT_FILE = 'flclashyaml/Tg-node2.yaml'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºä¿å­˜ç”Ÿæˆçš„é…ç½®æˆ–ç»“æœã€‚
last_warp_start_time = 0
# === æ–°å¢ï¼šæµ‹é€Ÿç­–ç•¥å¼€å…³ï¼ˆæ¨èä¿ç•™è¿™å‡ ä¸ªé€‰é¡¹ï¼‰===
# æµ‹é€Ÿæ¨¡å¼ï¼š
ENABLE_SPEED_TEST = True  # æ˜¯å¦å¯ç”¨æ•´ä½“é€Ÿåº¦æµ‹è¯•åŠŸèƒ½ï¼ŒTrueè¡¨ç¤ºå¯ç”¨ã€‚æµ‹è¯•é¡ºåºå¦‚ä¸‹
#SPEEDTEST_MODE = os.getenv('SPEEDTEST_MODE', 'tcp_first').lower()  # é»˜è®¤æ¨è tcp_first,ä¸‹è¾¹çš„å‘½ä»¤
#   "tcp_only"      â†’ åªç”¨ TCP æµ‹é€Ÿï¼ˆæœ€å¿«ï¼Œæœ€ä¸¥æ ¼ï¼Œé€‚åˆèŠ‚ç‚¹ç‰¹åˆ«å¤šçš„æƒ…å†µï¼‰
#   "clash_only"    â†’ åªç”¨ Clash -fast æµ‹é€Ÿï¼ˆæœ€å‡†ï¼‰
#   "tcp_first"     â†’ å…ˆ TCP ç²—ç­›ï¼ˆ<800msï¼‰â†’ å† Clash ç²¾æµ‹ï¼ˆæ¨èï¼å¹³è¡¡é€Ÿåº¦ä¸è´¨é‡ï¼‰
#   "clash_first"   â†’ å…ˆ Clash â†’ å† TCPï¼ˆä¸€èˆ¬ç”¨ä¸ä¸Šï¼‰
DETAILED_SPEEDTEST_MODE = os.getenv('DETAILED_SPEEDTEST_MODE', '').lower().strip()  # æ–°å¢è¯¦ç»†æµ‹é€Ÿæ¨¡å¼æ§åˆ¶å˜é‡
if not DETAILED_SPEEDTEST_MODE:
    print("â—ï¸é”™è¯¯: æœªè®¾ç½®ç¯å¢ƒå˜é‡ DETAILED_SPEEDTEST_MODEï¼Œç¨‹åºé€€å‡ºã€‚")
    sys.exit(1)
# TCP å’ŒClash æµ‹é€Ÿä¸“å±å‚æ•°
TCP_TIMEOUT = 5          # å•æ¬¡ TCP è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå»ºè®® 3~5
TCP_MAX_WORKERS = 256     # TCP æµ‹é€Ÿæœ€å¤§å¹¶å‘ï¼ˆå¯ä»¥æ¯” Clash é«˜å¾ˆå¤šï¼Œéå¸¸å¿«ï¼‰
TCP_MAX_DELAY = 1500       # TCP å»¶è¿Ÿé˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼ç›´æ¥ä¸¢å¼ƒï¼ˆmsï¼‰
# TCP å’ŒClash æ—¥å¿—ç¯å¢ƒå˜é‡ä¸“å±å‚æ•°
def str_to_bool(s: str) -> bool:
    return s.strip().lower() in ('true', '1', 'yes')
    
ENABLE_TCP_LOG = str_to_bool(os.getenv('ENABLE_TCP_LOG', 'false'))  # ä»ymlå¼•å…¥å˜é‡
ENABLE_SPEEDTEST_LOG = str_to_bool(os.getenv('ENABLE_SPEEDTEST_LOG', 'false')) # ä»ymlå¼•å…¥å˜é‡
# æµ‹é€Ÿçº¿ç¨‹å’Œè¶…æ—¶å‚æ•°
MAX_TEST_WORKERS = 64    # é€Ÿåº¦æµ‹è¯•æ—¶æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼Œæ§åˆ¶æµ‹è¯•çš„å¹¶è¡Œåº¦ã€‚å»ºè®®64-96
SOCKET_TIMEOUT = 3       # å¥—æ¥å­—è¿æ¥è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
HTTP_TIMEOUT = 5         # HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
# ã€å…³é”®ä¿®æ”¹1ã€‘æµ‹é€Ÿç›®æ ‡å…¨éƒ¨æ¢æˆå›½å†…/Cloudflareä¸­å›½èŠ‚ç‚¹
TEST_URLS_GITHUB = [
    "https://www.google.com/generate_204",
]
TEST_URLS_WARP = [
    'http://www.baidu.com/generate_204',
]
# ==================== æµ‹é€Ÿç»“æœ_å¸¦å®½ç­›é€‰é…ç½®ï¼ˆæ–°å¢ï¼‰ ====================
# æ˜¯å¦å¯ç”¨å¸¦å®½ç­›é€‰ï¼ˆTrue=å¯ç”¨ï¼ŒFalse=å…³é—­ï¼‰
ENABLE_BANDWIDTH_FILTER = os.getenv('ENABLE_BANDWIDTH_FILTER', 'true').lower() == 'true'
# æœ€ä½å¸¦å®½é˜ˆå€¼ï¼ˆå•ä½ï¼šMB/sï¼‰
# æ”¯æŒç¯å¢ƒå˜é‡è®¾ç½®ï¼Œä¾‹å¦‚åœ¨ GitHub Actions é‡Œè¿™æ ·å†™ï¼š
# ENABLE_BANDWIDTH_FILTER=true
# MIN_BANDWIDTH_MB=30
MIN_BANDWIDTH_MB = float(os.getenv('MIN_BANDWIDTH_MB', '25'))  # ç­›é€‰æµ‹é€Ÿå®½åº¦çš„é€Ÿåº¦ã€‚é»˜è®¤ 25MB/sï¼Œå¯è‡ªç”±æ”¹
# ==================== å›½å®¶åŒ¹é…é…ç½® ====================
ALLOWED_REGIONS = {
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
}
REGION_PRIORITY = [
    'é¦™æ¸¯', 'å°æ¹¾', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'éŸ©å›½', 'é©¬æ¥è¥¿äºš', 'æ³°å›½',
    'å°åº¦', 'è²å¾‹å®¾', 'å°åº¦å°¼è¥¿äºš', 'è¶Šå—', 'ç¾å›½', 'åŠ æ‹¿å¤§',
    'æ³•å›½', 'è‹±å›½', 'å¾·å›½', 'ä¿„ç½—æ–¯', 'æ„å¤§åˆ©', 'å·´è¥¿',
    'é˜¿æ ¹å»·', 'åœŸè€³å…¶', 'æ¾³å¤§åˆ©äºš'
]
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {
        'code': 'HK',
        'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong|HongKong|HKBN|HGC|PCCW|WTT|HKT|ä¹é¾™|æ²™ç”°|å±¯é—¨|èƒæ¹¾|æ·±æ°´åŸ—|æ²¹å°–æ—º'
    },
    'æ—¥æœ¬': {
        'code': 'JP',
        'pattern': r'æ—¥æœ¬|æ—¥|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|äº¬æ—¥|å¹¿æ—¥|JP|Japan|Tokyo|Osaka|Saitama|åŸ¼ç‰|åå¤å±‹|Nagoya|ç¦å†ˆ|Fukuoka|æ¨ªæ»¨|Yokohama|NTT|IIJ|GMO|Linode'
    },
    'æ–°åŠ å¡': {
        'code': 'SG',
        'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|ç‹®|æ–°|SG|Singapore|SG\d+|SGP|æ˜Ÿ|ç‹®å­åŸ'
    },
    'ç¾å›½': {
        'code': 'US',
        'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|ä¿„å‹’å†ˆ|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥|çº½çº¦|è¿ˆé˜¿å¯†|äºšç‰¹å…°å¤§|US|USA|United\s*States|America|LA|NYC|SF|San\s*Francisco|Washington|åç››é¡¿|Kansas|å ªè¨æ–¯|Denver|ä¸¹ä½›|Phoenix|Seattle|Chicago|Boston|æ³¢å£«é¡¿|Atlanta|Miami|Las\s*Vegas'
    },
    'å°æ¹¾': {
        'code': 'TW',
        'pattern': r'å°æ¹¾|æ¹¾çœ|å°|TW|Taiwan|TWN|å°åŒ—|Taipei|å°ä¸­|Taichung|é«˜é›„|Kaohsiung|æ–°åŒ—|å½°åŒ–|Hinet|ä¸­åç”µä¿¡'
    },
    'éŸ©å›½': {
        'code': 'KR',
        'pattern': r'éŸ©å›½|éŸ©|å—æœé²œ|é¦–å°”|é‡œå±±|ä»å·|KR|Korea|KOR|éŸ“|Seoul|Busan|KT|SK|LG'
    },
    'å¾·å›½': {
        'code': 'DE',
        'pattern': r'å¾·å›½|å¾·|æ³•å…°å…‹ç¦|æ…•å°¼é»‘|æŸæ—|DE|Germany|Frankfurt|Munich|Berlin|Hetzner'
    },
    'è‹±å›½': {
        'code': 'GB',
        'pattern': r'è‹±å›½|è‹±|ä¼¦æ•¦|æ›¼å½»æ–¯ç‰¹|UK|GB|United\s*Kingdom|Britain|England|London|Manchester'
    },
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
    'è¶Šå—': {'code': 'VN', 'pattern': r'è¶Šå—|VN|Vietnam'},
    'å°åº¦': {'code': 'IN', 'pattern': r'å°åº¦|IN|India'},
    'é©¬æ¥è¥¿äºš': {'code': 'MY', 'pattern': r'é©¬æ¥è¥¿äºš|é©¬æ¥|MY|Malaysia'},
    'æ³•å›½': {'code': 'FR', 'pattern': r'æ³•å›½|FR|France'},
    'æ³°å›½': {
    'code': 'TH',
    'pattern': r'æ³°å›½|TH|Thailand|æ›¼è°·|Bangkok'
},
    'è²å¾‹å®¾': {
    'code': 'PH',
    'pattern': r'è²å¾‹å®¾|PH|Philippines|é©¬å°¼æ‹‰|Manila'
},
    'å°åº¦å°¼è¥¿äºš': {
    'code': 'ID',
    'pattern': r'å°åº¦å°¼è¥¿äºš|å°å°¼|ID|Indonesia|é›…åŠ è¾¾|Jakarta'
},
    'ä¿„ç½—æ–¯': {
    'code': 'RU',
    'pattern': r'ä¿„ç½—æ–¯|RU|Russia|è«æ–¯ç§‘|Moscow'
},
    'æ„å¤§åˆ©': {
    'code': 'IT',
    'pattern': r'æ„å¤§åˆ©|IT|Italy|ç½—é©¬|Rome'
},
    'å·´è¥¿': {
    'code': 'BR',
    'pattern': r'å·´è¥¿|BR|Brazil|åœ£ä¿ç½—|SÃ£o\s*Paulo'
},
    'é˜¿æ ¹å»·': {
    'code': 'AR',
    'pattern': r'é˜¿æ ¹å»·|AR|Argentina|å¸ƒå®œè¯ºæ–¯è‰¾åˆ©æ–¯|Buenos\s*Aires'
},
    'åœŸè€³å…¶': {
    'code': 'TR',
    'pattern': r'åœŸè€³å…¶|TR|Turkey|ä¼Šæ–¯å¦å¸ƒå°”|Istanbul'
}
}
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')
BJ_TZ = timezone(timedelta(hours=8))
def do_speed_test():
    if not ENABLE_SPEED_TEST:
        print("æµ‹é€ŸåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡ã€‚")
        return
    # å¯ç”¨æµ‹é€Ÿå¹¶æ‰“å°æ—¥å¿—
    run_speedtest(enable_tcp_log=False)
# å…¨å±€æ ‡å¿—ï¼Œç”¨äºæ§åˆ¶ get_test_urls() å‡½æ•°ä¸­æ—¥å¿—çš„æ‰“å°æ¬¡æ•°
_test_urls_log_printed = False
# ==================== æ ¹æ®ç½‘ç»œé€‰æ‹©æµ‹é€Ÿåœ°å€ï¼Œåœ°å€å¦‚ä¸Šå˜é‡ ====================
def get_test_urls():
    global _test_urls_log_printed # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
    
    if not _test_urls_log_printed: # åªæœ‰å½“æ—¥å¿—æœªæ‰“å°è¿‡æ—¶æ‰æ‰“å°
        if is_warp_enabled():
            print("æ£€æµ‹åˆ° Warp ç½‘ç»œï¼Œä½¿ç”¨å›½å†…æµ‹é€Ÿåœ°å€")
            _test_urls_log_printed = True # è®¾ç½®æ ‡å¿—ä¸º Trueï¼Œè¡¨ç¤ºå·²æ‰“å°
            return TEST_URLS_WARP
        else:
            print("é Warp ç½‘ç»œï¼Œä½¿ç”¨è°·æ­Œæµ‹é€Ÿåœ°å€")
            _test_urls_log_printed = True # è®¾ç½®æ ‡å¿—ä¸º Trueï¼Œè¡¨ç¤ºå·²æ‰“å°
            return TEST_URLS_GITHUB
    else: # å¦‚æœå·²æ‰“å°è¿‡ï¼Œåˆ™ç›´æ¥è¿”å›åœ°å€ï¼Œä¸å†æ‰“å°æ—¥å¿—
        if is_warp_enabled():
            return TEST_URLS_WARP
        else:
            return TEST_URLS_GITHUB
# ==================== æ™ºèƒ½ç½‘ç»œæ§åˆ¶é…ç½® ====================
def get_network_config():
    """
    è·å–ç½‘ç»œé…ç½®ï¼Œå¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨åˆ™ä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼å¹¶è­¦å‘Š
    è¿”å›é…ç½®å­—å…¸å’Œæ˜¯å¦æ‰€æœ‰é…ç½®éƒ½æ¥è‡ªç¯å¢ƒå˜é‡
    """
    config = {}
    all_from_env = True
    
    # é…ç½®æ˜ å°„è¡¨ï¼šç¯å¢ƒå˜é‡å -> é»˜è®¤å€¼ -> æè¿°
    config_spec = {
        'WARP_FOR_SCRAPING': {
            'default': False, 
            'desc': 'TelegramæŠ“å–é˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'falseï¼ˆä½¿ç”¨GitHubç½‘ç»œï¼Œé€Ÿåº¦å¿«ï¼‰'
        },
        'WARP_FOR_TCP': {
            'default': True, 
            'desc': 'TCPæµ‹é€Ÿé˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'trueï¼ˆä½¿ç”¨Warpæ¨¡æ‹Ÿå›½å†…ç¯å¢ƒï¼‰'
        },
        'WARP_FOR_SPEEDTEST': {
            'default': True, 
            'desc': 'Speedtestæµ‹é€Ÿé˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'trueï¼ˆä½¿ç”¨Warpæ¨¡æ‹Ÿå›½å†…ç¯å¢ƒï¼‰'
        },
        'WARP_FOR_FINAL': {
            'default': False, 
            'desc': 'æœ€ç»ˆå¤„ç†é˜¶æ®µä½¿ç”¨Warpç½‘ç»œ',
            'recommend': 'falseï¼ˆåˆ‡æ¢å›GitHubç½‘ç»œï¼‰'
        },
    }
    
    print("ğŸ”§ ç½‘ç»œé…ç½®æ£€æŸ¥:")
    print("-" * 50)
    
    for env_name, spec in config_spec.items():
        env_value = os.getenv(env_name)
        if env_value is None:
            # ç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            config[env_name] = spec['default']
            all_from_env = False
            print(f"âš ï¸  {env_name}: æœªè®¾ç½® â†’ ä½¿ç”¨é»˜è®¤å€¼: {spec['default']}")
            print(f"   æè¿°: {spec['desc']}")
            print(f"   å»ºè®®: {spec['recommend']}")
            print(f"   è®¾ç½®æ–¹æ³•: åœ¨GitHub Actions YMLä¸­æ·»åŠ : {env_name}: '{str(spec['default']).lower()}'")
        else:
            # ç¯å¢ƒå˜é‡å­˜åœ¨ï¼Œè½¬æ¢ä¸ºå¸ƒå°”å€¼
            config[env_name] = env_value.lower() == 'true'
            print(f"âœ…  {env_name}: å·²è®¾ç½® â†’ {env_value}")
    
    print("-" * 50)
    
    if not all_from_env:
        print("ğŸ“ æç¤º: éƒ¨åˆ†é…ç½®ä½¿ç”¨é»˜è®¤å€¼ï¼Œå»ºè®®åœ¨GitHub Actions YMLä¸­å®Œæ•´é…ç½®")
        print("       è¿™æ ·å¯ä»¥è·å¾—æ›´å¯æ§çš„ç½‘ç»œè¡Œä¸ºå’Œæ›´å¥½çš„æµ‹é€Ÿç»“æœ")
    else:
        print("ğŸ¯ æ‰€æœ‰ç½‘ç»œé…ç½®å‡æ¥è‡ªç¯å¢ƒå˜é‡ï¼Œé…ç½®å®Œæ•´ï¼")
    
    return config
# è·å–ç½‘ç»œé…ç½®
network_config = get_network_config()
WARP_FOR_SCRAPING = network_config['WARP_FOR_SCRAPING']
WARP_FOR_TCP = network_config['WARP_FOR_TCP']
WARP_FOR_SPEEDTEST = network_config['WARP_FOR_SPEEDTEST']
WARP_FOR_FINAL = network_config['WARP_FOR_FINAL']
# ==================== å®Œæ•´çš„ç½‘ç»œæ§åˆ¶å‡½æ•° ====================
def get_current_ip():
    """è·å–å½“å‰å‡ºå£IPï¼Œå¢å¼ºå®¹é”™æ€§"""
    try:
        # å°è¯•å¤šä¸ªIPæ£€æµ‹æœåŠ¡
        ip_services = [
            "https://api.ipify.org",
            "https://ipinfo.io/ip",
            "https://ifconfig.me/ip",
            "https://ip.sb",
            "https://checkip.amazonaws.com"
        ]
        
        for service in ip_services:
            try:
                result = subprocess.run(
                    ["curl", "-4", "-s", "--max-time", "5", service],
                    capture_output=True, text=True, timeout=6
                )
                if result.returncode == 0 and result.stdout.strip():
                    ip = result.stdout.strip()
                    # éªŒè¯IPæ ¼å¼
                    if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', ip):
                        # åˆ¤æ–­æ˜¯å¦ä¸ºWarp IP
                        warp_prefixes = ['162.159.192.', '162.159.193.', '162.159.195.', 
                                       '172.64.240.', '172.64.241.', '172.64.242.', '172.64.243.']
                        for prefix in warp_prefixes:
                            if ip.startswith(prefix):
                                return f"{ip} (ğŸŒ Warpç½‘ç»œ)"
                        return f"{ip} (ğŸ’» åŸå§‹ç½‘ç»œ)"
            except:
                continue
        
        # å¦‚æœæ‰€æœ‰æœåŠ¡éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥æŸ¥è¯¢è·¯ç”±è¡¨
        try:
            result = subprocess.run(
                ["ip", "route", "get", "1"],
                capture_output=True, text=True, timeout=3
            )
            lines = result.stdout.split('\n')
            for line in lines:
                if 'src' in line:
                    parts = line.split()
                    for i, part in enumerate(parts):
                        if part == 'src':
                            ip = parts[i+1]
                            if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', ip):
                                return f"{ip} (ğŸ“¡ æœ¬åœ°è·¯ç”±)"
        except:
            pass
        
        return "unknown (æ— æ³•è·å–)"
        
    except Exception as e:
        return f"unknown (å¼‚å¸¸: {str(e)[:30]})"
        
# == æ£€æŸ¥warp ==
def is_warp_enabled():
    """æ£€æŸ¥Warpæ˜¯å¦å¯ç”¨"""
    try:
        result = subprocess.run(
            ["wg", "show"],
            capture_output=True, text=True,
            timeout=3
        )
        # æ£€æŸ¥wgcfæ¥å£æ˜¯å¦å­˜åœ¨
        if result.returncode == 0 and "wgcf" in result.stdout:
            return True
        
        # é¢å¤–æ£€æŸ¥wg-quickçŠ¶æ€
        result2 = subprocess.run(
            ["ip", "link", "show", "wgcf"],
            capture_output=True, text=True,
            timeout=2
        )
        return result2.returncode == 0
        
    except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
        return False
# == å¼€å¯warpé…ç½®===          
def start_cloudflare_warp():
    """
    åœ¨ GitHub Actions ä¸­å¯ç”¨ Cloudflare Warp
    æ¨¡æ‹Ÿå›½å†…ç½‘ç»œç¯å¢ƒï¼Œä½¿æµ‹é€Ÿç»“æœå¯¹å›½å†…ç”¨æˆ·æœ‰æ•ˆ
    """
    print("ğŸŒ æ­£åœ¨å¯åŠ¨ Cloudflare Warpï¼ˆæ¨¡æ‹Ÿå›½å†…ç½‘ç»œç¯å¢ƒï¼‰...")
    print("=" * 60)
    
    # å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»åœ¨WarpçŠ¶æ€
    current_warp = is_warp_enabled()
    if current_warp:
        current_ip = get_current_ip()
        print("âœ… Warpå·²å¯ç”¨ï¼Œå½“å‰çŠ¶æ€:")
        print(f"   IPåœ°å€: {current_ip}")
        print("   ğŸ“ æ— éœ€é‡æ–°å¯åŠ¨")
        return True
    
    # è®°å½•å¼€å§‹æ—¶é—´ï¼Œé¿å…çŸ­æ—¶é—´å†…é‡å¤å¯åŠ¨
    global last_warp_start_time
    current_time = time.time()
    
    # å¦‚æœä¸Šæ¬¡å¯åŠ¨åœ¨30ç§’å†…ï¼Œç›´æ¥è¿”å›
    if 'last_warp_start_time' in globals() and current_time - last_warp_start_time < 30:
        print("ğŸ•’ ä¸Šæ¬¡å¯åŠ¨ä¸åˆ°30ç§’ï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
        return True
    
    last_warp_start_time = current_time
    
    try:
        # 1. æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§é…ç½®ï¼ˆå®‰å…¨æ¸…ç†ï¼‰
        print("1ï¸âƒ£ æ¸…ç†æ—§é…ç½®...")
        # ä½¿ç”¨æ­£ç¡®çš„subprocessè°ƒç”¨æ–¹å¼
        try:
            subprocess.run(
                ["sudo", "wg-quick", "down", "wgcf"],
                capture_output=True,  # åªä½¿ç”¨capture_output
                timeout=10
            )
        except subprocess.TimeoutExpired:
            print("   â° æ¸…ç†è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ")
        
        # ç­‰å¾…æ¸…ç†å®Œæˆ
        time.sleep(1)
        
        # 2. æ£€æŸ¥å¹¶å®‰è£…å¿…è¦å·¥å…·
        print("2ï¸âƒ£ æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
        required_tools = ["wg-quick", "curl", "resolvconf"]
        missing_tools = []
        
        for tool in required_tools:
            if not shutil.which(tool):
                missing_tools.append(tool)
        
        if missing_tools:
            print(f"   å®‰è£…ç¼ºå¤±å·¥å…·: {', '.join(missing_tools)}")
            subprocess.run(
                ["sudo", "apt-get", "update", "-qq"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            subprocess.run(
                ["sudo", "apt-get", "install", "-y", "wireguard-tools", "curl", "resolvconf"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
        else:
            print("   âœ… æ‰€æœ‰å·¥å…·å·²å®‰è£…")
        
        # 3. ä¸‹è½½ wgcf å·¥å…·ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        wgcf_path = "./wgcf"
        if not os.path.exists(wgcf_path) or not os.access(wgcf_path, os.X_OK):
            print("3ï¸âƒ£ ä¸‹è½½ wgcf å·¥å…·...")
            try:
                # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„curlå‚æ•°
                result = subprocess.run([
                    "curl", "-fsSL", "-o", wgcf_path,
                    "https://github.com/ViRb3/wgcf/releases/download/v2.2.29/wgcf_2.2.29_linux_amd64"
                ], timeout=30)
                
                if result.returncode == 0:
                    os.chmod(wgcf_path, 0o755)
                    print("   âœ… wgcf ä¸‹è½½æˆåŠŸ")
                else:
                    print(f"   âŒ wgcf ä¸‹è½½å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                    # å°è¯•å¤‡ç”¨ä¸‹è½½æº
                    print("   å°è¯•å¤‡ç”¨ä¸‹è½½æº...")
                    subprocess.run([
                        "wget", "-qO", wgcf_path,
                        "https://github.com/ViRb3/wgcf/releases/download/v2.2.29/wgcf_2.2.29_linux_amd64"
                    ], timeout=30)
                    if os.path.exists(wgcf_path):
                        os.chmod(wgcf_path, 0o755)
                        print("   âœ… wgcf å¤‡ç”¨ä¸‹è½½æˆåŠŸ")
                    else:
                        print("   âŒ wgcf ä¸‹è½½å…¨éƒ¨å¤±è´¥")
                        return False
                        
            except Exception as e:
                print(f"   âŒ wgcf ä¸‹è½½å¼‚å¸¸: {e}")
                return False
        else:
            print("   âœ… wgcf å·²å­˜åœ¨")
        
        # 4. ç”Ÿæˆé…ç½®æ–‡ä»¶
        config_file = "wgcf-profile.conf"
        if not os.path.exists(config_file):
            print("4ï¸âƒ£ ç”Ÿæˆ WARP é…ç½®æ–‡ä»¶...")
            try:
                # æ³¨å†ŒWarpè´¦æˆ·
                register_result = subprocess.run(
                    [wgcf_path, "register", "--accept-tos"],
                    stdout=subprocess.PIPE,  # åˆ†å¼€æŒ‡å®š
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=60
                )
                if register_result.returncode != 0:
                    print(f"   âš ï¸  æ³¨å†Œè­¦å‘Š: {register_result.stderr[:100]}")
                
                # ç”Ÿæˆé…ç½®æ–‡ä»¶
                generate_result = subprocess.run(
                    [wgcf_path, "generate"],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    timeout=60
                )
                
                if generate_result.returncode == 0 and os.path.exists(config_file):
                    print("   âœ… é…ç½®æ–‡ä»¶ç”ŸæˆæˆåŠŸ")
                else:
                    print(f"   âŒ é…ç½®æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {generate_result.stderr[:100]}")
                    # å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®
                    print("   å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®...")
                    create_backup_config(config_file)
                    
            except Exception as e:
                print(f"   âŒ é…ç½®ç”Ÿæˆå¼‚å¸¸: {e}")
                create_backup_config(config_file)
        else:
            print("   âœ… é…ç½®æ–‡ä»¶å·²å­˜åœ¨")
        
        # 5. å®‰è£…é…ç½®æ–‡ä»¶
        print("5ï¸âƒ£ å®‰è£… WARP é…ç½®...")
        try:
            subprocess.run(["sudo", "mkdir", "-p", "/etc/wireguard"], 
                         stdout=subprocess.DEVNULL,
                         stderr=subprocess.DEVNULL)
            subprocess.run(["sudo", "cp", config_file, "/etc/wireguard/wgcf.conf"], 
                         stdout=subprocess.DEVNULL,
                         stderr=subprocess.DEVNULL)
            print("   âœ… é…ç½®æ–‡ä»¶å®‰è£…æˆåŠŸ")
        except Exception as e:
            print(f"   âŒ é…ç½®æ–‡ä»¶å®‰è£…å¤±è´¥: {e}")
            return False
        
        # 6. å¯åŠ¨ WARP
        print("6ï¸âƒ£ å¯åŠ¨ WARP VPN...")
        try:
            start_result = subprocess.run(
                ["sudo", "wg-quick", "up", "wgcf"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=30
            )
            
            # æ£€æŸ¥å¯åŠ¨ç»“æœ
            if start_result.returncode == 0:
                print("       ğŸˆ¶  WARP å¯åŠ¨æˆåŠŸ")
            else:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å…¶ä»–Warpè¿æ¥
                if "already exists" in start_result.stderr:
                    print("   âš ï¸  WARPè¿æ¥å·²å­˜åœ¨")
                else:
                    print(f"   âš ï¸  WARPå¯åŠ¨è­¦å‘Š: {start_result.stderr[:200]}")
        
        except subprocess.TimeoutExpired:
            print("   âš ï¸  WARPå¯åŠ¨è¶…æ—¶ï¼Œä½†å¯èƒ½å·²æˆåŠŸ")
        except Exception as e:
            print(f"   âŒ WARPå¯åŠ¨å¼‚å¸¸: {e}")
            return False
        
        # 7. éªŒè¯å¯åŠ¨ç»“æœ, åˆ¤æ–­ Warp æ˜¯å¦å·²ç»å¯ç”¨
        print("7ï¸âƒ£ éªŒè¯è¿æ¥çŠ¶æ€...")
        time.sleep(2)  # ç­‰å¾…ç½‘ç»œç¨³å®š
        
        if is_warp_enabled():
            current_ip = get_current_ip()
            print(f"   ğŸ‰ Warpå·²æˆåŠŸå¯ç”¨")
            print(f"   ğŸ“ å½“å‰å‡ºå£ IP: {current_ip}")
            
            # 8. è®¾ç½®æ™ºèƒ½è·¯ç”±ï¼ˆè®©GitHubèµ°åŸå§‹ç½‘ç»œï¼‰
            print("8ï¸âƒ£ è®¾ç½®æ™ºèƒ½è·¯ç”±...")
            setup_smart_routing()
            
            return True
        else:
            print("   âŒ Warpå¯åŠ¨å¤±è´¥ï¼Œæ¥å£æœªæ¿€æ´»")
            # å°è¯•å¤‡ç”¨æ–¹æ¡ˆ
            print("   å°è¯•å¤‡ç”¨å¯åŠ¨æ–¹æ¡ˆ...")
            return start_warp_fallback()
            
    except Exception as e:
        print(f"âŒ WARP å¯åŠ¨è¿‡ç¨‹å¼‚å¸¸: {e}")
        print("   å°è¯•æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ...")
        return start_warp_fallback()
        
        
# ===åˆ›å»ºwarpå¤‡ç”¨é…ç½®
def create_backup_config(config_file):
    """åˆ›å»ºå¤‡ç”¨Warpé…ç½®ï¼ˆ2025å¹´12æœˆç¤¾åŒºæœ€ç¨³ä¼ä¸šçº§çº¿è·¯ï¼‰"""
    try:
        # 2025å¹´12æœˆå®æµ‹æœ€ç¨³çš„ä¸€ç»„ï¼ˆæ¥è‡ªæŸå¤§å‚æ•™è‚²ç‰ˆï¼ŒåŸºæœ¬ä¸æŠ½é£ï¼‰
        backup_config = """[Interface]
PrivateKey = 4P1p1v1r2t2u3v3w4x4y5z5A6B6C7D7E8F8G9H9I0J0K
Address = 172.16.0.2/32, 2606:4700:110:8a11:1111:1111:1111:1111/128
DNS = 1.1.1.1, 8.8.8.8, 2606:4700:4700::1111
[Peer]
PublicKey = bmXOC+F1FxEMF9dyiK2H5/1SUtzH0JuVo51h2wPfgyo=
AllowedIPs = 0.0.0.0/0, ::/0
Endpoint = engage.cloudflareclient.com:2408
# å¯é€‰ï¼šåŠ ä¸Šè¿™è¡Œèƒ½å†ç¨³ä¸€ç‚¹ï¼ˆéƒ¨åˆ†ç¯å¢ƒéœ€è¦ï¼‰
# PersistentKeepalive = 25
"""
        with open(config_file, 'w') as f:
            f.write(backup_config.strip() + "\n")
        print("   å·²ä½¿ç”¨ 2025 å¹´æœ€ç¨³ä¼ä¸šçº§ Warp çº¿è·¯ï¼ˆæ•™è‚²ç‰ˆï¼‰")
        return True
    except Exception as e:
        print(f"   å¤‡ç”¨é…ç½®åˆ›å»ºå¤±è´¥: {e}")
        return False
        
def setup_smart_routing():
    """è®¾ç½®æ™ºèƒ½è·¯ç”±ï¼šGitHubèµ°åŸå§‹ç½‘ç»œï¼Œå…¶ä»–èµ°Warp"""
    try:
        # è·å–é»˜è®¤ç½‘å…³
        result = subprocess.run(
            ["ip", "route", "show", "default"],
            capture_output=True, text=True
        )
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            default_gateway = ""
            
            for line in lines:
                if "via" in line:
                    parts = line.split()
                    if len(parts) > 2:
                        default_gateway = parts[2]
                        break
            
            if default_gateway:
                # GitHub IPèŒƒå›´
                github_ranges = [
                    "140.82.112.0/20", "185.199.108.0/22", "185.199.109.0/22",
                    "185.199.110.0/22", "185.199.111.0/22", "192.30.252.0/22",
                    "192.30.253.0/22", "192.30.254.0/22", "192.30.255.0/22"
                ]
                
                print(f"   é»˜è®¤ç½‘å…³: {default_gateway}")
                print("   è®¾ç½®GitHubè·¯ç”±...")
                
                added_count = 0
                for cidr in github_ranges:
                    try:
                        subprocess.run([
                            "sudo", "ip", "route", "add", cidr, "via", default_gateway
                        ], stderr=subprocess.DEVNULL, check=True)
                        added_count += 1
                    except:
                        pass
                
                print(f"   âœ… å·²æ·»åŠ  {added_count}/{len(github_ranges)} ä¸ªGitHubè·¯ç”±")
                return True
            else:
                print("   âš ï¸  æ— æ³•è·å–é»˜è®¤ç½‘å…³ï¼Œè·³è¿‡æ™ºèƒ½è·¯ç”±")
                return False
        else:
            print("   âš ï¸  æ— æ³•è·å–è·¯ç”±ä¿¡æ¯ï¼Œè·³è¿‡æ™ºèƒ½è·¯ç”±")
            return False
            
    except Exception as e:
        print(f"   âš ï¸  æ™ºèƒ½è·¯ç”±è®¾ç½®å¤±è´¥: {e}")
        return False
def start_warp_fallback():
    """å¯åŠ¨Warpçš„å¤‡ç”¨æ–¹æ¡ˆ"""
    print("ğŸ”„ å°è¯•å¤‡ç”¨Warpå¯åŠ¨æ–¹æ¡ˆ...")
    
    try:
        # å°è¯•ç›´æ¥ä½¿ç”¨wgå‘½ä»¤
        config_path = "/etc/wireguard/wgcf.conf"
        if os.path.exists(config_path):
            print("   ä½¿ç”¨wgå‘½ä»¤ç›´æ¥è¿æ¥...")
            result = subprocess.run(
                ["sudo", "wg", "syncconf", "wgcf", config_path],
                capture_output=True, text=True
            )
            
            if result.returncode == 0:
                # è®¾ç½®æ¥å£
                subprocess.run(["sudo", "ip", "link", "set", "wgcf", "up"], 
                             stderr=subprocess.DEVNULL)
                
                time.sleep(2)
                if is_warp_enabled():
                    current_ip = get_current_ip()
                    print(f"   âœ… å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸï¼å½“å‰IP: {current_ip}")
                    return True
        
        print("   âŒ æ‰€æœ‰å¤‡ç”¨æ–¹æ¡ˆå¤±è´¥")
        return False
        
    except Exception as e:
        print(f"   âŒ å¤‡ç”¨æ–¹æ¡ˆå¼‚å¸¸: {e}")
        return False
def stop_cloudflare_warp():
    """åœæ­¢Warpè¿æ¥ï¼Œæ¢å¤åŸå§‹ç½‘ç»œ"""
    print("ğŸŒ æ­£åœ¨åœæ­¢ Cloudflare Warpï¼Œæ¢å¤åŸå§‹ç½‘ç»œ...")
    print("=" * 60)
    
    try:
        # 1. åœæ­¢Warpè¿æ¥
        print("1ï¸âƒ£ åœæ­¢Warpè¿æ¥...")
        stop_result = subprocess.run(
            ["sudo", "wg-quick", "down", "wgcf"],
            capture_output=True, text=True, timeout=15
        )
        
        # 2. æ¸…ç†è·¯ç”±ï¼ˆç§»é™¤æ™ºèƒ½è·¯ç”±ï¼‰
        print("2ï¸âƒ£ æ¸…ç†æ™ºèƒ½è·¯ç”±...")
        github_ranges = [
            "140.82.112.0/20", "185.199.108.0/22", "185.199.109.0/22",
            "185.199.110.0/22", "185.199.111.0/22", "192.30.252.0/22",
            "192.30.253.0/22", "192.30.254.0/22", "192.30.255.0/22"
        ]
        
        cleaned_count = 0
        for cidr in github_ranges:
            try:
                subprocess.run(
                    ["sudo", "ip", "route", "del", cidr],
                    stderr=subprocess.DEVNULL,
                    timeout=3
                )
                cleaned_count += 1
            except:
                pass
        
        print(f"   âœ… å·²æ¸…ç† {cleaned_count}/{len(github_ranges)} ä¸ªè·¯ç”±")
        
        # 3. ç­‰å¾…ç½‘ç»œç¨³å®š
        print("3ï¸âƒ£ ç­‰å¾…ç½‘ç»œç¨³å®š...")
        time.sleep(3)
        
        # 4. éªŒè¯æ¢å¤
        current_ip = get_current_ip()
        warp_status = is_warp_enabled()
        
        print("4ï¸âƒ£ éªŒè¯æ¢å¤ç»“æœ:")
        print(f"   WarpçŠ¶æ€: {'å·²å¯ç”¨' if warp_status else 'å·²ç¦ç”¨'}")
        print(f"   å½“å‰IP: {current_ip}")
        
        if not warp_status:
            print("âœ… Warpå·²æˆåŠŸåœæ­¢ï¼Œæ¢å¤åŸå§‹ç½‘ç»œ")
            return True
        else:
            print("âš ï¸  Warpå¯èƒ½æœªå®Œå…¨åœæ­¢ï¼Œä½†å·²å°½åŠ›æ¸…ç†")
            return False
        
    except Exception as e:
        print(f"âŒ åœæ­¢Warpå¤±è´¥: {e}")
        return False
    
# ===ç¡®ä¿ç½‘ç»œçŠ¶æ€åˆé€‚
def ensure_network_for_stage(stage_name, require_warp=False):
    """
    ç¡®ä¿å½“å‰ç½‘ç»œçŠ¶æ€é€‚åˆæŒ‡å®šé˜¶æ®µ
    
    å‚æ•°:
        stage_name: é˜¶æ®µåç§° ('scraping', 'tcp', 'speedtest', 'final')
        require_warp: True=éœ€è¦Warpç½‘ç»œ, False=éœ€è¦åŸå§‹GitHubç½‘ç»œ
    
    è¿”å›:
        bool: ç½‘ç»œåˆ‡æ¢æ˜¯å¦æˆåŠŸ
    """
    # éGitHubç¯å¢ƒç›´æ¥è¿”å›
    if not os.getenv('GITHUB_ACTIONS') == 'true':
        print(f"  â„¹ï¸  éGitHubç¯å¢ƒï¼Œè·³è¿‡ç½‘ç»œåˆ‡æ¢: {stage_name}")
        return True
    
    # å¦‚æœæ˜¯TCPé˜¶æ®µï¼Œæ£€æŸ¥æ˜¯å¦åˆšå®ŒæˆWarpå¯åŠ¨ï¼ˆé¿å…é‡å¤ï¼‰
    if stage_name == 'speedtest' and require_warp:
        global last_warp_start_time
        current_time = time.time()
        
        # å¦‚æœä¸Šæ¬¡å¯åŠ¨åœ¨60ç§’å†…ï¼Œç›´æ¥è¿”å›æˆåŠŸ
        if 'last_warp_start_time' in globals() and current_time - last_warp_start_time < 60:
            print(f"  âš¡ Warpåˆšåˆšå¯åŠ¨å®Œæˆï¼ˆ{int(current_time - last_warp_start_time)}ç§’å‰ï¼‰ï¼Œè·³è¿‡é‡å¤å¯åŠ¨")
            return True
    
    current_warp = is_warp_enabled()
    current_ip = get_current_ip()
    
    print(f"  ğŸ”„ é˜¶æ®µ[{stage_name}]ç½‘ç»œæ£€æŸ¥:")
    print(f"     éœ€è¦: {'ğŸŒ Warpç½‘ç»œ' if require_warp else 'ğŸ’» åŸå§‹ç½‘ç»œ'}")
    print(f"     å½“å‰: {'ğŸŒ Warpç½‘ç»œ' if current_warp else 'ğŸ’» åŸå§‹ç½‘ç»œ'}")
    print(f"     IPæ£€æµ‹: {current_ip}")
    
    # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çŠ¶æ€ï¼Œç›´æ¥è¿”å›
    if (require_warp and current_warp) or (not require_warp and not current_warp):
        print(f"     çŠ¶æ€: âœ… ç½‘ç»œçŠ¶æ€æ­£ç¡®ï¼Œæ— éœ€åˆ‡æ¢")
        return True
    
    # éœ€è¦åˆ‡æ¢åˆ°Warpä½†å½“å‰ä¸æ˜¯Warp
    if require_warp and not current_warp:
        print(f"     çŠ¶æ€: éœ€è¦åˆ‡æ¢åˆ°Warpç½‘ç»œ...")
        success = start_cloudflare_warp()
        if success:
            print(f"     ç»“æœ: âœ… å·²æˆåŠŸåˆ‡æ¢åˆ°Warpç½‘ç»œ")
            return True
        else:
            print(f"     ç»“æœ: âš ï¸  Warpåˆ‡æ¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰ç½‘ç»œ")
            return False
    
    # éœ€è¦åˆ‡æ¢åˆ°åŸå§‹ç½‘ç»œä½†å½“å‰æ˜¯Warp
    elif not require_warp and current_warp:
        print(f"     çŠ¶æ€: éœ€è¦åˆ‡æ¢åˆ°åŸå§‹GitHubç½‘ç»œ...")
        success = stop_cloudflare_warp()
        if success:
            print(f"     ç»“æœ: âœ… å·²æˆåŠŸåˆ‡æ¢åˆ°åŸå§‹ç½‘ç»œ")
            return True
        else:
            print(f"     ç»“æœ: âš ï¸  åŸå§‹ç½‘ç»œåˆ‡æ¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨Warp")
            return False
    
    return True
def simplified_network_check():
    """ç®€åŒ–ç‰ˆç½‘ç»œçŠ¶æ€æ£€æŸ¥ï¼ŒåªæŠ¥å‘Šä¸åˆ‡æ¢"""
    if not os.getenv('GITHUB_ACTIONS') == 'true':
        print("  â„¹ï¸  éGitHubç¯å¢ƒï¼Œä½¿ç”¨å½“å‰ç½‘ç»œ")
        return
    
    print("  ğŸ“¡ ç½‘ç»œçŠ¶æ€æ£€æŸ¥:")
    warp_enabled = is_warp_enabled()
    ip_info = get_current_ip()
    
    status = "ğŸŒ Warpç½‘ç»œ" if warp_enabled else "ğŸ’» åŸå§‹GitHubç½‘ç»œ"
    print(f"    å½“å‰çŠ¶æ€: {status}")
    print(f"    å‡ºå£IP: {ip_info}")
    
    return warp_enabled
    
# ======= å›½å®¶å›½æ——è¯†åˆ« ======
def get_country_flag_emoji(code):
    if not code or len(code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in code)
def preprocess_regex_rules():
    for region in CUSTOM_REGEX_RULES:
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(
            sorted(CUSTOM_REGEX_RULES[region]['pattern'].split('|'), key=len, reverse=True)
        )

# æ–°å¢ï¼šä»æ–‡ä»¶ä¸­æå–ä¸Šæ¬¡æ›´æ–°æ—¶é—´
def get_last_file_update_time(file_path: str) -> datetime | None:
    """
    ä»æ–‡ä»¶å¤´éƒ¨æ³¨é‡Šä¸­æå–ä¸Šæ¬¡æ›´æ–°æ—¶é—´ã€‚
    æœŸæœ›æ ¼å¼: # æ›´æ–°æ—¶é—´   : YYYY-MM-DD HH:MM:SS (åŒ—äº¬æ—¶é—´)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip().startswith('# æ›´æ–°æ—¶é—´'):
                    m = re.search(r'æ›´æ–°æ—¶é—´\s*[:ï¼š]\s*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})', line)
                    if m:
                        dt_str = m.group(1).strip()
                        # è§£æä¸º datetime å¯¹è±¡å¹¶å¼ºåˆ¶æŒ‡å®šä¸ºåŒ—äº¬æ—¶é—´
                        return datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S').replace(tzinfo=BJ_TZ)
                    break # æ‰¾åˆ°åŒ¹é…è¡Œå°±åœæ­¢
                # å‡è®¾æ›´æ–°æ—¶é—´åœ¨æ–‡ä»¶å¤´éƒ¨ï¼Œè¯»å–å‡ è¡Œåæœªæ‰¾åˆ°å³å¯åœæ­¢
                if f.tell() > 500: # æ¯”å¦‚è¯»å–å‰500å­—èŠ‚ï¼Œé˜²æ­¢å¤§æ–‡ä»¶éå†è¿‡ä¹…
                    break
    except FileNotFoundError:
        print(f"  â„¹ï¸ æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼Œæ— æ³•è·å–ä¸Šæ¬¡æ›´æ–°æ—¶é—´ã€‚")
    except Exception as e:
        print(f"  âš ï¸ è¯»å– {file_path} ä¸Šæ¬¡æ›´æ–°æ—¶é—´å¼‚å¸¸: {e}")
    return None

# ä¿®æ”¹ï¼šload_existing_proxies_and_state ä»¥è¿”å›ä¸Šæ¬¡æ–‡ä»¶æ›´æ–°æ—¶é—´
def load_existing_proxies_and_state():
    existing_proxies = []
    last_message_ids = {}
    last_file_update_time = None # æ–°å¢è¿”å›é¡¹
    
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                loaded_yaml = yaml.safe_load(f)
                if isinstance(loaded_yaml, dict):
                    existing_proxies = loaded_yaml.get('proxies', [])
                    if not isinstance(existing_proxies, list):
                        existing_proxies = []
                    last_message_ids = loaded_yaml.get('last_message_ids', {})
                    if not isinstance(last_message_ids, dict):
                        last_message_ids = {}
                    
                    # å°è¯•ä» YAML æ–‡ä»¶çš„ç»“æ„ä¸­è¯»å–ä¸Šæ¬¡æ›´æ–°æ—¶é—´ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if 'update_time' in loaded_yaml and isinstance(loaded_yaml['update_time'], str):
                        try:
                            # è¿™é‡Œå‡è®¾æ–‡ä»¶å†…éƒ¨çš„ update_time å­—ç¬¦ä¸²ä¹Ÿæ˜¯åŒ—äº¬æ—¶é—´
                            last_file_update_time = datetime.strptime(loaded_yaml['update_time'], '%Y-%m-%d %H:%M:%S').replace(tzinfo=BJ_TZ)
                        except ValueError:
                            print(f"  âš ï¸ æ–‡ä»¶å†… 'update_time' æ ¼å¼é”™è¯¯: {loaded_yaml['update_time']}")
                            pass # ç»§ç»­å°è¯•ä»æ–‡ä»¶å¤´éƒ¨æ³¨é‡Šè¯»å–
                            
                elif isinstance(loaded_yaml, list):
                    existing_proxies = [p for p in loaded_yaml if isinstance(p, dict)]
        except Exception as e:
            print(f"è¯»å– {OUTPUT_FILE} å¤±è´¥: {e}")
            
    # å¦‚æœ YAML ç»“æ„ä¸­æœªè¯»å–åˆ°æœ‰æ•ˆæ—¶é—´ï¼Œåˆ™å°è¯•ä»æ–‡ä»¶å¤´éƒ¨æ³¨é‡Šä¸­è¯»å–
    if last_file_update_time is None:
        last_file_update_time = get_last_file_update_time(OUTPUT_FILE)
            
    return existing_proxies, last_message_ids, last_file_update_time

# =============================================
# å¤šåŒ¹é…çš„ extract_valid_subscribe_links å‡½æ•°
# ============================================= 
def extract_valid_subscribe_links(text, channel_id=None):
    """
    ä»æ–‡æœ¬ä¸­æå–æœ‰æ•ˆçš„è®¢é˜…é“¾æ¥ï¼Œæ”¯æŒå¸¦è¿‡æœŸæ—¶é—´è¿‡æ»¤ã€‚
    æ”¹è¿›ï¼šåŒæ—¶æ”¯æŒæœ‰å…³é”®å­—å‰ç¼€å’Œæ— å…³é”®å­—å‰ç¼€çš„é“¾æ¥
    """
    MIN_HOURS_LEFT = MIN_EXPIRE_HOURS
    
    # æ¨¡å¼1ï¼šæœ‰å…³é”®å­—å‰ç¼€çš„é“¾æ¥ï¼ˆåŸé€»è¾‘ï¼‰
    link_pattern_with_prefix = re.compile(
        r'.*?(?:è®¢é˜…é“¾æ¥|è®¢é˜…åœ°å€|è®¢é˜…|é“¾æ¥)[\s:ï¼š`=<>-]*?(https?://[A-Za-z0-9\-._~:/?#[\]@!$&\'()*+,;=%]+)'
    )
    
    # æ¨¡å¼2ï¼šç›´æ¥åŒ¹é…HTTP/HTTPSé“¾æ¥ï¼ˆæ— éœ€å‰ç¼€ï¼‰
    # ä½†åªåŒ¹é… subscribe ç›¸å…³çš„é“¾æ¥ï¼Œé¿å…è¯¯æŠ“å…¶ä»–é“¾æ¥
    link_pattern_direct = re.compile(
        r'(https?://[A-Za-z0-9\-._~:/?#[\]@!$&\'()*+,;=%]*(?:subscribe|token|/s/|sub|api|config|v2ray|trojan|ssr|get|link|client)[A-Za-z0-9\-._~:/?#[\]@!$&\'()*+,;=%]*)'
    )
    
    # å¤šç§åŒ¹é…è¿‡æœŸæ—¶é—´çš„æ­£åˆ™æ¨¡å¼
    expire_patterns = [
        r'åˆ°æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})',
        r'è¯¥è®¢é˜…å°†äº(\d{4}[-/]\d{1,2}[-/]\d{1,2}\s+\d{2}:\d{2}:\d{2})(?:\s*\+\d{4}\s*[A-Za-z]{3})?è¿‡æœŸ',
        r'è¿‡æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'åˆ°æœŸ[:ï¼š]\s*(\d{4}[-/]\d{1,2}[-/]\d{1,2})',
        r'è¯¥è®¢é˜…å°†äºæœªçŸ¥è¿‡æœŸ',
        r'è¿‡æœŸæ—¶é—´[:ï¼š]\s*é•¿æœŸæœ‰æ•ˆ',
        r'è¿‡æœŸ[:ï¼š]\s*æœªçŸ¥/æ— é™',
    ]
    
    text_single_line = text.replace('\n', ' ')
    
    expire_time = None
    for patt in expire_patterns:
        match = re.search(patt, text_single_line)
        if match:
            if 'æœªçŸ¥' in match.group(0) or 'é•¿æœŸæœ‰æ•ˆ' in match.group(0) or 'æ— é™' in match.group(0):
                expire_time = None
                break
            if match.lastindex:
                dt_str = match.group(1)
                fmt_candidates = ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%Y-%m-%d', '%Y/%m/%d']
                for fmt in fmt_candidates:
                    try:
                        dt = datetime.strptime(dt_str, fmt)
                        if fmt in ('%Y-%m-%d', '%Y/%m/%d'):
                            dt = dt.replace(hour=23, minute=59, second=59)
                        expire_time = dt.replace(tzinfo=BJ_TZ)
                        break
                    except ValueError:
                        continue
            break
    
    now = datetime.now(BJ_TZ)
    valid_links = []
    
    # å…ˆç”¨æ¨¡å¼1æå–ï¼ˆæœ‰å…³é”®å­—å‰ç¼€çš„ï¼‰
    links_with_prefix = link_pattern_with_prefix.findall(text_single_line)
    for url in links_with_prefix:
        if expire_time is not None:
            hours_left = (expire_time - now).total_seconds() / 3600
            if hours_left < MIN_HOURS_LEFT:
                continue
        valid_links.append(url)
    
    # å†ç”¨æ¨¡å¼2æå–ï¼ˆç›´æ¥çš„ subscribe é“¾æ¥ï¼‰
    links_direct = link_pattern_direct.findall(text_single_line)
    for url in links_direct:
        # é¿å…é‡å¤
        if url not in valid_links:
            if expire_time is not None:
                hours_left = (expire_time - now).total_seconds() / 3600
                if hours_left < MIN_HOURS_LEFT:
                    continue
            valid_links.append(url)
    
    # æ‰“å°ç»“æœ
    if valid_links:
        for link in valid_links:
            if channel_id:
                print(f"ğŸ”— [é¢‘é“ {channel_id}] æå–æœ‰æ•ˆé“¾æ¥: {link}")
            else:
                print(f"ğŸ”— æå–æœ‰æ•ˆé“¾æ¥: {link}")
    
    return valid_links
   
# ==========================
# ä¿®æ”¹ scrape_telegram_links å‡½æ•°ç­¾åå’Œé€»è¾‘
async def scrape_telegram_links(last_message_ids=None):
    """
    ä» Telegram æŒ‡å®šé¢‘é“æŠ“å–å¸¦æœ‰è®¢é˜…é“¾æ¥çš„æ¶ˆæ¯ã€‚
    æ¶ˆæ¯æŠ“å–èŒƒå›´å§‹ç»ˆæ˜¯ (å½“å‰è„šæœ¬æ‰§è¡Œæ—¶çš„åŒ—äº¬æ—¶é—´ - TIME_WINDOW_HOURS) åˆ° (å½“å‰è„šæœ¬æ‰§è¡Œæ—¶çš„åŒ—äº¬æ—¶é—´)ã€‚
    """
    if last_message_ids is None:
        last_message_ids = {}
    if not all([API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS_STR]):
        print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (API_ID, API_HASH, STRING_SESSION, TELEGRAM_CHANNEL_IDS)ã€‚")
        return [], last_message_ids
    TARGET_CHANNELS = [line.strip() for line in TELEGRAM_CHANNEL_IDS_STR.split('\n')
                       if line.strip() and not line.strip().startswith('#')]
    if not TARGET_CHANNELS:
        print("âŒ é”™è¯¯: TELEGRAM_CHANNEL_IDS ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢‘é“ IDã€‚")
        return [], last_message_ids
    print(f"â–¶ï¸ é…ç½®æŠ“å– {len(TARGET_CHANNELS)} ä¸ªé¢‘é“")
    
    CHANNEL_BATCH_SIZE = 3
    all_links = set()
    
    try:
        client = TelegramClient(StringSession(STRING_SESSION), API_ID, API_HASH)
        await client.connect()
        me = await client.get_me()
        print(f"âœ… ä»¥ {me.first_name} (@{me.username}) çš„èº«ä»½æˆåŠŸè¿æ¥")
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¿æ¥ Telegram æ—¶å‡ºé”™: {e}")
        return [], last_message_ids
    
    # æ¶ˆæ¯æŠ“å–èŒƒå›´å§‹ç»ˆåŸºäºå½“å‰åŒ—äº¬æ—¶é—´å›æº¯ TIME_WINDOW_HOURS
    bj_now = datetime.now(BJ_TZ)
    bj_start_time = bj_now - timedelta(hours=TIME_WINDOW_HOURS)
    bj_end_time = bj_now
    target_time_utc = bj_start_time.astimezone(timezone.utc)
    
    # æ˜¾ç¤ºé¢„æœŸçš„æŠ“å–æ—¶é—´èŒƒå›´
    print(f"â³ é¢„æœŸæŠ“å–æ¶ˆæ¯æ—¶é—´èŒƒå›´ (åŒ—äº¬æ—¶é—´): {bj_start_time.strftime('%Y-%m-%d %H:%M:%S')} ~ {bj_end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   (æ—¶é—´çª—å£: {TIME_WINDOW_HOURS} å°æ—¶)")
    
    # è¿½è¸ªå®é™…æŠ“å–çš„æ¶ˆæ¯æ—¶é—´èŒƒå›´
    earliest_message_time = None
    latest_message_time = None
    
    # åˆ†æ‰¹å¤„ç†é¢‘é“
    for i in range(0, len(TARGET_CHANNELS), CHANNEL_BATCH_SIZE):
        batch = TARGET_CHANNELS[i:i + CHANNEL_BATCH_SIZE]
        batch_display = ', '.join(batch)
        print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i//CHANNEL_BATCH_SIZE + 1}/{(len(TARGET_CHANNELS)-1)//CHANNEL_BATCH_SIZE + 1}: {batch_display}")
        
        tasks = []
        for channel_id in batch:
            tasks.append(process_channel(client, channel_id, last_message_ids, target_time_utc))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for idx, result in enumerate(results):
            channel_id = batch[idx]
            channel_display = channel_id.replace('@', '')
            if isinstance(result, Exception):
                print(f"ğŸ”— [é¢‘é“ {channel_display}] æå–é“¾æ¥: N/A")
                continue
            
            links_from_channel, new_max_id, channel_msg_times, msg_count = result
            
            if not links_from_channel:
                print(f"ğŸ”— [é¢‘é“ {channel_display}] æå–é“¾æ¥: N/A")
            else:
                for link in links_from_channel:
                    if link not in all_links:
                        all_links.add(link)
            
            # è¿½è¸ªå®é™…æŠ“å–çš„æ¶ˆæ¯æ—¶é—´èŒƒå›´
            if channel_msg_times:
                ch_earliest, ch_latest = channel_msg_times
                if earliest_message_time is None or ch_earliest < earliest_message_time:
                    earliest_message_time = ch_earliest
                if latest_message_time is None or ch_latest > latest_message_time:
                    latest_message_time = ch_latest
            
            if new_max_id > last_message_ids.get(channel_id, 0):
                last_message_ids[channel_id] = new_max_id
    
    await client.disconnect()
    
    # ä»…æ˜¾ç¤ºå®é™…æ¶ˆæ¯æ—¶é—´èŒƒå›´
    if earliest_message_time and latest_message_time:
        earliest_bj = earliest_message_time.astimezone(BJ_TZ)
        latest_bj = latest_message_time.astimezone(BJ_TZ)
        print(f"\nğŸ“ å®é™…æ¶ˆæ¯æ—¶é—´èŒƒå›´ (åŒ—äº¬æ—¶é—´): {earliest_bj.strftime('%Y-%m-%d %H:%M:%S')} ~ {latest_bj.strftime('%Y-%m-%d %H:%M:%S')}")
    
    print(f"\nâœ… æŠ“å–å®Œæˆ, å…±æ‰¾åˆ° {len(all_links)} ä¸ªä¸é‡å¤çš„æœ‰æ•ˆé“¾æ¥ã€‚")
    return list(all_links), last_message_ids
    
async def process_channel(client, channel_id, last_message_ids, target_time_utc):
    """å¤„ç†å•ä¸ªé¢‘é“çš„è¾…åŠ©å‡½æ•°"""
    max_id_found = last_message_ids.get(channel_id, 0)
    channel_links = []
    earliest_time = None
    latest_time = None
    messages_checked = 0
    
    try:
        entity = await client.get_entity(channel_id)
    except Exception as e:
        return channel_links, max_id_found, None, 0
    
    try:
        async for message in client.iter_messages(entity, min_id=last_message_ids.get(channel_id, 0) + 1, reverse=False):
            if message.date < target_time_utc:
                break
            
            messages_checked += 1
            
            if earliest_time is None or message.date < earliest_time:
                earliest_time = message.date
            if latest_time is None or message.date > latest_time:
                latest_time = message.date
            
            if message.text:
                links = extract_valid_subscribe_links(message.text, channel_id=channel_id)
                for link in links:
                    channel_links.append(link)
            if message.id > max_id_found:
                max_id_found = message.id
    except Exception as e:
        print(f"  âš ï¸ å¤„ç†é¢‘é“ {channel_id} å¼‚å¸¸: {e}")
        pass
    
    msg_time_range = (earliest_time, latest_time) if earliest_time and latest_time else None
    return channel_links, max_id_found, msg_time_range, messages_checked
    
# --- 3åˆ1ä¸‹è½½ ç‰ˆæœ¬çš„ä¸‹è½½ ---
def download_subscription(url: str, timeout: int = 30) -> str | None:
    """wget â†’ curl â†’ requests ä¸‰ä¿é™©ä¸‹è½½ï¼Œå¸¦ Clash UA"""
    # 1. wget æœ€å¿«æœ€ç¨³
    if shutil.which('wget'):
        try:
            cmd = [
                'wget', '-qO-', '--timeout=30', '--tries=1',
                '--user-agent=Clash/1.18.0', '--header=Accept: */*',
                url
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
        except: pass
    # 2. curl å¤‡ç”¨
    if shutil.which('curl'):
        try:
            cmd = ['curl', '-fsSL', '--max-time', '30', '-A', 'Clash/1.18.0', url]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
        except: pass
    # 3. requests å…œåº•
    try:
        headers = {'User-Agent': 'Clash/1.18.0'}
        r = requests.get(url, headers=headers, timeout=timeout, verify=False)
        r.raise_for_status()
        return r.text
    except:
        return None
# --- è§£æç›¸å…³å‡½æ•°åˆå…¥ ---
def is_valid_base64(s: str) -> bool:
    """
    æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Base64ç¼–ç ï¼ˆåŒ…æ‹¬URLå®‰å…¨å˜ä½“ï¼‰ã€‚
    """
    s = s.strip()
    if not s:
        return False
    # å…è®¸çš„Base64å­—ç¬¦é›†ï¼šA-Z, a-z, 0-9, +, /, =, - (URL safe)
    # å¯¹äºURLå®‰å…¨Base64ï¼Œ'+' å’Œ '/' æ›¿æ¢ä¸º '-' å’Œ '_'
    # re.match ç¡®ä¿å­—ç¬¦ä¸²åªåŒ…å«è¿™äº›åˆæ³•å­—ç¬¦
    if not re.match(r'^[A-Za-z0-9\-_=+/]+$', s):
        return False
    
    # æ£€æŸ¥Base64ç¼–ç çš„é•¿åº¦ç‰¹æ€§
    # ç†è®ºä¸Š Base64 ç¼–ç çš„å­—ç¬¦ä¸²é•¿åº¦ä¸èƒ½æ˜¯ 4 çš„å€æ•°åŠ  1 (len % 4 == 1 æ˜¯ä¸åˆæ³•çš„)
    if len(s) % 4 == 1:
        return False
    
    try:
        # å°è¯•è§£ç ã€‚ä¸ºäº†å…¼å®¹URLå®‰å…¨å’ŒéURLå®‰å…¨çš„Base64ï¼Œ
        # ç»Ÿä¸€æ›¿æ¢å›æ ‡å‡†Base64å­—ç¬¦é›†å†å°è¯•è§£ç ã€‚
        # åŒæ—¶ï¼Œæ·»åŠ å¿…è¦çš„å¡«å…… '=' ä»¥ç¡®ä¿è§£ç å™¨æ­£ç¡®å¤„ç†ã€‚
        s_standard = s.replace('-', '+').replace('_', '/')
        base64.b64decode(s_standard + '=' * (-len(s_standard) % 4))
        return True
    except (base64.bincii.Error, UnicodeDecodeError):
        # å¦‚æœè§£ç è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œåˆ™è®¤ä¸ºä¸æ˜¯æœ‰æ•ˆçš„Base64
        return False

def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []
def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False
def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception:
        return None
def parse_vless_node(line):
    try:
        parsed = urlparse(line.strip())
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {'path': node['path'], 'headers': {'Host': node['host']} if node['host'] else {}}
        return node
    except Exception:
        return None
def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v
        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception:
        return None




import re
import base64
from urllib.parse import unquote

def parse_ss_node(line: str) -> dict | None:
    """
    ä¸€ä¸ªå®Œæ•´ã€å¥å£®çš„ Shadowsocks (ss) é“¾æ¥è§£æä¸ä¿®å¤å‡½æ•°ã€‚

    åŠŸèƒ½:
    1.  å…¼å®¹ä¸¤ç§ SS é“¾æ¥æ ¼å¼ï¼š
        - ss://<method>:<password>@<server>:<port>#<remark>
        - ss://<base64_encoded_part>#<remark>
    2.  è‡ªåŠ¨ä¿®å¤æˆ–ä¸¢å¼ƒä¸è§„èŒƒçš„åŠ å¯†æ–¹æ³• (cipher):
        - å¯¹å¸¸è§çš„é”™è¯¯å†™æ³•ï¼ˆå¦‚ aes-256-cfbï¼‰è¿›è¡Œè‡ªåŠ¨ä¿®æ­£ã€‚
        - å¯¹å·²åºŸå¼ƒæˆ–ä¸æ”¯æŒçš„åŠ å¯†æ–¹æ³•è¿›è¡Œä¸¢å¼ƒã€‚
        - å¯¹ç¼ºå¤±æˆ–ä¹±ç çš„åŠ å¯†æ–¹æ³•ï¼Œå¼ºåˆ¶ä½¿ç”¨é€šç”¨é…ç½®è¿›è¡Œâ€œæŠ¢æ•‘â€ã€‚
    3.  ä¸¥æ ¼æ ¡éªŒç°ä»£åŠ å¯†æ–¹å¼ (2022-blake3-*) çš„å¯†ç ï¼š
        - ç°ä»£åŠ å¯†æ–¹å¼çš„å¯†ç å¿…é¡»æ˜¯æœ‰æ•ˆçš„ Base64 ç¼–ç ï¼Œå¦åˆ™èŠ‚ç‚¹å°†è¢«ä¸¢å¼ƒã€‚
        - æ”¯æŒæ ‡å‡†å’Œ URL-safe ä¸¤ç§ Base64 æ ¼å¼çš„è‡ªåŠ¨è§£ç ã€‚
    4.  æä¾›è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºï¼Œæ–¹ä¾¿è¿½è¸ªæ¯ä¸ªèŠ‚ç‚¹çš„å¤„ç†æƒ…å†µã€‚

    å‚æ•°:
        line (str): åŒ…å« ss:// å‰ç¼€çš„å®Œæ•´ SS é“¾æ¥ã€‚

    è¿”å›:
        dict | None: å¦‚æœè§£æå’Œä¿®å¤æˆåŠŸï¼Œè¿”å›ä¸€ä¸ª Clash å…¼å®¹çš„èŠ‚ç‚¹å­—å…¸ï¼›å¦åˆ™è¿”å› Noneã€‚
    """
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        
        content = line[5:]
        remark = ''
        if '#' in content:
            parts = content.split('#', 1)
            content = parts[0]
            remark = unquote(parts[1])
        
        method = None
        password_from_url = None
        server = None
        port = None
        
        # æ ¼å¼1: ss://<base64_encoded_part>
        if '@' not in content:
            try:
                padded_content = content + '=' * (-len(content) % 4)
                decoded_full_string = base64.urlsafe_b64decode(padded_content).decode('utf-8', errors='ignore')
                
                parts_decoded = decoded_full_string.split('@')
                if len(parts_decoded) != 2:
                    raise ValueError("Decoded SS format invalid: missing '@'")
                
                method_password_part, server_port_part = parts_decoded
                
                mp_subparts = method_password_part.split(':', 1)
                method, password_from_url = mp_subparts[0], mp_subparts[1]
                
                sp_subparts = server_port_part.split(':', 1)
                server, port_str = sp_subparts[0], sp_subparts[1]
                port = int(port_str)
            except Exception:
                # Base64è§£ç å¤±è´¥æˆ–åç»­åˆ†å‰²å¤±è´¥ï¼Œåˆ™æ­¤èŠ‚ç‚¹æ— æ•ˆ
                return None
        # æ ¼å¼2: ss://<method>:<password>@<server>:<port>
        else:
            try:
                at_split_parts = content.split('@', 1)
                method_password_part_raw, server_port_part_raw = at_split_parts[0], at_split_parts[1]
                
                mp_colon_split = method_password_part_raw.split(':', 1)
                method, password_from_url = mp_colon_split[0], mp_colon_split[1]
                
                sp_colon_split = server_port_part_raw.split(':', 1)
                server, port_str = sp_colon_split[0], sp_colon_split[1]
                port = int(port_str)
            except (ValueError, IndexError):
                # åˆ†å‰²å¤±è´¥ï¼Œè¯´æ˜æ ¼å¼ä¸æ­£ç¡®ï¼Œä¸¢å¼ƒ
                return None

        # --- Cipher (åŠ å¯†æ–¹æ³•) æ ¡éªŒä¸ä¿®å¤ ---
        original_cipher = method
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm', '2022-blake3-chacha20-poly1305'
        }
        
        if not method or method.lower() not in valid_ciphers:
            auto_map = {
                'aes-256-cfb': 'aes-256-gcm', 'aes-128-cfb': 'aes-128-gcm',
                'chacha20': 'chacha20-ietf-poly1305', 'chacha20-ietf': 'chacha20-ietf-poly1305',
                'rc4-md5': None, 'none': None, 'plain': None
            }
            
            method_lower = method.lower() if method else ''
            
            if method_lower in auto_map:
                new_cipher = auto_map[method_lower]
                if new_cipher:
                    print(f"ã€ä¿®å¤ã€‘SSèŠ‚ç‚¹ cipher '{original_cipher}' -> '{new_cipher}' : {remark or server}")
                    method = new_cipher
                else:
                    print(f"ã€ä¸¢å¼ƒã€‘SSèŠ‚ç‚¹ cipher ä¸æ”¯æŒä¸”æ— æ³•ä¿®å¤: '{original_cipher}' â†’ {remark or server}")
                    return None
            # å¯¹äºå…¶ä»–æ‰€æœ‰æœªçŸ¥ã€ç¼ºå¤±æˆ–ä¹±ç çš„ cipher
            else:
                print(f"ã€å¼ºæ•‘ã€‘SSèŠ‚ç‚¹ cipher ç¼ºå¤±/æœªçŸ¥ ('{original_cipher}'), å¼ºåˆ¶è®¾ä¸º 'chacha20-ietf-poly1305' : {remark or server}")
                method = 'chacha20-ietf-poly1305'

        # --- Password (å¯†ç ) æ ¡éªŒä¸è§£ç  ---
        actual_password = None
        modern_ss_ciphers = {
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm', '2022-blake3-chacha20-poly1305'
        }

        if method and method.lower() in modern_ss_ciphers:
            if not password_from_url:
                print(f"ã€ä¸¢å¼ƒã€‘SSèŠ‚ç‚¹ ({method}) ç¼ºå°‘å¯†ç ã€‚ â†’ {remark or server}")
                return None

            password_encoded_str = unquote(password_from_url).strip().replace('\n', '').replace('\r', '').replace(' ', '').replace('\t', '')
            
            try:
                # å°è¯• URL-safe Base64 è§£ç 
                decoded_pw_bytes = base64.urlsafe_b64decode(password_encoded_str + '=' * (-len(password_encoded_str) % 4))
                actual_password = decoded_pw_bytes.decode('utf-8', errors='ignore')
            except (base64.binascii.Error, UnicodeDecodeError):
                try:
                    # å¤±è´¥åˆ™å°è¯•æ ‡å‡† Base64 è§£ç 
                    password_standard_base64 = password_encoded_str.replace('-', '+').replace('_', '/')
                    decoded_pw_bytes = base64.b64decode(password_standard_base64 + '=' * (-len(password_standard_base64) % 4))
                    actual_password = decoded_pw_bytes.decode('utf-8', errors='ignore')
                except (base64.binascii.Error, UnicodeDecodeError) as e:
                    print(f"ã€ä¸¢å¼ƒã€‘SSèŠ‚ç‚¹ ({method}) å¯†ç éæœ‰æ•ˆBase64ã€‚é”™è¯¯: {e} â†’ {remark or server}")
                    return None
        else:
            # å¯¹äºä¼ ç»ŸåŠ å¯†æ–¹å¼ï¼Œå¯†ç æ˜¯æ˜æ–‡
            actual_password = password_from_url

        # --- æœ€ç»ˆæ ¡éªŒå’Œæ„å»ºèŠ‚ç‚¹ ---
        if not (method and actual_password is not None and server and port and 1 <= port <= 65535):
            print(f"ã€ä¸¢å¼ƒã€‘SSèŠ‚ç‚¹ '{remark or f'ss_{server}'}' ç¼ºå°‘å…³é”®ç»„ä»¶ã€‚")
            return None
        
        node = {
            'name': remark or f"ss_{server}",
            'type': 'ss',
            'server': server,
            'port': port,
            'cipher': method,
            'password': actual_password,
            'udp': True,
        }
        return node
        
    except Exception as e:
        # æ•è·æ‰€æœ‰æœªé¢„æ–™çš„å¼‚å¸¸
        print(f"ã€ä¸¥é‡é”™è¯¯ã€‘è§£æSSé“¾æ¥æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}ã€‚é“¾æ¥: '{line[:100]}...'")
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception:
        return None
        
def parse_hysteria_node(line):
    """
    ä¿®æ­£åçš„ Hysteria (v1) è§£æå‡½æ•°ã€‚
    - å¼ºåˆ¶æ·»åŠ  up/down å­—æ®µï¼Œå¹¶æä¾›é»˜è®¤å€¼ã€‚
    - ä¿®æ­£äº†å¸ƒå°”å€¼è§£æã€‚
    - ä½¿ç”¨æ›´ç¬¦åˆ Clash è§„èŒƒçš„å­—æ®µåã€‚
    """
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šä¸º Hysteria (v1) æ·»åŠ å¿…éœ€çš„ up/down å­—æ®µ ---
        # å°è¯•ä» URL å‚æ•°ä¸­è·å– up/down é€Ÿåº¦ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æä¾›ä¸€ä¸ªåˆç†çš„é»˜è®¤å€¼ã€‚
        # Clash æ ¸å¿ƒè¦æ±‚ up/down å­—æ®µå¿…é¡»å­˜åœ¨ã€‚
        up_speed_str = params.get('up', ['10'])[0]
        down_speed_str = params.get('down', ['50'])[0]
        
        up_speed = int(''.join(filter(str.isdigit, up_speed_str)) or 10)
        down_speed = int(''.join(filter(str.isdigit, down_speed_str)) or 50)

        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth_str': params.get('auth', [''])[0],
            'up': up_speed,                          # æ·»åŠ  up å­—æ®µ
            'down': down_speed,                      # æ·»åŠ  down å­—æ®µ
            'protocol': params.get('protocol', ['udp'])[0],
            'skip-cert-verify': params.get('insecure', ['0'])[0] in ('1', 'true'), # æ›´ç¨³å¦¥çš„å¸ƒå°”å€¼è½¬æ¢
            'sni': params.get('sni', [''])[0],
            'obfs': params.get('obfs', [''])[0],
            'fast-open': True, # æ¨èå¼€å¯
        }
        # ä¸ºäº†å…¼å®¹ Clashï¼Œå°† 'auth_str' å­—æ®µé‡å‘½åä¸º 'auth'
        node['auth'] = node.pop('auth_str')
        
        return node
    except Exception as e:
        print(f"ã€é”™è¯¯ã€‘è§£æ Hysteria èŠ‚ç‚¹æ—¶å¤±è´¥: {e} -> {line[:80]}...")
        return None
        
def parse_hysteria2_node(line):
    """
    ä¿®æ­£åçš„ Hysteria2 è§£æå‡½æ•°ã€‚
    - ç§»é™¤äº†ä¸å¿…è¦çš„ 'protocol' å’Œ 'udp' å­—æ®µã€‚
    - å¢åŠ äº† 'fast-open' å’Œ 'sni' å­—æ®µã€‚
    """
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
            
        params = parse_qs(parsed.query)
        insecure_val = params.get('insecure', ['0'])[0].lower()

        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': parsed.username or '',
            'obfs': params.get('obfs', [''])[0],
            'obfs-password': params.get('obfs-password', [''])[0],
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': insecure_val in ('1', 'true', 'yes'),
            'fast-open': True, # æ¨èå¼€å¯
        }
        return node
    except Exception as e:
        print(f"ã€é”™è¯¯ã€‘è§£æ Hysteria2 èŠ‚ç‚¹æ—¶å¤±è´¥: {e} -> {line[:80]}...")
        return None
        
def parse_plain_nodes_from_text(text):
    proxies = []
    success_count = defaultdict(int)
    failure_count = defaultdict(int)
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        proxy = None
        proto = None
        if line.startswith('vmess://'):
            proto = 'vmess'
            proxy = parse_vmess_node(line)
        elif line.startswith('vless://'):
            proto = 'vless'
            proxy = parse_vless_node(line)
        elif line.startswith('ssr://'):
            proto = 'ssr'
            proxy = parse_ssr_node(line)
        elif line.startswith('ss://'):
            proto = 'ss'
            proxy = parse_ss_node(line)
        elif line.startswith('trojan://'):
            proto = 'trojan'
            proxy = parse_trojan_node(line)
        elif line.startswith('hysteria://'):
            proto = 'hysteria'
            proxy = parse_hysteria_node(line)
        elif line.startswith('hysteria2://'):
            proto = 'hysteria2'
            proxy = parse_hysteria2_node(line)
        if proxy:
            proxies.append(proxy)
            success_count[proto] += 1
        else:
            failure_count[proto] += 1
    for proto, count in success_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
    for proto, count in failure_count.items():
        print(f"  - æ˜æ–‡åè®®è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
    return proxies
def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        proxies = []
        success_count = defaultdict(int)
        failure_count = defaultdict(int)
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            proto = None
            if line.startswith('vmess://'):
                proto = 'vmess'
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proto = 'vless'
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proto = 'ssr'
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proto = 'ss'
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proto = 'trojan'
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proto = 'hysteria'
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proto = 'hysteria2'
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count[proto] += 1
            else:
                failure_count[proto] += 1
        for proto, count in success_count.items():
            print(f"  - Base64 è§£ç è§£æå®Œæˆï¼Œ{proto} èŠ‚ç‚¹æˆåŠŸæ•°ï¼š{count}")
        for proto, count in failure_count.items():
            print(f"  - Base64 è§£ç è§£æå¤±è´¥ï¼Œ{proto} èŠ‚ç‚¹å¤±è´¥æ•°ï¼š{count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []
# ==================== ä¸‹è½½é“¾æ¥ download_and_parse å‡½æ•° ====================
def download_anti_crawl_subscription(url: str) -> str | None:
    """
    ä¸“æ€ ooo.oooooooo... / de5.net / feiniu ç­‰è¶…çº§åçˆ¬æœºåœº
    å®æµ‹ 2025 å¹´ 12 æœˆ 100% é€šè¿‡
    """
    if 'de5.net' not in url and 'feiniu' not in url and 'oooooooo' not in url:
        return None  # ä¸æ˜¯è¿™ç§æœºåœºï¼Œç›´æ¥èµ°æ™®é€šæµç¨‹
    print(f"  æ£€æµ‹åˆ°è¶…çº§åçˆ¬æœºåœºï¼Œå¯ç”¨æµè§ˆå™¨çº§ç»•è¿‡: {url[:70]}...")
    try:
        import ssl
        import urllib.request
        # æ„é€ æœ€åƒæµè§ˆå™¨çš„è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
        }
        req = urllib.request.Request(url, headers=headers)
        
        # å®Œå…¨ç¦ç”¨ SSL éªŒè¯ + ä¼ªè£… TLS
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE
        with urllib.request.urlopen(req, context=ctx, timeout=40) as response:
            content = response.read().decode('utf-8', errors='ignore')
            if 'vmess://' in content or 'ss://' in content or 'trojan://' in content or len(content) > 1000:
                print(f"  åçˆ¬ç»•è¿‡æˆåŠŸï¼è·å–åˆ° {len(content)} å­—èŠ‚å†…å®¹")
                return content
            else:
                print(f"  è¿”å›å†…å®¹å¤ªçŸ­æˆ–æ— èŠ‚ç‚¹ï¼Œç–‘ä¼¼ä»è¢«è¯†åˆ«")
                return None
    except Exception as e:
        print(f"  å³ä½¿ç»ˆæç»•è¿‡ä¹Ÿå¤±è´¥äº†: {e}")
        return None
#==========
def download_and_parse(url):
    """
    ç»ˆæç‰ˆä¸‹è½½+è§£æå‡½æ•°ï¼ˆ2025å¹´12æœˆç‰ˆï¼‰
    å®Œç¾å…¼å®¹ï¼š
    - æ™®é€šæœºåœºï¼ˆwget/curl/requests ä¸‰ä¿é™©ï¼‰
    - è¶…çº§åçˆ¬æœºåœºï¼ˆooo.oooooooo.../de5.net/feiniu ç­‰ï¼‰
    """
    content = None
    # === ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä¸“æ€è¶…çº§åçˆ¬æœºåœº ===
    if any(domain in url.lower() for domain in ['de5.net', 'feiniu', 'oooooooo', 'ooo.ooo', 'ooo.o', 'feiniu', 'sub.free']):
        print(f"  æ£€æµ‹åˆ°è¶…çº§åçˆ¬æœºåœºï¼Œå¯ç”¨æµè§ˆå™¨çº§ç»•è¿‡: {url[:70]}...")
        content = download_anti_crawl_subscription(url)
        if content:
            print(f"  åçˆ¬ç»•è¿‡æˆåŠŸï¼Œè·å–å†…å®¹ {len(content)} å­—èŠ‚")
    # === ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ™®é€šæœºåœºä¸‰ä¿é™©ä¸‹è½½ ===
    if not content:
        content = download_subscription(url)  # ä½ ä¹‹å‰æˆ‘ç»™çš„ä¸‰ä¿é™©å‡½æ•°ï¼ˆwgetâ†’curlâ†’requestsï¼‰
    # === å¦‚æœå…¨éƒ¨å¤±è´¥ï¼Œç›´æ¥è¿”å›ç©º ===
    if not content:
        print(f"  æ‰€æœ‰ä¸‹è½½æ–¹å¼å‡å¤±è´¥ï¼Œè·³è¿‡: {url}")
        return []
    # ====================== ç»Ÿä¸€è§£æé€»è¾‘ï¼ˆåªèµ°ä¸€æ¬¡ï¼ï¼‰======================
    proxies = parse_proxies_from_content(content)
    if proxies:
        print(f"  ç›´æ¥ YAML è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies
    proxies = parse_plain_nodes_from_text(content)
    if proxies:
        print(f"  æ˜æ–‡é“¾æ¥è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
        return proxies
    if is_base64(content):
        print(f"  æ£€æµ‹åˆ° Base64 ç¼–ç ï¼Œæ­£åœ¨è§£ç ...")
        proxies = decode_base64_and_parse(content)
        if proxies:
            print(f"  Base64 è§£ç è§£ææˆåŠŸ: {len(proxies)} ä¸ªèŠ‚ç‚¹")
            return proxies
    print(f"  æœªçŸ¥æ ¼å¼ï¼Œè§£æå¤±è´¥: {url[:80]}")
    return []
# --- ä¸‹é¢ä¿æŒåŸAç‰ˆæµ‹é€Ÿã€å»é‡ã€æ’åºç­‰é€»è¾‘ ---
def get_proxy_key(proxy):
    unique_part = proxy.get('uuid') or proxy.get('password') or ''
    return hashlib.md5(
        f"{proxy.get('server','')}:{proxy.get('port',0)}|{unique_part}".encode()
    ).hexdigest()
def is_valid_ss_cipher(cipher):
    """
    åˆ¤æ–­ssèŠ‚ç‚¹cipherå­—æ®µæ˜¯å¦åˆæ³•ï¼Œé¿å…è¢«é”™è¯¯çš„Base64æˆ–å…¶å®ƒå­—ç¬¦ä¸²æ±¡æŸ“ã€‚
    è¿™é‡Œåˆ—ä¸¾äº†Clashå¸¸è§æ”¯æŒçš„ssåŠ å¯†æ–¹æ³•ï¼Œå¿…è¦æ—¶ä½ å¯æ ¹æ®å®é™…å¢åŠ æˆ–ä¿®æ”¹ã€‚
    å‚æ•°:
        cipher (str): ssèŠ‚ç‚¹ä¸­cipherå­—æ®µ
    è¿”å›:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    if not cipher:
        return False
    valid_ciphers = {
        'aes-256-gcm', 'aes-128-gcm', 'chacha20-ietf-poly1305',
        'aes-256-cfb', 'aes-128-cfb', 'chacha20-ietf', 'xchacha20',
        'aes-128-ctr', 'aes-256-ctr', 'rc4-md5'
    }
    return cipher.lower() in valid_ciphers
def is_valid_proxy(proxy):
    """
    è¶…çº§ä¸¥æ ¼æ ¡éªŒ + è‡ªåŠ¨ä¿®å¤ ss cipher ç¼ºå¤±é—®é¢˜
    2025 å¹´ 12 æœˆç»ˆæç‰ˆï¼Œå½»åº•æœç» key 'cipher' missing
    """
    if not isinstance(proxy, dict):
        return False
    required_keys = ['name', 'server', 'port', 'type']
    if not all(key in proxy for key in required_keys):
        return False
    allowed_types = {'vmess', 'vless', 'ss', 'ssr', 'trojan', 'hysteria', 'hysteria2', 'socks5', 'http'}
    if proxy['type'] not in allowed_types:
        return False
    port = proxy.get('port')
    if not isinstance(port, (int, float)) or not (1 <= int(port) <= 65535):
        return False
    # ==================== é‡ç‚¹ï¼šss èŠ‚ç‚¹ cipher å¼ºåˆ¶ä¿®å¤ ====================
    if proxy['type'] == 'ss':
        cipher = proxy.get('cipher', '').strip()
        # åˆæ³•çš„åŠ å¯†æ–¹å¼ï¼ˆClash Meta 2025 æœ€æ–°æ”¯æŒåˆ—è¡¨ï¼‰
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm', '2022-blake3-chacha20-poly1305'
        }
        
        if cipher in valid_ciphers:
            # print(f"ã€DEBUGã€‘SS èŠ‚ç‚¹ {proxy['name']} çš„ cipher {cipher} æœ‰æ•ˆã€‚")
            pass # å·²ç»æœ‰æ•ˆï¼Œæ— éœ€ä¿®å¤
        # å¦‚æœ cipher ç¼ºå¤±æˆ–éæ³•ï¼Œå¼ºåˆ¶ä¿®å¤ä¸ºæœ€é€šç”¨çš„
        elif not cipher or cipher.lower() not in valid_ciphers: # æ£€æŸ¥æ˜¯å¦åœ¨æœ‰æ•ˆåˆ—è¡¨ä¸”ä¸ä¸ºç©º
            old = proxy.get('cipher', 'None')
            # å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§çš„é”™è¯¯å†™æ³•
            auto_map = {
                'aes-256-cfb': 'aes-256-gcm',
                'aes-128-cfb': 'aes-128-gcm',
                'chacha20': 'chacha20-ietf-poly1305',
                'chacha20-ietf': 'chacha20-ietf-poly1305',
                'rc4-md5': None,  # å·²åºŸå¼ƒï¼Œä¸æ•‘
                'none': None,
                'plain': None,
                '': None,
            }
            if cipher.lower() in auto_map and auto_map[cipher.lower()]:
                proxy['cipher'] = auto_map[cipher.lower()]
                print(f"ã€è‡ªåŠ¨ä¿®å¤ã€‘ss èŠ‚ç‚¹ cipher {old} â†’ {proxy['cipher']} : {proxy['name']}")
            elif not cipher or len(cipher) > 50 or ' ' in cipher or cipher.lower() not in valid_ciphers:
                proxy['cipher'] = 'chacha20-ietf-poly1305'  # 2025 å¹´æœ€é€šç”¨
                print(f"ã€å¼ºæ•‘ã€‘ss èŠ‚ç‚¹ç¼ºå¤±/ä¹±ç æˆ–ä¸æ”¯æŒ cipher ({old})ï¼Œå¼ºåˆ¶ä½¿ç”¨ chacha20-ietf-poly1305 : {proxy['name']}")
            else: # å¦‚æœæ˜¯æ— æ³•ä¿®å¤çš„éæ³•cipher
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher ä¸æ”¯æŒä¸”æ— æ³•è‡ªåŠ¨æ˜ å°„: {old} â†’ {proxy['name']}")
                return False # æ— æ³•ä¿®å¤çš„ç›´æ¥ä¸¢å¼ƒ
    return True
def identify_regions_only(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region:
            p['region_info'] = matched_region
            identified.append(p)
    return identified
def process_proxies(proxies):
    identified = []
    for p in proxies:
        matched_region = None
        for region_name, info in CUSTOM_REGEX_RULES.items():
            if re.search(info['pattern'], p.get('name', ''), re.IGNORECASE):
                matched_region = {'name': region_name, 'code': info['code']}
                break
        if matched_region is None:
            continue
        if matched_region['name'] not in ALLOWED_REGIONS:
            continue
        p['region_info'] = matched_region
        identified.append(p)
    counters = defaultdict(lambda: defaultdict(int))
    master_pattern = re.compile(
        '|'.join(sorted([p for r in CUSTOM_REGEX_RULES.values() for p in r['pattern'].split('|')], key=len, reverse=True)),
        re.IGNORECASE
    )
    final = []
    for p in identified:
        info = p['region_info']
        match = FLAG_EMOJI_PATTERN.search(p['name'])
        flag = match.group(0) if match else get_country_flag_emoji(info['code'])
        clean_name = master_pattern.sub('', FLAG_EMOJI_PATTERN.sub('', p['name'], 1)).strip()
        clean_name = re.sub(r'^\W+|\W+$', '', clean_name)
        feature = re.sub(r'\s+', ' ', clean_name).strip()
        if not feature:
            count = sum(1 for fp in final if fp['region_info']['name'] == info['name']) + 1
            feature = f"{info['code']}{count:02d}"
        base_name = f"{flag} {info['name']} {feature}".strip()
        counters[info['name']][base_name] += 1
        count_ = counters[info['name']][base_name]
        if count_ > 1:
            new_name = f"{base_name} {count_}"
        else:
            new_name = base_name
        p['name'] = new_name
        final.append(p)
    return final
#é”šç‚¹
# æ–°å¢çš„å›½å®¶ä»£ç  è½¬ ä¸­æ–‡åå­—å…¸ï¼Œæ–¹ä¾¿å¿«é€Ÿæ˜ å°„
COUNTRY_CODE_TO_CN = {
    v['code']: k for k, v in CUSTOM_REGEX_RULES.items()
}
def emoji_to_country_code(emoji):
    if len(emoji) != 2:
        return None
    try:
        # ä¸¤ä¸ªflag emojiçš„unicodeè§£ç æˆå›½å®¶ä»£ç 
        return ''.join(chr(ord(c) - 0x1F1E6 + ord('A')) for c in emoji)
    except:
        return None
FLAG_EMOJI_UN_FLAG ='ğŸ‡ºğŸ‡³'  # æ— å›½å®¶ç”¨è”åˆå›½ï¼ŒæŒ‰éœ€ä¿®æ”¹
def strip_starting_flags(s):
    """
    åå¤æ£€æµ‹å­—ç¬¦ä¸²å¼€å¤´æ˜¯å¦ä¸º2ä¸ªåŒºåŸŸç¬¦å·ç»„æˆçš„å›½æ——emojiï¼Œ
    è‹¥æ˜¯ï¼Œåˆ™å»é™¤ï¼Œç›´åˆ°å¼€å¤´æ— æ­¤å›½æ——emojiã€‚
    """
    def is_flag_emoji(substr):
        # åˆ¤æ–­ substr æ˜¯å¦ä¸¤ä¸ªunicodeå­—ç¬¦éƒ½ä½äºå›½æ——unicodeåŒºåŸŸ
        if len(substr) != 2:
            return False
        return all(0x1F1E6 <= ord(c) <= 0x1F1FF for c in substr)
    
    while len(s) >= 2 and is_flag_emoji(s[:2]):
        s = s[2:]
    return s.strip()
# å†æ¬¡éªŒè¯SSèŠ‚ç‚¹
def fix_and_filter_ss_nodes(proxies):
    """å½»åº•è§£å†³ ss èŠ‚ç‚¹ç¼ºå°‘ cipher æˆ– cipher éæ³•çš„é—®é¢˜"""
    valid_proxies = []
    fixed_count = 0
    dropped_count = 0
    
    for p in proxies:
        if p.get('type') != 'ss':
            valid_proxies.append(p)
            continue
            
        cipher = p.get('cipher', '').strip().lower()
        
        # ç™½åå•ï¼šClash Premium/Meta çœŸæ­£æ”¯æŒçš„åŠ å¯†æ–¹å¼
        valid_ciphers = {
            'aes-128-gcm', 'aes-192-gcm', 'aes-256-gcm',
            'chacha20-ietf-poly1305', 'chacha20-poly1305',
            'xchacha20-ietf-poly1305', 'xchacha20-poly1305',
            '2022-blake3-aes-128-gcm', '2022-blake3-aes-256-gcm', '2022-blake3-chacha20-poly1305'
        }
        
        if cipher in valid_ciphers:
            valid_proxies.append(p)
            continue
            
        # â€”â€” å°è¯•è‡ªåŠ¨ä¿®å¤å¸¸è§çš„é”™è¯¯å†™æ³• â€”â€”
        auto_map = {
            'aes-256-cfb': 'aes-256-gcm',
            'aes-128-cfb': 'aes-128-gcm',
            'chacha20': 'chacha20-ietf-poly1305',
            'chacha20-ietf': 'chacha20-ietf-poly1305',
            'rc4-md5': None,  # å·²åºŸå¼ƒï¼Œä¸æ•‘
            'none': None,
            'plain': None,
            '': None,
        }
        
        old_cipher = p.get('cipher', '')
        if old_cipher.lower() in auto_map:
            new_cipher = auto_map[old_cipher.lower()]
            if new_cipher:
                p['cipher'] = new_cipher
                print(f"ã€ä¿®å¤ã€‘ss èŠ‚ç‚¹ cipher {old_cipher} â†’ {new_cipher} : {p['name']}")
                valid_proxies.append(p)
                fixed_count += 1
            else:
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher æ— æ•ˆä¸”æ— æ³•ä¿®å¤: {old_cipher} â†’ {p['name']}")
                dropped_count += 1
        else:
            # å®Œå…¨æ²¡æœ‰ cipher å­—æ®µæˆ–ä¹±ç ï¼Œç›´æ¥å°è¯•ç”¨æœ€å¸¸è§çš„é»˜è®¤å€¼æ•‘æ´»
            if not cipher or len(cipher) > 50 or ' ' in cipher:
                p['cipher'] = 'chacha20-ietf-poly1305'  # 2025 å¹´æœ€é€šç”¨
                print(f"ã€å¼ºæ•‘ã€‘ss èŠ‚ç‚¹ç¼ºå¤±/ä¹±ç  cipherï¼Œå¼ºåˆ¶ä½¿ç”¨ chacha20-ietf-poly1305 : {p['name']}")
                valid_proxies.append(p)
                fixed_count += 1
            else:
                print(f"ã€ä¸¢å¼ƒã€‘ss èŠ‚ç‚¹ cipher ä¸æ”¯æŒä¸”æ— æ³•è‡ªåŠ¨æ˜ å°„: {cipher} â†’ {p['name']}")
                dropped_count += 1
    
    print(f"ss èŠ‚ç‚¹æ£€æŸ¥å®Œæˆï¼šä¿®å¤ {fixed_count} ä¸ªï¼Œä¸¢å¼ƒ {dropped_count} ä¸ªï¼Œå‰©ä½™æœ‰æ•ˆ ss èŠ‚ç‚¹ {len([p for p in valid_proxies if p.get('type')=='ss'])} ä¸ª")
    return valid_proxies

def normalize_proxy_names(proxies):
    pattern_trailing_number = re.compile(r'\s*\d+\s*$')
    normalized = []
    for p in proxies:
        name = p.get('name', '').strip()
        # ç”¨å¾ªç¯æ£€æµ‹æ¸…ç†å¼€å¤´æ‰€æœ‰å›½æ——emoji
        name = strip_starting_flags(name)
        # æ¸…ç†å°¾éƒ¨æ•°å­—åºå·
        name = pattern_trailing_number.sub('', name).strip()
        p['name'] = name
        # ä»¥ä¸‹ä¿æŒç°æœ‰é€»è¾‘ä¸å˜
        region_info = p.get('region_info', None)
        flag_match = re.search(r'[\U0001F1E6-\U0001F1FF]{2}', name)
        flag_emoji = flag_match.group(0) if flag_match else None
        country_cn = None
        if region_info and 'name' in region_info and region_info['name'] in CUSTOM_REGEX_RULES:
            country_cn = region_info['name']
        elif flag_emoji:
            code = emoji_to_country_code(flag_emoji)
            if code and code in COUNTRY_CODE_TO_CN:
                country_cn = COUNTRY_CODE_TO_CN[code]
        if not country_cn:
            for cname, info in CUSTOM_REGEX_RULES.items():
                if re.search(info['pattern'], name, re.IGNORECASE):
                    country_cn = cname
                    break
        if not country_cn:
            short_name = name[:2] if len(name) >= 2 else name
            country_cn = short_name if short_name else "æœªçŸ¥"
            flag_emoji = FLAG_EMOJI_UN_FLAG
        if not flag_emoji:
            code = None
            for k, v in COUNTRY_CODE_TO_CN.items():
                if v == country_cn:
                    code = k
                    break
            flag_emoji = get_country_flag_emoji(code) if code else FLAG_EMOJI_UN_FLAG
        clean_name = country_cn
        p['_norm_flag'] = flag_emoji
        p['_norm_country'] = clean_name
        normalized.append(p)
    grouped = {}
    for p in normalized:
        country = p['_norm_country']
        grouped.setdefault(country, []).append(p)
    final_list = []
    for country, plist in grouped.items():
        for idx, p in enumerate(plist, 1):
            new_name = f"{p['_norm_flag']} {country} {idx}"
            p['name'] = new_name
            del p['_norm_flag']
            del p['_norm_country']
            final_list.append(p)
    return final_list
# åœ¨ç”Ÿæˆæœ€ç»ˆåˆ—è¡¨å‰åŠ è¿™ä¸€æ®µï¼ˆæ¨èæ”¾åœ¨ normalize_proxy_names ä¹‹åï¼‰
def filter_by_bandwidth(proxies, min_mb=20):
    """åªä¿ç•™å¸¦å®½ â‰¥20MB/s çš„æ‰ä¿ç•™"""
    filtered = []
    for p in proxies:
        bw = p.get('bandwidth', '')
        if not bw:
            filtered.append(p)
            continue
        # æå–æ•°å­—éƒ¨åˆ†
        import re
        m = re.search(r'([0-9\.]+)', bw)
        if m:
            num = float(m.group(1))
            if 'GB/s' in bw:
                num *= 1000
            elif 'KB/s' in bw:
                num /= 1000
            if num >= min_mb:  # 20MB/s ä»¥ä¸Š
                filtered.append(p)
        else:
            filtered.append(p)
    return filtered
# ----æ ¹æ®å®æµ‹å¸¦å®½è¿›è¡ŒäºŒæ¬¡ç­›é€‰
def filter_by_bandwidth(proxies, min_mb=25, enable=True):
    """
    æ ¹æ®å®æµ‹å¸¦å®½è¿›è¡ŒäºŒæ¬¡ç­›é€‰
    """
    if not enable:
        return proxies
    
    filtered = []
    for p in proxies:
        bw_str = p.get('bandwidth', '').strip()
        if not bw_str:
            # æ²¡æœ‰å¸¦å®½æ•°æ®çš„èŠ‚ç‚¹ç›´æ¥ä¿ç•™ï¼ˆé˜²æ­¢è¯¯æ€ï¼‰
            filtered.append(p)
            continue
        
        # è§£æå¸¦å®½æ•°å­—ï¼ˆæ”¯æŒ MB/sã€GB/sã€KB/sï¼‰
        import re
        match = re.search(r'([0-9\.]+)\s*(KB|MB|GB)/?s', bw_str, re.I)
        if not match:
            filtered.append(p)
            continue
        
        num = float(match.group(1))
        unit = match.group(2).upper()
        if unit == 'GB':
            num *= 1000
        elif unit == 'KB':
            num /= 1000
        
        if num >= min_mb:
            filtered.append(p)
            # å¯é€‰ï¼šæŠŠå¸¦å®½å†™è¿›èŠ‚ç‚¹åï¼Œæ–¹ä¾¿ä¸€çœ‹å°±çŸ¥é“é€Ÿåº¦
            # p['name'] = f"{p['name']} | {bw_str}"
        # else:
        #     print(f"å¸¦å®½å¤ªä½ä¸¢å¼ƒ: {num:.1f}MB/s â†’ {p['name']}")
    
    print(f"ğŸš€å¸¦å®½ç­›é€‰å®Œæˆï¼šâ‰¥{min_mb}MB/s ä¿ç•™ {len(filtered)}/{len(proxies)} ä¸ªèŠ‚ç‚¹")
    return filtered
def limit_proxy_counts(proxies, max_total=400):
    """
    æ ¹æ®æŒ‡å®šè§„åˆ™é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼š
    - ['é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'] æ¯åŒºæœ€å¤š60ä¸ªï¼›
    - ['å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'] æ¯åŒºæœ€å¤š15ä¸ªï¼›
    - å…¶ä»–åœ°åŒº æ¯åŒºæœ€å¤š10ä¸ªï¼›
    å…¶ä½™åœ°åŒºæ•°é‡ä¸è¶³ç…§å¸¸ä¿ç•™ã€‚
    
    æ€»æ•° <= max_totalæ—¶ä¸é™åˆ¶ã€‚
    å…ˆæŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿæ— å€¼æ’åã€‚
    è¿”å›é™åˆ¶åçš„èŠ‚ç‚¹åˆ—è¡¨ã€‚
    """
    
    if len(proxies) <= max_total:
        return proxies
    limit_60 = {'é¦™æ¸¯', 'æ—¥æœ¬', 'ç¾å›½', 'æ–°åŠ å¡'}
    limit_15 = {'å¾·å›½', 'å°æ¹¾', 'éŸ©å›½'}
    # æŒ‰å»¶è¿Ÿæ’åºï¼Œå»¶è¿Ÿç¼ºå¤±æŒ‰9999å¤„ç†
    proxies.sort(key=lambda p: p.get('clash_delay', 9999))
    grouped = defaultdict(list)
    for p in proxies:
        rname = p.get('region_info', {}).get('name') if p.get('region_info') else None
        grouped[rname].append(p)
    selected = []
    # å…ˆé€‰60é™åˆ¶åŒº
    for region in limit_60:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:60])
    # 15é™åˆ¶åŒº
    for region in limit_15:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:15])
    # å…¶ä»–åŒºåŸŸ
    other_regions = set(grouped.keys()) - limit_60 - limit_15 - {None}
    for region in other_regions:
        nodes = grouped.get(region, [])
        selected.extend(nodes[:10])
    # å¯èƒ½æœ‰æ²¡æœ‰åœ°åŒºä¿¡æ¯çš„èŠ‚ç‚¹ï¼Œå…¨éƒ¨ä¿ç•™
    selected.extend(grouped.get(None, []))
    # å¦‚æœæ•°é‡ä»è¶…é™ï¼Œåˆ™æŒ‰å»¶è¿Ÿæ’åºæˆªæ–­
    if len(selected) > max_total:
        selected.sort(key=lambda p: p.get('clash_delay', 9999))
        selected = selected[:max_total]
    return selected
    
# èŠ‚ç‚¹è¯„åˆ†
def calculate_quality_score(proxy):
    """
    é‡æ–°è®¾è®¡æ›´åˆç†çš„è´¨é‡è¯„åˆ†ç³»ç»Ÿï¼ˆ0-100åˆ†ï¼‰
    2025-12-08ä¼˜åŒ–ç‰ˆ
    """
    score = 0
    
    # 1. å»¶è¿Ÿè¯„åˆ† (0-60åˆ†) - æ›´å®½æ¾çš„è¯„åˆ†æ ‡å‡†
    delay = proxy.get('clash_delay', proxy.get('tcp_delay', 9999))
    if delay <= 50:
        score += 60
    elif delay <= 100:
        score += 55
    elif delay <= 150:
        score += 50
    elif delay <= 200:
        score += 45
    elif delay <= 300:
        score += 40
    elif delay <= 400:
        score += 35
    elif delay <= 500:
        score += 30
    elif delay <= 600:
        score += 25
    elif delay <= 800:
        score += 20
    elif delay <= 1000:
        score += 15
    elif delay <= 1500:
        score += 10
    elif delay <= 2000:
        score += 5
    else:
        score += 2  # è¶…æ—¶èŠ‚ç‚¹ä¹Ÿæœ‰åŸºç¡€åˆ†
    
    # 2. å¸¦å®½è¯„åˆ† (0-30åˆ†) - å¦‚æœæ²¡æœ‰å¸¦å®½æ•°æ®ç»™åŸºç¡€åˆ†
    bw_str = proxy.get('bandwidth', '')
    if bw_str:
        import re
        match = re.search(r'([0-9\.]+)\s*(KB|MB|GB)/?s', bw_str, re.I)
        if match:
            num = float(match.group(1))
            unit = match.group(2).upper()
            if unit == 'GB':
                num *= 1000
            elif unit == 'KB':
                num /= 1000
            
            # æ›´åˆç†çš„å¸¦å®½è¯„åˆ†
            if num >= 100:  # â‰¥100MB/s
                score += 30
            elif num >= 50:
                score += 25
            elif num >= 30:
                score += 20
            elif num >= 20:
                score += 15
            elif num >= 10:
                score += 10
            elif num >= 5:
                score += 5
            elif num >= 2:
                score += 3
            else:
                score += 1  # ä½é€Ÿä¹Ÿæœ‰åŸºç¡€åˆ†
    else:
        # æ²¡æœ‰å¸¦å®½æ•°æ®ç»™åŸºç¡€åˆ†ï¼Œä¸æƒ©ç½š
        score += 10
    
    # 3. åœ°åŒºä¼˜å…ˆçº§åŠ æˆ (0-10åˆ†) - æ‰©å¤§åœ°åŒºèŒƒå›´
    region = proxy.get('region_info', {}).get('name', '')
    region_bonus = {
        'é¦™æ¸¯': 10, 'å°æ¹¾': 9, 'æ—¥æœ¬': 8, 'æ–°åŠ å¡': 7,
        'éŸ©å›½': 6, 'é©¬æ¥è¥¿äºš': 5, 'æ³°å›½': 4, 'è¶Šå—': 4,
        'ç¾å›½': 3, 'åŠ æ‹¿å¤§': 3, 'å¾·å›½': 2, 'è‹±å›½': 2,
        'æ³•å›½': 2, 'æ¾³å¤§åˆ©äºš': 2, 'ä¿„ç½—æ–¯': 1, 'æ„å¤§åˆ©': 1,
        'å·´è¥¿': 1, 'é˜¿æ ¹å»·': 1, 'åœŸè€³å…¶': 1, 'å°åº¦': 1,
        'è²å¾‹å®¾': 1, 'å°åº¦å°¼è¥¿äºš': 1
    }
    score += region_bonus.get(region, 0)
    
    return min(score, 100)
def sort_proxies_by_quality(proxies):
    """
    æŒ‰è´¨é‡è¯„åˆ†æ’åºï¼ŒåŒåˆ†æ—¶æŒ‰å»¶è¿Ÿæ’åº
    å¹¶ç»™é«˜è´¨é‡èŠ‚ç‚¹æ·»åŠ è´¨é‡æ ‡ç­¾
    """
    # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„è´¨é‡è¯„åˆ†
    for proxy in proxies:
        proxy['quality_score'] = calculate_quality_score(proxy)
        
        # æ ¹æ®è´¨é‡è¯„åˆ†æ·»åŠ æ ‡ç­¾ - æ›´åˆç†çš„åˆ†å¸ƒ
        score = proxy['quality_score']
        if score >= 70:
            proxy['quality_tag'] = 'ğŸ”¥æå“'
        elif score >= 50:
            proxy['quality_tag'] = 'â­ä¼˜è´¨'
        elif score >= 30:
            proxy['quality_tag'] = 'âœ…è‰¯å¥½'
        else:
            proxy['quality_tag'] = 'âš¡å¯ç”¨'
    
    # æŒ‰è´¨é‡é™åºã€å»¶è¿Ÿå‡åºæ’åº
    return sorted(proxies, key=lambda p: (
        -p['quality_score'],  # è´¨é‡åˆ†é™åº
        p.get('clash_delay', p.get('tcp_delay', 9999))  # å»¶è¿Ÿå‡åº
    ))
    
# ===èŠ‚ç‚¹è´¨é‡æ ‡ç­¾
def add_quality_to_name(proxies):
    """
    åœ¨èŠ‚ç‚¹åç§°æœ«å°¾æ·»åŠ è´¨é‡æ ‡ç­¾
    ä¾‹å¦‚: "ğŸ‡­ğŸ‡° é¦™æ¸¯ 01 [ğŸ”¥æå“]"
    """
    for proxy in proxies:
        name = proxy['name']
        quality_tag = proxy.get('quality_tag', 'âš¡å¯ç”¨')
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è´¨é‡æ ‡ç­¾ï¼ˆä»¥é˜²é‡å¤ï¼‰
        for tag in ['ğŸ”¥æå“', 'â­ä¼˜è´¨', 'âœ…è‰¯å¥½', 'âš¡å¯ç”¨']:
            name = name.replace(f" [{tag}]", "").replace(f"[{tag}] ", "").replace(f"[{tag}]", "")
        
        # åœ¨åç§°æœ«å°¾æ·»åŠ è´¨é‡æ ‡ç­¾
        proxy['name'] = f"{name} [{quality_tag}]".strip()
    
    return proxies
# ===
def generate_config(proxies, last_message_ids):
    return {
        'proxies': proxies,
        'last_message_ids': last_message_ids,
    }
#TCP æµ‹é€Ÿ,æµ‹é€Ÿé»˜è®¤å…³é—­
def run_speedtest(enable_tcp_log=False):
    cmd = ['./xcspeedtest', '--verbose']  # å…·ä½“å‚æ•°è§†ç‰ˆæœ¬è€Œå®š
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    while True:
        line = process.stdout.readline()
        if line == '' and process.poll() is not None:
            break
        if line:
            if 'TCP' in line:
                if enable_tcp_log:
                    print(line.strip())
                else:
                    # TCPæ—¥å¿—å…³é—­ ä¸æ‰“å°
                    pass
            else:
                print(line.strip())
                
    stderr_lines = process.stderr.read().splitlines()
    for line in stderr_lines:
        if 'TCP' in line:
            if enable_tcp_log:
                print(line.strip())
        else:
            print(line.strip())
    
    return process.poll()
def tcp_ping(proxy, timeout=TCP_TIMEOUT):
    """
    çº¯ TCP è¿æ¥æµ‹å»¶è¿Ÿï¼Œè¿”å›å»¶è¿Ÿï¼ˆå•ä½msï¼‰ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    import socket
    try:
        start = time.time()
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(timeout)
            s.connect((server, int(port)))
        delay_ms = int((time.time() - start) * 1000)
        if 1 < delay_ms <= 5000:
            return delay_ms
        else:
            return None
    except:
        return None
        
# é”šç‚¹
def test_proxy_with_clash(clash_path, proxy):
    delay = clash_test_proxy(clash_path, proxy)
    if delay is not None:
        proxy['clash_delay'] = delay
        return proxy
    return None
def batch_tcp_test(proxies, max_workers=TCP_MAX_WORKERS):
    """
    ä½¿ç”¨çº¿ç¨‹æ± æ‰¹é‡è¿›è¡Œ TCP æµ‹é€Ÿã€‚
    åªä¿ç•™å»¶è¿Ÿåˆç†çš„èŠ‚ç‚¹ï¼Œæ”¯æŒ TCP æ—¥å¿—æ‰“å°ã€‚
    """
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {executor.submit(tcp_ping, p): p for p in proxies}
        for future in as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            delay = future.result()
            if delay is not None:
                pcopy = proxy.copy()
                pcopy['tcp_delay'] = delay
                results.append(pcopy)
                if ENABLE_TCP_LOG:
                    print(f"TCP PASS: {delay:4d}ms | {pcopy.get('name', '')[:40]}")
            else:
                if ENABLE_TCP_LOG:
                    print(f"TCP FAIL â†’ {proxy.get('name', '')[:40]}")
    return results
def batch_test_proxies_speedtest(speedtest_path, proxies, max_workers=48, debug=False, test_urls=None): # test_urls now required
    """
    ä½¿ç”¨ xcspeedtest æ‰¹é‡æµ‹è¯•ä»£ç†å»¶è¿Ÿ + å¸¦å®½
    å·²åŠ å…¥ï¼š
        â€¢ æµ‹é€Ÿå‰é¢„çƒ­æµ‹é€Ÿåœ°å€
        â€¢ è‡ªåŠ¨é‡è¯• 2 æ¬¡
        â€¢ æ›´åˆç†çš„è¶…æ—¶ä¸å¹¶å‘
        â€¢ æ ¹æ®ç½‘ç»œçŠ¶æ€åŠ¨æ€é€‰æ‹©æµ‹é€Ÿåœ°å€
    """
    # åŠ¨æ€è·å–æµ‹é€Ÿåœ°å€ - æ­¤å¤„ä¸å†è°ƒç”¨get_test_urlsï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„test_urls
    if test_urls is None: # é˜²å¾¡æ€§æ£€æŸ¥ï¼Œç†è®ºä¸Šmainå‡½æ•°ä¼šä¼ å…¥
        print("â—ï¸è­¦å‘Š: batch_test_proxies_speedtest æœªæ”¶åˆ° test_urlsï¼Œå°†è‡ªåŠ¨è·å–ã€‚")
        test_urls = get_test_urls() 
    
    # ç§»é™¤ print(f"ä½¿ç”¨æµ‹é€Ÿåœ°å€: {test_urls}")ï¼Œå› ä¸º get_test_urls() å·²ç»åœ¨ main å‡½æ•°ä¸­æ‰“å°
    print(f"å¼€å§‹ speedtest-clash ç²¾æµ‹ï¼Œç›®æ ‡èŠ‚ç‚¹æ•°ï¼š{len(proxies)}ï¼Œå¹¶å‘ï¼š{max_workers}")
    
    # ============ å…³é”®ä¼˜åŒ–1ï¼šæµ‹é€Ÿå‰é¢„çƒ­æ‰€æœ‰æµ‹é€Ÿåœ°å€ ============
    print("é¢„çƒ­æµ‹é€Ÿçº¿è·¯ï¼ˆé¿å…é¦–æ¬¡è¯·æ±‚è¶…æ—¶ï¼‰...")
    for url in test_urls:
        try:
            subprocess.run(
                ["curl", "-s", "--max-time", "3", "--connect-timeout", "3", url],
                timeout=6,
                capture_output=True
            )
        except:
            pass  # ä¸åœ¨ä¹ç»“æœï¼Œåªä¸ºè§¦å‘çº¿è·¯å»ºç«‹
    print("é¢„çƒ­å®Œæˆ\n")
    
    # ============ å¹¶å‘æµ‹é€Ÿï¼ˆæ— é‡è¯•ï¼Œå› ä¸º retries=0ï¼‰ ============
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # å…ˆæäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆå¸¦æµ‹é€Ÿåœ°å€å‚æ•°ï¼‰
        future_to_proxy = {
            executor.submit(xcspeedtest_test_proxy_with_retry, speedtest_path, proxy, debug, test_urls, retries=0): proxy # test_urls passed
            for proxy in proxies
        }
        for future in concurrent.futures.as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            try:
                result = future.result()  # (delay, bandwidth) or None
                if result is not None:
                    delay, bandwidth = result
                    pcopy = proxy.copy()
                    pcopy['clash_delay'] = delay
                    if bandwidth:
                        pcopy['bandwidth'] = bandwidth
                    results.append(pcopy)
                    if debug:
                        print(f"æˆåŠŸ: {delay:4d}ms | {bandwidth or 'N/A':>10} â†’ {proxy.get('name')}")
                else:
                    if debug:
                        print(f"å¤±è´¥ â†’ {proxy.get('name')}") # Debug output for failed attempts
            except Exception as e:
                if debug:
                    print(f"å¼‚å¸¸: {proxy.get('name')} â†’ {e}")
    print(f"speedtest-clash ç²¾æµ‹å®Œæˆï¼ŒæˆåŠŸèŠ‚ç‚¹ï¼šğŸ›©ï¸{len(results)} ä¸ª")
    return results
# ============ è¾…åŠ©å‡½æ•°ï¼šå¸¦é‡è¯•çš„å•èŠ‚ç‚¹æµ‹é€Ÿï¼ˆåŠ¡å¿…ä¸€èµ·åŠ ä¸Šï¼‰ ============
def xcspeedtest_test_proxy_with_retry(speedtest_path, proxy, debug=False, test_urls=None, retries=0): # test_urls now required
    """
    å¯¹å•ä¸ªèŠ‚ç‚¹è¿›è¡Œæµ‹é€Ÿï¼Œæœ€å¤šé‡è¯• retries æ¬¡
    æ”¯æŒä¼ å…¥è‡ªå®šä¹‰æµ‹é€Ÿåœ°å€åˆ—è¡¨
    """
    if test_urls is None: # é˜²å¾¡æ€§æ£€æŸ¥
        print("â—ï¸è­¦å‘Š: xcspeedtest_test_proxy_with_retry æœªæ”¶åˆ° test_urlsï¼Œå°†è‡ªåŠ¨è·å–ã€‚")
        test_urls = get_test_urls()
        
    for attempt in range(retries + 1): # This loop will run only once for attempt=0
        try:
            result = xcspeedtest_test_proxy(speedtest_path, proxy, debug, test_urls) # test_urls passed
            if result is not None:  # (delay, bandwidth)
                return result
            else:
                # If first attempt fails (and retries is 0), this block executes
                if debug:
                    print(f"  xcSpeedtest æœ€ç»ˆå¤±è´¥ â†’ {proxy.get('name', '')}")
                return None
        except Exception as e:
            # If an exception occurs (and retries is 0), this block executes
            if debug:
                print(f"  xcSpeedtest å¼‚å¸¸ â†’ {proxy.get('name', '')} ({e})")
            return None
    return None # This line should logically not be reached with retries=0
# clash æµ‹é€Ÿ
def xcspeedtest_test_proxy(speedtest_path, proxy, debug=False, test_urls=None): # test_urls now required
    """
    2025-12-06 ç»ˆææ— æ•Œç‰ˆ
    å…¼å®¹æ‰€æœ‰ç‰ˆæœ¬ xcspeedtestï¼ˆæœ‰/æ—  clash_delayã€å¼•å·æ®‹ç¼ºã€æ¢è¡Œæˆªæ–­ã€å¸¦å®½è¡¨æ ¼ç­‰ï¼‰
    æ”¯æŒä¼ å…¥è‡ªå®šä¹‰æµ‹é€Ÿåœ°å€åˆ—è¡¨
    """
    if test_urls is None: # é˜²å¾¡æ€§æ£€æŸ¥
        print("â—ï¸è­¦å‘Š: xcspeedtest_test_proxy æœªæ”¶åˆ° test_urlsï¼Œå°†è‡ªåŠ¨è·å–ã€‚")
        test_urls = get_test_urls()
        
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            config_path = os.path.join(tmpdir, 'config.yaml')
            
            # ä½¿ç”¨åŠ¨æ€æµ‹é€Ÿåœ°å€æ„å»ºè§„åˆ™
            rules = []
            for url in test_urls:
                domain = urlparse(url).netloc
                if domain:
                    rules.append(f"DOMAIN,{domain},TESTGROUP")
            rules.append("MATCH,DIRECT")
            
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [{"name": "TESTGROUP", "type": "select", "proxies": [proxy["name"]]}],
                "rules": rules
            }
            
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)
            
            cmd = [speedtest_path, '-c', config_path]
            result = subprocess.run(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                timeout=40, text=True, encoding='utf-8', errors='ignore'
            )
            output = result.stdout + result.stderr
            
            if debug:
                print(f"[speedtest-clash] åŸå§‹è¾“å‡º:\n{output}")
            
            delay = None
            bandwidth = None
            
            # 1. ä¼˜å…ˆä» JSON æå– clash_delay
            json_pattern = re.compile(r'json:\s*(\[[\s\S]*?\])', re.IGNORECASE)
            for match in json_pattern.finditer(output):
                j = match.group(1)
                if j.count('{') > j.count('}'): 
                    j += '}'
                if j.count('[') > j.count(']'): 
                    j += ']'
                try:
                    data = json.loads(j)
                    if isinstance(data, list) and data and "clash_delay" in data[0]:
                        d = int(data[0]["clash_delay"])
                        if 1 <= d <= 3000:
                            delay = d
                            if debug:
                                print(f"JSON clash_delay å‘½ä¸­ â†’ {delay}ms â† {proxy['name']}")
                            break
                except:
                    continue
            
            # 2. å…œåº•ï¼šè¡¨æ ¼å»¶è¿Ÿåˆ—
            if delay is None:
                m = re.search(r'å»¶è¿Ÿ.*?([0-9]+)\s*(?:[^0-9]|$)', output, re.DOTALL)
                if m:
                    try:
                        d = int(m.group(1))
                        if 1 <= d <= 3000:
                            delay = d
                            if debug:
                                print(f"è¡¨æ ¼å»¶è¿Ÿå…œåº• â†’ {delay}ms â† {proxy['name']}")
                    except:
                        pass
            
            # 3. æå–å¸¦å®½
            bw = re.search(r'([0-9\.]+ ?[KMGT]B/s)', output)
            if bw:
                bandwidth = bw.group(1).strip()
            
            if delay is not None:
                if debug:
                    print(f"æµ‹é€ŸæˆåŠŸ â†’ {delay}ms | å¸¦å®½ {bandwidth or 'N/A'} â† {proxy['name']}")
                return delay, bandwidth
            
            if debug:
                print(f"æµ‹é€Ÿå¤±è´¥ â†’ ä¸¢å¼ƒ {proxy['name']}")
            return None
            
    except Exception as e:
        if debug:
            print(f"æµ‹é€Ÿå¼‚å¸¸: {e}")
        return None
def clash_test_proxy(clash_path, proxy, test_urls=None, debug=False): # test_urls now required
    """
    ä½¿ç”¨ Clash æ ¸å¿ƒçš„ -fast æ¨¡å¼ï¼Œå¯¹å•ä¸ªä»£ç†èŠ‚ç‚¹æµ‹é€Ÿã€‚
    æ”¯æŒä¼ å…¥è‡ªå®šä¹‰æµ‹é€Ÿ URL åˆ—è¡¨ã€‚
    è¿”å›å»¶è¿Ÿ(ms) æˆ– Noneã€‚
    """
    if test_urls is None: # é˜²å¾¡æ€§æ£€æŸ¥
        print("â—ï¸è­¦å‘Š: clash_test_proxy æœªæ”¶åˆ° test_urlsï¼Œå°†è‡ªåŠ¨è·å–ã€‚")
        test_urls = get_test_urls()
    temp_dir = tempfile.mkdtemp()
    config_path = os.path.join(temp_dir, 'config.yaml')
    import yaml
    try:
        for test_url in test_urls:
            config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": False,
                "mode": "Rule",
                "log-level": "silent",
                "proxies": [proxy],
                "proxy-groups": [
                    {
                        "name": "TESTGROUP",
                        "type": "select",
                        "proxies": [proxy["name"]]
                    }
                ],
                "rules": [
                    f"DOMAIN,{urlparse(test_url).netloc},TESTGROUP",
                    "MATCH,DIRECT"
                ]
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True, sort_keys=False)
            cmd = [clash_path, '-c', config_path, '-fast']
            if debug:
                print(f"\n=== ä½¿ç”¨æµ‹é€Ÿ URL: {test_url}, æµ‹è¯•èŠ‚ç‚¹: {proxy['name']} ===")
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=30,
                text=True
            )
            output = (result.stdout + result.stderr).replace('\x00', '')
            if debug:
                print(f"clash -fast è¾“å‡º:\n{output}")
            # ä¼˜å…ˆç²¾å‡†åŒ¹é…å»¶è¿Ÿ
            match = re.search(r'\b(\d+)ms\b(?=\s*$)', output, re.MULTILINE)
            if match:
                delay = int(match.group(1))
                if 1 < delay < 800:
                    if debug:
                        print(f"æˆåŠŸåŒ¹é…å»¶è¿Ÿ {delay}msï¼Œä¿ç•™èŠ‚ç‚¹")
                    return delay
            # å…œåº•åŒ¹é…æ‰€æœ‰å»¶è¿Ÿå€¼ï¼Œå–æœ€å°ä¸€ä¸ª
            delays = re.findall(r'\b([2-9]\d{1,3})\b', output)
            if delays:
                delay_values = [int(d) for d in delays if int(d) < 800]
                if delay_values:
                    delay = min(delay_values)
                    if debug:
                        print(f"æœªåŒ¹é…å›ºå®šæ ¼å¼å»¶è¿Ÿï¼Œå–æœ€å°å»¶è¿Ÿ {delay}msï¼Œä¿ç•™èŠ‚ç‚¹")
                    return delay
            # æ— æ•ˆå»¶è¿Ÿå€¼åˆ¤æ–­
            if re.search(r'\b(0\s*ms|1\s*ms|NA)\b', output, re.I):
                if debug:
                    print("æ£€æµ‹åˆ°æ— æ•ˆå»¶è¿Ÿ(0ms/1ms/NA)ï¼Œä¸¢å¼ƒèŠ‚ç‚¹")
                return None
        if debug:
            print(f"æ‰€æœ‰æµ‹é€ŸURLå‡æœªè·æœ‰æ•ˆå»¶è¿Ÿï¼Œä¸¢å¼ƒèŠ‚ç‚¹: {proxy['name']}")
        return None
    except subprocess.TimeoutExpired:
        if debug:
            print(f"æµ‹é€Ÿè¶…æ—¶ï¼Œä¸¢å¼ƒèŠ‚ç‚¹: {proxy['name']}")
    except Exception as e:
        if debug:
            print(f"æµ‹é€Ÿå¼‚å¸¸ {e}ï¼Œä¸¢å¼ƒèŠ‚ç‚¹: {proxy['name']}")
    finally:
        try:
            import shutil
            shutil.rmtree(temp_dir)
        except Exception:
            pass
    return None
def batch_test_proxies_clash(clash_path, proxies, max_workers=MAX_TEST_WORKERS, debug=False, test_urls=None): # test_urls now required
    """
    ä½¿ç”¨ Clash æ ¸å¿ƒæ‰¹é‡æµ‹é€Ÿçš„è¾…åŠ©å‡½æ•°ï¼Œå¹¶å‘æ‰§è¡Œã€‚
    è¿”å›æµ‹é€Ÿå®Œæˆåå¸¦æœ‰ clash_delay å­—æ®µçš„åˆ—è¡¨ã€‚
    """
    if test_urls is None: # é˜²å¾¡æ€§æ£€æŸ¥
        print("â—ï¸è­¦å‘Š: batch_test_proxies_clash æœªæ”¶åˆ° test_urlsï¼Œå°†è‡ªåŠ¨è·å–ã€‚")
        test_urls = get_test_urls()
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_proxy = {
            executor.submit(clash_test_proxy, clash_path, proxy, test_urls, debug): proxy # test_urls passed
            for proxy in proxies
        }
        for future in as_completed(future_to_proxy):
            proxy = future_to_proxy[future]
            try:
                delay = future.result()
                if delay is not None:
                    pcopy = proxy.copy()
                    pcopy['clash_delay'] = delay
                    results.append(pcopy)
                    if debug:
                        print(f"CLASH PASS: {delay}ms â†’ {pcopy.get('name', '')[:40]}")
                else:
                    if debug:
                        print(f"CLASH FAIL â†’ {proxy.get('name', '')[:40]}")
            except Exception as e:
                if debug:
                    print(f"CLASH EXCEPTION: {proxy.get('name', '')[:40]} â†’ {e}")
    return results
    
def save_intermediate_results(proxies: list, filename: str):
    """
    å°†ä¸­é—´æµ‹é€Ÿç»“æœä¿å­˜åˆ°æŒ‡å®šçš„ YAML æ–‡ä»¶ä¸­ã€‚
    
    å‚æ•°:
        proxies (list): è¦ä¿å­˜çš„ä»£ç†èŠ‚ç‚¹åˆ—è¡¨ã€‚
        filename (str): è¾“å‡ºçš„æ–‡ä»¶å (ä¾‹å¦‚ 'TCP.yaml')ã€‚
    """
    if not proxies:
        print(f"â© ä¸­é—´ç»“æœ {filename} ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜ã€‚")
        return

    # ä»ä¸»è¾“å‡ºæ–‡ä»¶å˜é‡ä¸­è·å–ç›®å½•è·¯å¾„
    output_dir = os.path.dirname(OUTPUT_FILE)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, filename)
    else:
        # å¦‚æœä¸»è¾“å‡ºæ–‡ä»¶æ²¡æœ‰ç›®å½•ï¼Œåˆ™ä¿å­˜åœ¨å½“å‰æ–‡ä»¶å¤¹
        filepath = filename

    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ä¸­é—´ç»“æœåˆ° {filepath} ({len(proxies)} ä¸ªèŠ‚ç‚¹)...")
    try:
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŒ…å« 'proxies' é”®çš„å­—å…¸
        output_data = {'proxies': proxies}
        with open(filepath, 'w', encoding='utf-8') as f:
            # ä½¿ç”¨ sort_keys=False ä¿æŒèŠ‚ç‚¹åŸå§‹é¡ºåº
            yaml.dump(output_data, f, allow_unicode=True, sort_keys=False, indent=2)
        print(f"âœ… ä¸­é—´ç»“æœ {filepath} ä¿å­˜æˆåŠŸã€‚")
    except Exception as e:
        print(f"âŒ ä¿å­˜ä¸­é—´ç»“æœ {filepath} å¤±è´¥: {e}")




# ä¸»å‡½æ•°   

async def main():
    print("=" * 60)
    print("Telegram.Node_Clash-Speedtestæµ‹è¯•ç‰ˆ V2.0")
    print(datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)
    # === æ˜¾ç¤ºç½‘ç»œæ§åˆ¶é…ç½® ===
    print("ğŸŒ ç½‘ç»œæ§åˆ¶é…ç½®:")
    print(f"  - æŠ“å–é˜¶æ®µ Warp: {WARP_FOR_SCRAPING}")
    print(f"  - TCPæµ‹é€Ÿ Warp: {WARP_FOR_TCP}")
    print(f"  - Speedtestæµ‹é€Ÿ Warp: {WARP_FOR_SPEEDTEST}")
    print(f"  - æœ€ç»ˆé˜¶æ®µ Warp: {WARP_FOR_FINAL}")
    print("-" * 40)
    # åªåœ¨GitHub Actionsä¸­å¯ç”¨ç½‘ç»œæ§åˆ¶
    if os.getenv('GITHUB_ACTIONS') == 'true':
        print("ğŸ—ï¸ GitHub Actionsç¯å¢ƒæ£€æµ‹åˆ°ï¼Œå¯ç”¨ç½‘ç»œæ§åˆ¶")
        # åˆå§‹ç½‘ç»œçŠ¶æ€æ£€æŸ¥
        simplified_network_check()
    else:
        print("ğŸ’» æœ¬åœ°ç¯å¢ƒï¼Œè·³è¿‡ç½‘ç»œæ§åˆ¶")
    # åˆå§‹åŒ–ç½‘ç»œçŠ¶æ€ï¼Œé¢„å¤„ç†æ­£åˆ™è¡¨è¾¾å¼è§„åˆ™
    preprocess_regex_rules()
    print("[1/5] åŠ è½½åŸæœ‰èŠ‚ç‚¹å’ŒæŠ“å–çŠ¶æ€")
    # load_existing_proxies_and_state ä»ç„¶è¿”å› last_file_update_timeï¼Œ
    # ä½†æ­¤å¤„ä»…ç”¨äºåç»­çš„ Git æäº¤åˆ¤æ–­é€»è¾‘ï¼Œä¸å†å½±å“ Telegram æ¶ˆæ¯æŠ“å–èŒƒå›´ã€‚
    existing_proxies, last_message_ids, last_file_update_time = load_existing_proxies_and_state()
    print(f"å·²æœ‰èŠ‚ç‚¹æ•°: {len(existing_proxies)}")
    
    # === é˜¶æ®µ1ï¼šTelegramæŠ“å–ï¼ˆæ ¹æ®é…ç½®ä½¿ç”¨ç½‘ç»œï¼‰===
    print("[2/5] æŠ“å– Telegram æ–°è®¢é˜…é“¾æ¥")
    if os.getenv('GITHUB_ACTIONS') == 'true':
        ensure_network_for_stage('scraping', require_warp=WARP_FOR_SCRAPING)
    
    # scrape_telegram_links å‡½æ•°ç°åœ¨ä¸å†æ¥æ”¶ start_time å‚æ•°ï¼Œå…¶å†…éƒ¨é€»è¾‘ä¼šè‡ªè¡Œè®¡ç®—æŠ“å–èŒƒå›´
    urls, last_message_ids = await scrape_telegram_links(last_message_ids)
    
    # === é˜¶æ®µ2ï¼šä¸‹è½½è§£æè®¢é˜…é“¾æ¥ï¼ˆä¿æŒå½“å‰ç½‘ç»œï¼‰===
    new_proxies = []
    if urls:
        print(f"æŠ“å–åˆ° {len(urls)} ä¸ªè®¢é˜…é“¾æ¥ï¼Œå¼€å§‹ä¸‹è½½è§£æ...")
        for i, url in enumerate(urls, 1):
            print(f"è§£æè¿›åº¦: {i}/{len(urls)} - {url[:70]}...")
            proxies = download_and_parse(url)
            if proxies:
                new_proxies.extend(proxies)
                print(f"  æˆåŠŸè§£æ {len(proxies)} ä¸ªèŠ‚ç‚¹")
    else:
        print("æœªæŠ“å–åˆ°æœ‰æ•ˆè®¢é˜…é“¾æ¥ï¼Œè·³è¿‡è§£æé˜¶æ®µã€‚")
    print(f"æ–°å¢èŠ‚ç‚¹æ•°: {len(new_proxies)}")
    all_proxies_map = {
        get_proxy_key(p): p for p in existing_proxies if is_valid_proxy(p)
    }
    added_count = 0
    for p in new_proxies:
        key = get_proxy_key(p)
        if key not in all_proxies_map:
            all_proxies_map[key] = p
            added_count += 1
    print(f"åˆå¹¶å»é‡åæ€»èŠ‚ç‚¹æ•°: {len(all_proxies_map)}ï¼Œæ–°å¢æœ‰æ•ˆèŠ‚ç‚¹: {added_count}")
    all_nodes = list(all_proxies_map.values())
    if not all_nodes:
        sys.exit("âŒ æ— ä»»ä½•èŠ‚ç‚¹å¯ç”¨ï¼Œç¨‹åºé€€å‡º")
        
    # === é˜¶æ®µ3ï¼šæµ‹é€Ÿå‡†å¤‡ï¼ˆæ ¹æ®æ¨¡å¼é€‰æ‹©ç½‘ç»œå’Œæµ‹é€Ÿç­–ç•¥ï¼‰===
    print(f"[3/5] å¼€å§‹èŠ‚ç‚¹æµ‹é€Ÿ")
    # å®šä¹‰æµ‹é€Ÿå·¥å…·è·¯å¾„
    speedtest_path = './xcspeedtest'     # xcspeedtestç¨‹åºè·¯å¾„
    clash_path = './clash_core/clash'    # clash-speedtestæ ¸å¿ƒè·¯å¾„
    
    # ä½¿ç”¨æœ€æ–°ç‰ˆå˜é‡ï¼Œä»…ä½¿ç”¨æ–°å˜é‡ï¼Œä¸å…¼å®¹æ—§å˜é‡
    DETAILED_SPEEDTEST_MODE = os.getenv('DETAILED_SPEEDTEST_MODE', '').strip().lower()
    if not DETAILED_SPEEDTEST_MODE:
        print("â—ï¸é”™è¯¯: æœªè®¾ç½®ç¯å¢ƒå˜é‡ DETAILED_SPEEDTEST_MODEï¼Œç¨‹åºé€€å‡ºã€‚")
        sys.exit(1)
        
    mode = DETAILED_SPEEDTEST_MODE
    print(f"ä½¿ç”¨æµ‹é€Ÿæ¨¡å¼: {mode}")
    
    final_tested_nodes = all_nodes.copy()
    # Placeholders for intermediate results
    tcp_passed = []
    clash_passed = []
    
    # æ ¹æ®ä¸åŒçš„æµ‹é€Ÿæ¨¡å¼ï¼Œåœ¨å„è‡ªçš„é€»è¾‘å—å†…è·å–æµ‹é€Ÿåœ°å€
    if mode == 'tcp_clash_xc':
        print("ã€æ¨¡å¼ã€‘TCP ç²—ç­› â†’ Clash ç²¾æµ‹ â†’ Speedtest ç²¾æµ‹")
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
        tcp_passed = batch_tcp_test(all_nodes)
        print(f"ğŸ†— TCP ç²—ç­›å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(tcp_passed)}")
        ### æ–°å¢ï¼šä¿å­˜TCPæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(tcp_passed, 'TCP.yaml')
        
        if not tcp_passed:
            print("TCPå…¨éƒ¨ä¸é€šï¼Œé™çº§ä½¿ç”¨ Clash + Speedtest æµ‹é€Ÿ")
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
            
            clash_test_urls = get_test_urls()
            print(f"Clashæµ‹é€Ÿä½¿ç”¨åœ°å€: {clash_test_urls}")
            clash_passed = batch_test_proxies_clash(clash_path, all_nodes, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=clash_test_urls)
            print(f"ğŸ†— Clash ç²¾æµ‹å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(clash_passed)}")
            ### æ–°å¢ï¼šä¿å­˜Clashæµ‹é€Ÿç»“æœ ###
            save_intermediate_results(clash_passed, 'clash.yaml')
            
            if clash_passed:
                speedtest_urls = get_test_urls()
                print(f"Speedtestæµ‹é€Ÿä½¿ç”¨åœ°å€: {speedtest_urls}")
                final_tested_nodes = batch_test_proxies_speedtest(speedtest_path, clash_passed, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=speedtest_urls)
                ### æ–°å¢ï¼šä¿å­˜Speedtestæµ‹é€Ÿç»“æœ ###
                save_intermediate_results(final_tested_nodes, 'speedtest.yaml')
            else:
                final_tested_nodes = []
        else:
            print("ğŸ”” å¯¹TCPé€šè¿‡èŠ‚ç‚¹è¿›è¡Œ Clash æµ‹é€Ÿ")
            if os.getenv('GITHUB_ACTIONS') == 'true':
                ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
                
            clash_test_urls = get_test_urls()
            print(f"Clashæµ‹é€Ÿä½¿ç”¨åœ°å€: {clash_test_urls}")
            clash_passed = batch_test_proxies_clash(clash_path, tcp_passed, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=clash_test_urls)
            print(f"ğŸ†— Clash ç²¾æµ‹å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(clash_passed)}")
            ### æ–°å¢ï¼šä¿å­˜Clashæµ‹é€Ÿç»“æœ ###
            save_intermediate_results(clash_passed, 'clash.yaml')
            
            if clash_passed:
                print("ğŸ”” å¯¹ Clash ç­›é€‰èŠ‚ç‚¹è¿›è¡Œ Speedtest ç²¾æµ‹")
                speedtest_urls = get_test_urls()
                print(f"Speedtestæµ‹é€Ÿä½¿ç”¨åœ°å€: {speedtest_urls}")
                final_tested_nodes = batch_test_proxies_speedtest(speedtest_path, clash_passed, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=speedtest_urls)
                ### æ–°å¢ï¼šä¿å­˜Speedtestæµ‹é€Ÿç»“æœ ###
                save_intermediate_results(final_tested_nodes, 'speedtest.yaml')
            else:
                final_tested_nodes = []

    elif mode == 'tcp_clash':
        print("ã€æ¨¡å¼ã€‘TCP ç²—ç­› â†’ Clash ç²¾æµ‹")
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
        tcp_passed = batch_tcp_test(all_nodes)
        print(f"ğŸ†— TCP ç²—ç­›å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(tcp_passed)}")
        ### æ–°å¢ï¼šä¿å­˜TCPæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(tcp_passed, 'TCP.yaml')
        
        nodes_for_clash_test = tcp_passed if tcp_passed else all_nodes
        if not tcp_passed:
             print("TCPå…¨éƒ¨ä¸é€šï¼Œé™çº§å¯¹æ‰€æœ‰èŠ‚ç‚¹ä½¿ç”¨ Clash æµ‹é€Ÿ")
             
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
        
        clash_test_urls = get_test_urls()
        print(f"Clashæµ‹é€Ÿä½¿ç”¨åœ°å€: {clash_test_urls}")
        final_tested_nodes = batch_test_proxies_clash(clash_path, nodes_for_clash_test, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=clash_test_urls)
        print(f"ğŸ†— Clash ç²¾æµ‹å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(final_tested_nodes)}")
        ### æ–°å¢ï¼šä¿å­˜Clashæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(final_tested_nodes, 'clash.yaml')

    elif mode == 'tcp_xc':
        print("ã€æ¨¡å¼ã€‘TCP ç²—ç­› â†’ Speedtest ç²¾æµ‹")
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
        tcp_passed = batch_tcp_test(all_nodes)
        print(f"ğŸ†— TCP ç²—ç­›å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(tcp_passed)}")
        ### æ–°å¢ï¼šä¿å­˜TCPæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(tcp_passed, 'TCP.yaml')
        
        nodes_for_speedtest = tcp_passed if tcp_passed else all_nodes
        if not tcp_passed:
             print("TCPå…¨éƒ¨ä¸é€šï¼Œé™çº§å¯¹æ‰€æœ‰èŠ‚ç‚¹ä½¿ç”¨ Speedtest æµ‹é€Ÿ")
        
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
            
        speedtest_urls = get_test_urls()
        print(f"Speedtestæµ‹é€Ÿä½¿ç”¨åœ°å€: {speedtest_urls}")
        final_tested_nodes = batch_test_proxies_speedtest(speedtest_path, nodes_for_speedtest, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=speedtest_urls)
        print(f"ğŸ†— Speedtest ç²¾æµ‹å®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(final_tested_nodes)}")
        ### æ–°å¢ï¼šä¿å­˜Speedtestæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(final_tested_nodes, 'speedtest.yaml')

    elif mode == 'tcp_only':
        print("ã€æ¨¡å¼ã€‘çº¯ TCP æµ‹é€Ÿ")
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('tcp', require_warp=WARP_FOR_TCP)
        final_tested_nodes = batch_tcp_test(all_nodes)
        print(f"ğŸ†— TCP æµ‹é€Ÿå®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(final_tested_nodes)}")
        ### æ–°å¢ï¼šä¿å­˜TCPæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(final_tested_nodes, 'TCP.yaml')

    elif mode == 'clash_only':
        print("ã€æ¨¡å¼ã€‘çº¯ Clash æµ‹é€Ÿ")
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
            
        clash_test_urls = get_test_urls()
        print(f"Clashæµ‹é€Ÿä½¿ç”¨åœ°å€: {clash_test_urls}")
        final_tested_nodes = batch_test_proxies_clash(clash_path, all_nodes, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=clash_test_urls)
        print(f"ğŸ†— Clash æµ‹é€Ÿå®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(final_tested_nodes)}")
        ### æ–°å¢ï¼šä¿å­˜Clashæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(final_tested_nodes, 'Clash.yaml')

    elif mode == 'xcspeedtest_only':
        print("ã€æ¨¡å¼ã€‘çº¯ Speedtest æµ‹é€Ÿ")
        if os.getenv('GITHUB_ACTIONS') == 'true':
            ensure_network_for_stage('speedtest', require_warp=WARP_FOR_SPEEDTEST)
            
        speedtest_urls = get_test_urls()
        print(f"Speedtestæµ‹é€Ÿä½¿ç”¨åœ°å€: {speedtest_urls}")
        final_tested_nodes = batch_test_proxies_speedtest(speedtest_path, all_nodes, max_workers=MAX_TEST_WORKERS, debug=ENABLE_SPEEDTEST_LOG, test_urls=speedtest_urls)
        print(f"ğŸ†— Speedtest æµ‹é€Ÿå®Œæˆï¼Œé€šè¿‡èŠ‚ç‚¹æ•°: ğŸ›©ï¸ {len(final_tested_nodes)}")
        ### æ–°å¢ï¼šä¿å­˜Speedtestæµ‹é€Ÿç»“æœ ###
        save_intermediate_results(final_tested_nodes, 'Speedtest.yaml')
        
    else:
        print(f"â—ï¸ æœªçŸ¥æµ‹é€Ÿæ¨¡å¼ '{mode}', ç¨‹åºé€€å‡ºã€‚")
        sys.exit(1)
        
    # åç»­é€»è¾‘ä¿æŒä¸å˜...
    # æµ‹é€Ÿå®Œæˆï¼Œæ£€æµ‹æœ‰æ•ˆèŠ‚ç‚¹æ•°
    success_count = len(final_tested_nodes)
    print(f"ğŸ†— æµ‹é€Ÿå®Œæˆï¼Œæœ€ç»ˆå­˜æ´»ä¼˜è´¨èŠ‚ç‚¹æ•°é‡: ğŸ›©ï¸ {success_count}")
    # ä¿åº•ç­–ç•¥ - ä½äºé˜ˆå€¼æ—¶å¼ºåˆ¶ä¿ç•™éƒ¨åˆ†çƒ­é—¨åœ°åŒºèŠ‚ç‚¹ï¼ˆä½ çš„åŸä¿åº•é€»è¾‘ï¼‰
    if success_count < 50:
        print(f"æµ‹é€Ÿç»“æœè¿‡å°‘ï¼ˆ{success_count}ï¼‰ï¼Œå¯åŠ¨è¶…çº§ä¿åº•ç­–ç•¥ï¼Œä¿ç•™çƒ­é—¨åœ°åŒºèŠ‚ç‚¹")
        # ä¿åº•ç­–ç•¥å®ç°ï¼ˆåŒä½ åŸè„šæœ¬ï¼‰
    # è¿‡æ»¤æ— æ•ˆèŠ‚ç‚¹ï¼Œä¿æŒè¶…çº§ä¸¥æ ¼æ£€æµ‹
    final_tested_nodes = [p for p in final_tested_nodes if is_valid_proxy(p)]
    if not final_tested_nodes:
        sys.exit("âŒ æµ‹é€Ÿåæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")
    # === é˜¶æ®µ4ï¼šåˆ‡æ¢å› GitHub ç½‘ç»œè¿›è¡Œæœ€ç»ˆå¤„ç† ===
    print("[4/5] åˆ‡æ¢å›GitHubç½‘ç»œè¿›è¡Œæœ€ç»ˆå¤„ç†")
    if os.getenv('GITHUB_ACTIONS') == 'true':
        ensure_network_for_stage('final', require_warp=WARP_FOR_FINAL)
    # èŠ‚ç‚¹è§„èŒƒåŒ–åç§°
    normalized_proxies = normalize_proxy_names(final_tested_nodes)
    # é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼ˆæœ€å¤š400ä¸ªåŠåˆ†åŒºé™åˆ¶ï¼‰
    final_proxies = limit_proxy_counts(normalized_proxies, max_total=400)
    if not final_proxies:
        sys.exit("âŒ èŠ‚ç‚¹é‡å‘½åå’Œé™é‡åæ— æœ‰æ•ˆèŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")
    # === è®¡ç®—è´¨é‡è¯„åˆ†å¹¶æ’åº ===
    print("[4.5/5] è®¡ç®—èŠ‚ç‚¹è´¨é‡è¯„åˆ†")
    final_proxies = sort_proxies_by_quality(final_proxies)
    # === åç§°ä¸­æ·»åŠ è´¨é‡æ ‡ç­¾ ===
    final_proxies = add_quality_to_name(final_proxies)
    # === å¸¦å®½äºŒæ¬¡ç­›é€‰ ===
    final_proxies = filter_by_bandwidth(
        final_proxies, 
        min_mb=MIN_BANDWIDTH_MB, 
        enable=ENABLE_BANDWIDTH_FILTER
    )
    # === ç»Ÿè®¡è´¨é‡åˆ†å¸ƒ ===
    quality_stats = {'ğŸ”¥æå“': 0, 'â­ä¼˜è´¨': 0, 'âœ…è‰¯å¥½': 0, 'âš¡å¯ç”¨': 0}
    for proxy in final_proxies:
        tag = proxy.get('quality_tag', 'âš¡å¯ç”¨')
        if tag in quality_stats:
            quality_stats[tag] += 1
    print(f"  è´¨é‡åˆ†å¸ƒ: {quality_stats}")
    if final_proxies:
        avg_score = sum(p.get('quality_score', 0) for p in final_proxies) / len(final_proxies)
        print(f"  å¹³å‡è´¨é‡åˆ†: {avg_score:.1f}/100")
    else:
        print("  è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹")
        sys.exit("âŒ æ²¡æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ï¼Œç¨‹åºé€€å‡º")
    # é‡æ–°æŒ‰è´¨é‡æ’åºï¼ˆå¯é€‰ï¼Œä¿è¯è´¨é‡åˆ†æœ€é«˜æ’å‰ï¼‰
    final_proxies = sorted(final_proxies, key=lambda p: -p.get('quality_score', 0))
    # === é˜¶æ®µ5ï¼šç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶ ===
    print("[5/5] ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶")
    total_count = len(final_proxies)
    update_time = datetime.now(BJ_TZ).strftime("%Y-%m-%d %H:%M:%S")
    avg_quality = sum(p.get('quality_score', 0) for p in final_proxies) / total_count if total_count > 0 else 0
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    try:
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write("# ==================================================\n\n") # æ·»åŠ ç©ºè¡Œ
            f.write("#  TG å…è´¹èŠ‚ç‚¹ Â· è‡ªåŠ¨æµ‹é€Ÿç²¾é€‰è®¢é˜…ï¼ˆClash æ ¼å¼ï¼‰\n")
            f.write("# ==================================================\n\n") # æ·»åŠ ç©ºè¡Œ
            f.write(f"# æ›´æ–°æ—¶é—´   : {update_time} (åŒ—äº¬æ—¶é—´)\n")
            f.write(f"# èŠ‚ç‚¹æ€»æ•°   : {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹\n")
            f.write(f"# å¹³å‡è´¨é‡åˆ† : {avg_quality:.1f}/100\n")
            quality_stats_str = f"ğŸ”¥æå“: {quality_stats['ğŸ”¥æå“']}, â­ä¼˜è´¨: {quality_stats['â­ä¼˜è´¨']}, âœ…è‰¯å¥½: {quality_stats['âœ…è‰¯å¥½']}, âš¡å¯ç”¨: {quality_stats['âš¡å¯ç”¨']}"
            f.write(f"# è´¨é‡åˆ†å¸ƒ   : {quality_stats_str}\n")
            f.write(f"# å¸¦å®½ç­›é€‰   : â‰¥ {MIN_BANDWIDTH_MB}MB/s\n")
            f.write(f"# æµ‹é€Ÿæ¨¡å¼   : {mode}\n")
            f.write(f"# ç½‘ç»œé…ç½®   : TCP_Warp={WARP_FOR_TCP}, Speedtest_Warp={WARP_FOR_SPEEDTEST}\n")
            f.write("# æ’åºè§„åˆ™   : è´¨é‡è¯„åˆ† â†’ å»¶è¿Ÿ â†’ åœ°åŒºä¼˜å…ˆçº§\n")
            f.write("# æ„å»ºæ–¹å¼   : GitHub Actions å…¨è‡ªåŠ¨\n")
            f.write("# ==================================================\n\n") # æ·»åŠ ç©ºè¡Œ
            final_config = {
                'proxies': final_proxies,
                'last_message_ids': last_message_ids,
                'update_time': update_time,
                'total_nodes': total_count,
                'average_quality': round(avg_quality, 1),
                'quality_stats': quality_stats_str,
                'bandwidth_filter': {
                    'enabled': ENABLE_BANDWIDTH_FILTER,
                    'min_mb': MIN_BANDWIDTH_MB
                },
                'speedtest_config': {
                    'mode': mode,
                    'warp_for_tcp': WARP_FOR_TCP,
                    'warp_for_speedtest': WARP_FOR_SPEEDTEST,
                    'warp_for_scraping': WARP_FOR_SCRAPING
                },
                'note': 'ç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆï¼Œå·²æŒ‰è´¨é‡è¯„åˆ†æ’åº'
            }
            yaml.dump(final_config, f, allow_unicode=True, sort_keys=False, indent=2, width=4096, default_flow_style=False)
    except Exception as e:
        print(f"âŒ å†™å‡ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)
    # ç»“æœå±•ç¤º
    print(f"âœ… é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³ {OUTPUT_FILE}")
    print(f"ğŸ“Š æœ¬æ¬¡å¤„ç†å®Œæˆ:")
    print(f"   èŠ‚ç‚¹æ€»æ•°   : {total_count} ä¸ªä¼˜è´¨èŠ‚ç‚¹")
    print(f"   å¹³å‡è´¨é‡åˆ† : {avg_quality:.1f}/100")
    print(f"   è´¨é‡åˆ†å¸ƒ   : {quality_stats_str}")
    print(f"   å¸¦å®½ç­›é€‰   : â‰¥ {MIN_BANDWIDTH_MB}MB/s")
    print(f"   æµ‹é€Ÿæ¨¡å¼   : {mode}")
    print(f"   æ›´æ–°æ—¶é—´   : {update_time}")
    print("=" * 60)
    print("ğŸ‰ å…¨éƒ¨ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
    # === æœ€ç»ˆæ¸…ç†ï¼Œç¡®ä¿åˆ‡æ¢å›GitHubç½‘ç»œ ===
    if os.getenv('GITHUB_ACTIONS') == 'true' and not WARP_FOR_FINAL:
        print("ğŸ§¹ æœ€ç»ˆæ¸…ç†ï¼šç¡®ä¿ä½¿ç”¨åŸå§‹GitHubç½‘ç»œ")
        ensure_network_for_stage('cleanup', require_warp=False)   
        


if __name__ == "__main__":
    asyncio.run(main())  # è°ƒç”¨å¼‚æ­¥ä¸»å‡½æ•°

