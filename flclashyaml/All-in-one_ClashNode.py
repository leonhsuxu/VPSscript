"""
å›ºå®šé“¾æ¥è·å–èŠ‚ç‚¹è„šæœ¬ V1
-----------------------------------------
åŠŸèƒ½è¯´æ˜ï¼š
æœ¬è„šæœ¬ç”¨äºä» URL.TXT æ–‡ä»¶ä¸­è¯»å–å¤šä¸ªä»¥â€œ#â€å¼€å¤´åˆ’åˆ†çš„è®¢é˜…åŒºå—ï¼Œæ¯ä¸ªåŒºå—åŒ…å«è‹¥å¹²è®¢é˜…é“¾æ¥ã€‚
è„šæœ¬ä¼šï¼š
1. è‡ªåŠ¨è¯†åˆ«å¹¶æ‹†åˆ†å¤šä¸ªè®¢é˜…åŒºå—ï¼›
2. é’ˆå¯¹æ¯ä¸ªåŒºå—ï¼Œæå–æ‰€æœ‰ HTTP/HTTPS è®¢é˜…é“¾æ¥ï¼›
3. ä¾æ¬¡ä¸‹è½½è®¢é˜…å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨ wgetï¼Œå¤±è´¥åä½¿ç”¨ requestsï¼‰ï¼›
4. è‡ªåŠ¨è¯†åˆ« YAML ç›´æ¥è§£æï¼Œæˆ– Base64 è§£ç å¹¶æ”¯æŒå¤šåè®®èŠ‚ç‚¹è§£æï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰ï¼›
5. åˆå¹¶å»é‡æ‰€æœ‰èŠ‚ç‚¹ï¼ŒåŒæ—¶æ”¯æŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆé€šè¿‡çº¯ Python socketï¼‰ç­›é€‰å¯ç”¨èŠ‚ç‚¹ï¼›
6. æ™ºèƒ½ä¸ºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ ç¬¦åˆè§„åˆ™çš„åŒºåŸŸæ ‡è¯†å’Œå›½æ—— Emojiï¼Œå¹¶é‡å‘½åï¼›
7. æŒ‰åœ°åŒºä¼˜å…ˆçº§åŠæµ‹é€Ÿç»“æœæ’åºèŠ‚ç‚¹ï¼›
8. ä¸ºæ¯ä¸ªåŒºå—ç”Ÿæˆç‹¬ç«‹çš„ Clash é…ç½® YAML æ–‡ä»¶ï¼Œæ–‡ä»¶ä¿å­˜åœ¨ output_yaml ç›®å½•ä¸­ã€‚
ä½¿ç”¨è¯´æ˜ï¼š
- åœ¨ URL.TXT ä¸­æ·»åŠ è®¢é˜…ï¼Œä½¿ç”¨â€œ# åŒºå—åç§°:â€æ ¼å¼åˆ’åˆ†å¤šä¸ªåŒºå—ï¼Œæ¯å—ä¸‹æ–¹ä¸ºç›¸å…³è®¢é˜…é“¾æ¥åˆ—è¡¨
- è¿è¡Œè„šæœ¬ï¼Œå³å¯åœ¨ output_yaml ç›®å½•ä¸­å¾—åˆ°åˆ†å—ç”Ÿæˆçš„ YAML é…ç½®æ–‡ä»¶
"""
import os
import re
import yaml
import base64
import json
import socket
import shutil
import hashlib
import subprocess
import requests
import concurrent.futures
import time
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from urllib.parse import urlparse, parse_qs, unquote

# ========== åŸºç¡€é…ç½® ==========
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
URL_FILE = os.path.join(SCRIPT_DIR, "URL.TXT")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output_yaml")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ========== æµ‹é€Ÿé…ç½® ==========
ENABLE_SPEED_TEST = True
SOCKET_TIMEOUT = 10
MAX_TEST_WORKERS = 256

# ========== åŒºåŸŸæ˜ å°„ä¸è§„åˆ™ ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'ç¾å›½', 'å°æ¹¾', 'éŸ©å›½', 'å¾·å›½', 'è‹±å›½', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš']

CHINESE_COUNTRY_MAP = {
    'US': 'ç¾å›½', 'United States': 'ç¾å›½', 'USA': 'ç¾å›½',
    'JP': 'æ—¥æœ¬', 'Japan': 'æ—¥æœ¬',
    'HK': 'é¦™æ¸¯', 'Hong Kong': 'é¦™æ¸¯',
    'SG': 'æ–°åŠ å¡', 'Singapore': 'æ–°åŠ å¡',
    'TW': 'å°æ¹¾', 'Taiwan': 'å°æ¹¾',
    'KR': 'éŸ©å›½', 'Korea': 'éŸ©å›½', 'KOR': 'éŸ©å›½',
    'DE': 'å¾·å›½', 'Germany': 'å¾·å›½',
    'GB': 'è‹±å›½', 'United Kingdom': 'è‹±å›½', 'UK': 'è‹±å›½',
    'CA': 'åŠ æ‹¿å¤§', 'Canada': 'åŠ æ‹¿å¤§',
    'AU': 'æ¾³å¤§åˆ©äºš', 'Australia': 'æ¾³å¤§åˆ©äºš',
}
COUNTRY_NAME_TO_CODE_MAP = {
    "é˜¿æ ¹å»·": "AR", "æ¾³å¤§åˆ©äºš": "AU", "å¥¥åœ°åˆ©": "AT", "å­ŸåŠ æ‹‰å›½": "BD", "æ¯”åˆ©æ—¶": "BE",
    "å·´è¥¿": "BR", "ä¿åŠ åˆ©äºš": "BG", "åŠ æ‹¿å¤§": "CA", "æ™ºåˆ©": "CL", "å“¥ä¼¦æ¯”äºš": "CO",
    "å…‹ç½—åœ°äºš": "HR", "æ·å…‹": "CZ", "ä¸¹éº¦": "DK", "åŸƒåŠ": "EG", "çˆ±æ²™å°¼äºš": "EE",
    "èŠ¬å…°": "FI", "æ³•å›½": "FR", "å¾·å›½": "DE", "å¸Œè…Š": "GR", "é¦™æ¸¯": "HK", "åŒˆç‰™åˆ©": "HU",
    "å†°å²›": "IS", "å°åº¦": "IN", "å°åº¦å°¼è¥¿äºš": "ID", "çˆ±å°”å…°": "IE", "ä»¥è‰²åˆ—": "IL",
    "æ„å¤§åˆ©": "IT", "æ—¥æœ¬": "JP", "å“ˆè¨å…‹æ–¯å¦": "KZ", "éŸ©å›½": "KR", "æ‹‰è„±ç»´äºš": "LV",
    "ç«‹é™¶å®›": "LT", "å¢æ£®å ¡": "LU", "æ¾³é—¨": "MO", "é©¬æ¥è¥¿äºš": "MY", "å¢¨è¥¿å“¥": "MX",
    "æ‘©å°”å¤šç“¦": "MD", "è·å…°": "NL", "æ–°è¥¿å…°": "NZ", "å°¼æ—¥åˆ©äºš": "NG", "æŒªå¨": "NO",
    "å·´åŸºæ–¯å¦": "PK", "è²å¾‹å®¾": "PH", "æ³¢å…°": "PL", "è‘¡è„ç‰™": "PT", "ç½—é©¬å°¼äºš": "RO",
    "ä¿„ç½—æ–¯": "RU", "æ²™ç‰¹é˜¿æ‹‰ä¼¯": "SA", "å¡å°”ç»´äºš": "RS", "æ–°åŠ å¡": "SG", "æ–¯æ´›ä¼å…‹": "SK",
    "æ–¯æ´›æ–‡å°¼äºš": "SI", "å—é": "ZA", "è¥¿ç­ç‰™": "ES", "ç‘å…¸": "SE", "ç‘å£«": "CH",
    "å°æ¹¾": "TW", "æ³°å›½": "TH", "åœŸè€³å…¶": "TR", "ä¹Œå…‹å…°": "UA", "é˜¿è”é…‹": "AE",
    "è‹±å›½": "GB", "ç¾å›½": "US", "è¶Šå—": "VN", "é˜¿æ›¼": "OM", "æŸ¬åŸ”å¯¨": "KH",
    "ç§˜é²": "PE", "é˜¿å¡æ‹œç–†": "AZ", "å·´æ—": "BH","ä¼Šæ‹‰å…‹": "IQ", "å°¼æ³Šå°”": "NP",
    "å¡å¡”å°”": "QA", "ç§‘å¨ç‰¹": "KW", "é©¬è€³ä»–": "MT", "å¡æµ¦è·¯æ–¯": "CY", "æ ¼é²å‰äºš": "GE",
    "é˜¿å°”å·´å°¼äºš": "AL", "æ³¢é»‘": "BA", "åŒ—é©¬å…¶é¡¿": "MK", "é»å·´å«©": "LB", "çº¦æ—¦": "JO",
    "ç¼…ç”¸": "MM", "è€æŒ": "LA", "æ–¯é‡Œå…°å¡": "LK", "è‚¯å°¼äºš": "KE", "æ‘©æ´›å“¥": "MA",
    "çªå°¼æ–¯": "TN", "å„ç“œå¤šå°”": "EC", "ä¹Œæ‹‰åœ­": "UY", "å“¥æ–¯è¾¾é»åŠ ": "CR", "å·´æ‹¿é©¬": "PA",
}
JUNK_PATTERNS = re.compile(
    r"(?:ä¸“çº¿|IPLC|IEPL|BGP|ä½“éªŒ|ä¸‘å›¢|å®˜ç½‘|å€ç‡|x\d[\.\d]*|Rate|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)"
    r"|(?:(?:[\u2460-\u2473\u2776-\u277F\u2780-\u2789]|å…è²»|å›å®¶).*?(?=,|$))",
    re.IGNORECASE
)
CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong Kong|HKBN|HGC|PCCW|WTT'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|JP|Japan'},
    'æ–°åŠ å¡': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|å¡|æ–°åŠ å¡|SG|Singapore'},
    'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥'},
    'å°æ¹¾': {'code': 'TW', 'pattern': r'å°æ¹¾|å°æ¹¾|å°|æ–°åŒ—|å½°åŒ–|TW|Taiwan'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|éŸ©|é¦–å°”|KR|Korea|KOR|éŸ“'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
    'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|è‹±|UK|GB|United Kingdom|England'},
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
}
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')

def preprocess_regex_rules():
    for region, rules in CUSTOM_REGEX_RULES.items():
        parts = rules['pattern'].split('|')
        sorted_parts = sorted(parts, key=len, reverse=True)
        escaped_parts = [re.escape(p) for p in sorted_parts]
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(escaped_parts)

preprocess_regex_rules()

def sanitize_filename(name: str) -> str:
    import re
    match = re.match(r"#\s*(.*?)\s*[:ï¼š]", name, re.IGNORECASE)
    if match:
        title = match.group(1)
    else:
        title = name.lstrip('#').strip()
        title = re.sub(r'[:ï¼š]+$', '', title).strip()
    title = re.sub(r'[\\/:*?"<>|\sï¼š]+', '_', title)
    title = title.strip('_')
    return title or 'default'

def get_country_flag_emoji(country_code):
    if not country_code or len(country_code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in country_code)

def safe_b64decode(data):
    data = data.encode() if isinstance(data, str) else data
    missing_padding = (-len(data)) % 4
    data += b'=' * missing_padding
    return base64.urlsafe_b64decode(data)

# ----- ä¸‹è½½ç›¸å…³ -----
def attempt_download_using_wget(url):
    print(f"  â¬‡ï¸ wget ä¸‹è½½: {url[:80]}")
    if not shutil.which("wget"):
        print("  âœ— æœªå®‰è£… wget")
        return None
    try:
        proc = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        )
        return proc.stdout if proc.stdout else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget å¤±è´¥: {e.stderr.strip()}")
        return None

def attempt_download_using_requests(url):
    print(f"  â¬‡ï¸ requests ä¸‹è½½: {url[:80]}")
    try:
        headers = {'User-Agent': 'Clash'}
        r = requests.get(url, headers=headers, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding or 'utf-8'
        return r.text
    except Exception as e:
        print(f"  âœ— requests å¤±è´¥: {e}")
        return None

def download_subscription(url):
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        return []
    proxies = parse_proxies_from_content(content)
    if proxies:
        return proxies
    if is_base64(content):
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        print("  - Base64 è§£ç æ— æ•ˆèŠ‚ç‚¹")
    else:
        print("  - å†…å®¹é Base64")
    return []

# ----- è§£æç›¸å…³ -----
def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        # å¯é€‰ï¼šåœ¨è¿™é‡Œæ‰“å°è§£ç å†…å®¹é¢„è§ˆï¼ˆæ³¨é‡Šæ‰é¿å…å¤ªé•¿ï¼‰
        # print(f"  - Base64 è§£ç å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰ï¼š\n{decoded[:500]}{'...' if len(decoded) > 500 else ''}")
        proxies = []
        success_count = 0
        failure_count = 0
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            if line.startswith('vmess://'):
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count += 1
            else:
                failure_count += 1
        print(f"  - Base64 è§£ç è§£æå®Œæˆï¼ŒæˆåŠŸè§£æèŠ‚ç‚¹æ•°ï¼š{success_count}ï¼Œå¤±è´¥æ•°ï¼š{failure_count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

# ----- åè®®è§£æå®ç° -----
def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception as e:
        print(f"  - vmess èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_vless_node(line):
    try:
        line = line.strip()
        parsed = urlparse(line)
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {
                'path': node['path'],
                'headers': {'Host': node['host']} if node['host'] else {}
            }
        return node
    except Exception as e:
        print(f"  - vless èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v

        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception as e:
        print(f"  - ssr èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {
                'name': name,
                'type': 'ss',
                'server': server,
                'port': port,
                'cipher': method,
                'password': password,
                'udp': True,
            }
            return node
        else:
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {
                'name': remark or f"ss_{server}",
                'type': 'ss',
                'server': server,
                'port': int(port),
                'cipher': method,
                'password': password,
                'udp': True,
            }
            return node
    except Exception as e:
        print(f"  - ss èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception as e:
        print(f"  - trojan èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception as e:
        print(f"  - hysteria èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception as e:
        print(f"  - hysteria2 èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

# ----- åˆå¹¶å»é‡ -----
def get_proxy_key(proxy):
    try:
        key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}|"
        if 'uuid' in proxy:
            key += proxy['uuid']
        elif 'password' in proxy:
            key += proxy['password']
        else:
            key += proxy.get('name', '')
        return hashlib.md5(key.encode('utf-8')).hexdigest()
    except:
        return None

def merge_and_deduplicate_proxies(proxies):
    unique = {}
    for proxy in proxies:
        if not isinstance(proxy, dict) or 'name' not in proxy:
            continue
        k = get_proxy_key(proxy)
        if k and k not in unique:
            unique[k] = proxy
    return list(unique.values())

# ----- é‡ç‚¹å‡½æ•°ï¼šé‡å‘½åæ’åº -----
def process_and_rename_proxies(proxies):
    country_counters = defaultdict(int)
    final_proxies = []
    all_region_names_for_stripping = set()
    for rules in CUSTOM_REGEX_RULES.values():
        all_region_names_for_stripping.update(rules['pattern'].split('|'))
    for k, v in CHINESE_COUNTRY_MAP.items():
        all_region_names_for_stripping.add(k)
        all_region_names_for_stripping.add(v)
    all_region_names_for_stripping.update(COUNTRY_NAME_TO_CODE_MAP.keys())
    sorted_region_names = sorted(list(all_region_names_for_stripping), key=len, reverse=True)
    master_region_pattern = re.compile('|'.join(map(re.escape, sorted_region_names)), re.IGNORECASE)
    country_code_pattern = re.compile(r'\b(' + '|'.join(re.escape(k) for k in CHINESE_COUNTRY_MAP.keys()) + r')\b', re.IGNORECASE)

    def replace_country_code(m):
        code = m.group(0)
        return CHINESE_COUNTRY_MAP.get(code.upper(), code)

    speed_pattern = re.compile(r'(\d+(?:\.\d+)?)\s*(M|K)?B/s', re.IGNORECASE)

    # æ–°å¢ï¼šåˆ é™¤æ‰€æœ‰å›½æ—— Emoji çš„å‡½æ•°
    def remove_all_flag_emojis(text):
        return FLAG_EMOJI_PATTERN.sub('', text).strip()

    # ç¬¬ä¸€æ­¥ï¼Œè¯†åˆ« region
    for p in proxies:
        original_name = p.get('name', '').strip()
        name_wo_flag = remove_all_flag_emojis(original_name)  # åˆ é™¤æ‰€æœ‰å›½æ——
        name_with_chinese = country_code_pattern.sub(replace_country_code, name_wo_flag)
        name_for_region_detect = JUNK_PATTERNS.sub('', name_with_chinese).strip()
        for eng, chn in CHINESE_COUNTRY_MAP.items():
            pattern = re.compile(r'\b' + re.escape(eng) + r'\b', re.IGNORECASE)
            name_for_region_detect = pattern.sub(chn, name_for_region_detect)
        p['region'] = None
        for region_name, rules in CUSTOM_REGEX_RULES.items():
            if re.search(rules['pattern'], name_for_region_detect, re.IGNORECASE):
                p['region'] = region_name
                break
        if p['region'] is None:
            matched_region = None
            for country_chn_name in COUNTRY_NAME_TO_CODE_MAP.keys():
                pattern = re.compile(r'\b' + re.escape(country_chn_name) + r'\b', re.IGNORECASE)
                if pattern.search(name_for_region_detect):
                    matched_region = country_chn_name
                    break
            p['region'] = matched_region if matched_region else (original_name if original_name else 'æœªçŸ¥')

    # ç¬¬äºŒæ­¥ï¼Œé‡å‘½åï¼Œæ ¼å¼ï¼šå›½æ——+åœ°åŒº-åºå·|ä¸‹è½½é€Ÿåº¦
    for proxy in proxies:
        original_name = proxy.get('name', '').strip()
        # åˆ é™¤æ‰€æœ‰å›½æ—— emoji
        name_wo_flag = remove_all_flag_emojis(original_name)

        region_name = proxy.get('region', 'æœªçŸ¥')
        region_code = COUNTRY_NAME_TO_CODE_MAP.get(region_name) or CUSTOM_REGEX_RULES.get(region_name, {}).get('code', '')
        flag_emoji = get_country_flag_emoji(region_code)

        name_with_chinese = country_code_pattern.sub(replace_country_code, name_wo_flag)

        # æŸ¥æ‰¾æ‰€æœ‰æµ‹é€Ÿæ–‡æœ¬ï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ª
        speed_text = ''
        speed_matches = speed_pattern.findall(name_with_chinese)
        if speed_matches:
            number, unit = speed_matches[0]
            unit = unit.upper() if unit else ''
            speed_text = f"{number}{unit}B/s"

        # åˆ é™¤æ‰€æœ‰æµ‹é€Ÿæ–‡æœ¬
        name_without_speed = speed_pattern.sub('', name_with_chinese).strip()

        country_counters[region_name] += 1
        seq_num = country_counters[region_name]

        new_name = f"{flag_emoji}{region_name}-{seq_num}"
        if speed_text:
            new_name += f"|{speed_text}"

        proxy['name'] = new_name
        final_proxies.append(proxy)

    return final_proxies

# ----- æµ‹é€Ÿ -----
def test_single_proxy_socket(proxy):
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(SOCKET_TIMEOUT)
        start = time.time()
        sock.connect((str(server), int(port)))
        end = time.time()
        proxy['delay'] = int((end - start) * 1000)
        return proxy
    except Exception:
        return None
    finally:
        if 'sock' in locals():
            sock.close()

def speed_test_proxies(proxies):
    print(f"å¼€å§‹æµ‹é€Ÿ: å…± {len(proxies)} ä¸ªèŠ‚ç‚¹")
    fast_proxies = []
    total = len(proxies)
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_TEST_WORKERS) as executor:
        futures = {executor.submit(test_single_proxy_socket, p): p for p in proxies}
        for i, f in enumerate(concurrent.futures.as_completed(futures), 1):
            result = f.result()
            if i % 100 == 0 or i == total:
                print(f"\ræµ‹é€Ÿè¿›åº¦: {i}/{total}", end='', flush=True)
            if result:
                fast_proxies.append(result)
    print()
    print(f"æµ‹é€Ÿå®Œæˆ: æœ‰æ•ˆèŠ‚ç‚¹ {len(fast_proxies)}")
    return fast_proxies

# ----- é…ç½®æ–‡ä»¶ç”Ÿæˆ -----
def generate_config(proxies):
    if not proxies:
        return None
    proxy_names = [p['name'] for p in proxies]
    clean_proxies = [{k: v for k, v in p.items() if k not in ['region', 'delay']} for p in proxies]
    return {
        'mixed-port': 7890,
        'allow-lan': True,
        'bind-address': '*',
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': clean_proxies,
        'proxy-groups': [
            {'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'type': 'select',
             'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + proxy_names},
            {'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'type': 'url-test', 'proxies': proxy_names,
             'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
            {'name': 'ğŸ”¯ æ•…éšœè½¬ç§»', 'type': 'fallback', 'proxies': proxy_names,
             'url': 'http://www.gstatic.com/generate_204', 'interval': 300}],
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

# ------------------ å¤šåŒºå—è¯»å–ä¸å¤„ç† ------------------
def parse_url_txt_to_blocks():
    if not os.path.exists(URL_FILE):
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {URL_FILE}")
        return []
    with open(URL_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    blocks = []
    current_block = {'title': None, 'lines': []}
    for line in lines:
        stripped = line.strip()
        if stripped.startswith('#'):
            if current_block['title']:
                blocks.append(current_block)
            current_block = {'title': stripped, 'lines': []}
        else:
            if stripped:
                current_block['lines'].append(stripped)
    if current_block['title']:
        blocks.append(current_block)
    return blocks

def extract_urls_from_lines(lines):
    url_pattern = re.compile(r'https?://[^\s]+', re.IGNORECASE)
    urls = []
    for line in lines:
        urls.extend(url_pattern.findall(line))
    return urls

def process_block_to_yaml(block):
    title = block['title']
    lines = block['lines']
    urls = extract_urls_from_lines(lines)
    if not urls:
        print(f"{title} åŒºå—æ— æœ‰æ•ˆè®¢é˜…ï¼Œè·³è¿‡ã€‚")
        return
    print(f"\nå¤„ç†åŒºå—ï¼š{title} | {len(urls)} ä¸ªè®¢é˜…é“¾æ¥")
    all_proxies = []
    for url in urls:
        all_proxies.extend(download_subscription(url))
    if not all_proxies:
        print(f"{title} è®¢é˜…ä¸‹è½½å¤±è´¥æˆ–æ— èŠ‚ç‚¹ï¼Œè·³è¿‡ã€‚")
        return
    unique_proxies = merge_and_deduplicate_proxies(all_proxies)
    if ENABLE_SPEED_TEST:
        tested_proxies = speed_test_proxies(unique_proxies)
        if not tested_proxies:
            print(f"{title} æµ‹é€Ÿæ— å¯ç”¨èŠ‚ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ã€‚")
            tested_proxies = unique_proxies
    else:
        tested_proxies = unique_proxies
    region_order = {r: i for i, r in enumerate(REGION_PRIORITY)}
    tested_proxies.sort(key=lambda p: (region_order.get(p.get('region', 'æœªçŸ¥'), 999), p.get('delay', 9999)))
    final_proxies = process_and_rename_proxies(tested_proxies)
    config = generate_config(final_proxies)
    if not config:
        print(f"{title} é…ç½®ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚")
        return
    filename = sanitize_filename(title) + ".yaml"
    filepath = os.path.join(OUTPUT_DIR, filename)
    with open(filepath, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2)
    print(f"{title} é…ç½®å·²ç”Ÿæˆï¼š{filepath}ï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(final_proxies)}")

def main():
    print("=" * 60)
    print("å›ºå®šé“¾æ¥è·å–èŠ‚ç‚¹è„šæœ¬ V1")
    print(f"æ—¶é—´: {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    blocks = parse_url_txt_to_blocks()
    if not blocks:
        print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆåŒºå—ï¼Œé€€å‡ºã€‚")
        return
    for block in blocks:
        process_block_to_yaml(block)
    print(f"\nå…¨éƒ¨åŒºå—å¤„ç†å®Œæˆï¼Œé…ç½®æ–‡ä»¶å­˜æ”¾äºï¼š{OUTPUT_DIR}")

if __name__ == "__main__":
    main()
