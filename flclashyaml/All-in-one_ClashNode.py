"""
å›ºå®šé“¾æ¥è·å–èŠ‚ç‚¹è„šæœ¬ V1
-----------------------------------------
åŠŸèƒ½è¯´æ˜ï¼š
æœ¬è„šæœ¬ç”¨äºä» URL.TXT æ–‡ä»¶ä¸­è¯»å–å¤šä¸ªä»¥â€œ#â€å¼€å¤´åˆ’åˆ†çš„è®¢é˜…åŒºå—ï¼Œæ¯ä¸ªåŒºå—åŒ…å«è‹¥å¹²è®¢é˜…é“¾æ¥ã€‚
è„šæœ¬ä¼šï¼š
1. è‡ªåŠ¨è¯†åˆ«å¹¶æ‹†åˆ†å¤šä¸ªè®¢é˜…åŒºå—ï¼›
2. é’ˆå¯¹æ¯ä¸ªåŒºå—ï¼Œæå–æ‰€æœ‰ HTTP/HTTPS è®¢é˜…é“¾æ¥ï¼›
3. ä¾æ¬¡ä¸‹è½½è®¢é˜…å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨ wgetï¼Œå¤±è´¥åä½¿ç”¨ requestsï¼‰ï¼›
4. è‡ªåŠ¨è¯†åˆ« YAML ç›´æ¥è§£æï¼Œæˆ– Base64 è§£ç å¹¶æ”¯æŒå¤šåè®®èŠ‚ç‚¹è§£æï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰ï¼›
5. åˆå¹¶å»é‡æ‰€æœ‰èŠ‚ç‚¹ï¼ŒåŒæ—¶æ”¯æŒèŠ‚ç‚¹æµ‹é€Ÿï¼ˆé€šè¿‡çº¯ Python socketï¼‰ç­›é€‰å¯ç”¨èŠ‚ç‚¹ï¼›
6. æ™ºèƒ½ä¸ºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ ç¬¦åˆè§„åˆ™çš„åŒºåŸŸæ ‡è¯†å’Œå›½æ—— Emojiï¼Œå¹¶é‡å‘½åï¼›
7. æŒ‰åœ°åŒºä¼˜å…ˆçº§åŠæµ‹é€Ÿç»“æœæ’åºèŠ‚ç‚¹ï¼›
8. ä¸ºæ¯ä¸ªåŒºå—ç”Ÿæˆç‹¬ç«‹çš„ Clash é…ç½® YAML æ–‡ä»¶ï¼Œæ–‡ä»¶ä¿å­˜åœ¨ output_yaml ç›®å½•ä¸­ã€‚
ä½¿ç”¨è¯´æ˜ï¼š
- åœ¨ URL.TXT ä¸­æ·»åŠ è®¢é˜…ï¼Œä½¿ç”¨â€œ# åŒºå—åç§°:â€æ ¼å¼åˆ’åˆ†å¤šä¸ªåŒºå—ï¼Œæ¯å—ä¸‹æ–¹ä¸ºç›¸å…³è®¢é˜…é“¾æ¥åˆ—è¡¨
- è¿è¡Œè„šæœ¬ï¼Œå³å¯åœ¨ output_yaml ç›®å½•ä¸­å¾—åˆ°åˆ†å—ç”Ÿæˆçš„ YAML é…ç½®æ–‡ä»¶
"""
import os
import re
import yaml
import base64
import json
import socket
import shutil
import hashlib
import subprocess
import requests
import concurrent.futures
import time
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from urllib.parse import urlparse, parse_qs, unquote

# ========== åŸºç¡€é…ç½® ==========
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__)) # è·å–å½“å‰è„šæœ¬æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•çš„ç»å¯¹è·¯å¾„
URL_FILE = os.path.join(SCRIPT_DIR, "URL.TXT") # æ„å»ºURLæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼Œè¯¥æ–‡ä»¶åº”ä½äºè„šæœ¬åŒç›®å½•ä¸‹
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output_yaml") # æ„å»ºè¾“å‡ºç›®å½•çš„å®Œæ•´è·¯å¾„ï¼Œç”¨äºå­˜æ”¾ç”Ÿæˆçš„YAMLæ–‡ä»¶
os.makedirs(OUTPUT_DIR, exist_ok=True) # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™

# ========== æµ‹é€Ÿé…ç½® ========== # ä»¥ä¸‹æ˜¯å…³äºé€Ÿåº¦æµ‹è¯•çš„é…ç½®é¡¹
ENABLE_SPEED_TEST = True # æ˜¯å¦å¯ç”¨é€Ÿåº¦æµ‹è¯•ï¼Œè®¾ç½®ä¸ºTrueè¡¨ç¤ºå¯ç”¨
SOCKET_TIMEOUT = 10 # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_TEST_WORKERS = 256 # æœ€å¤§æµ‹è¯•å·¥ä½œçº¿ç¨‹æ•°ï¼Œè¡¨ç¤ºåŒæ—¶è¿›è¡Œé€Ÿåº¦æµ‹è¯•çš„æœ€å¤§å¹¶å‘è¿æ¥æ•°

# ========== åŒºåŸŸæ˜ å°„ä¸è§„åˆ™ï¼ˆåˆå¹¶ç‰ˆï¼‰ ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'æ—¥æœ¬', 'æ–°åŠ å¡', 'ç¾å›½', 'å°æ¹¾', 'éŸ©å›½', 'å¾·å›½', 'è‹±å›½', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš']

CHINESE_COUNTRY_MAP = {
    'US': 'ç¾å›½', 'United States': 'ç¾å›½', 'USA': 'ç¾å›½', 'America': 'ç¾å›½',
    'New York': 'ç¾å›½', 'Los Angeles': 'ç¾å›½', 'Washington': 'ç¾å›½', 'Chicago': 'ç¾å›½',
    'San Francisco': 'ç¾å›½', 'Las Vegas': 'ç¾å›½', 'Miami': 'ç¾å›½', 'Seattle': 'ç¾å›½',
    'Houston': 'ç¾å›½', 'Boston': 'ç¾å›½', 'Atlanta': 'ç¾å›½', 'Dallas': 'ç¾å›½',

    'JP': 'æ—¥æœ¬', 'Japan': 'æ—¥æœ¬', 'Tokyo': 'æ—¥æœ¬', 'Osaka': 'æ—¥æœ¬', 'Nagoya': 'æ—¥æœ¬',
    'Sapporo': 'æ—¥æœ¬', 'Fukuoka': 'æ—¥æœ¬', 'NTT': 'æ—¥æœ¬', 'IIJ': 'æ—¥æœ¬', 'GMO': 'æ—¥æœ¬', 'Linode': 'æ—¥æœ¬',

    'HK': 'é¦™æ¸¯', 'Hong Kong': 'é¦™æ¸¯', 'HongKong': 'é¦™æ¸¯', 'HKT': 'é¦™æ¸¯',
    'ä¹é¾™': 'é¦™æ¸¯', 'æ²™ç”°': 'é¦™æ¸¯', 'å±¯é—¨': 'é¦™æ¸¯', 'èƒæ¹¾': 'é¦™æ¸¯', 'æ·±æ°´åŸ—': 'é¦™æ¸¯', 'æ²¹å°–æ—º': 'é¦™æ¸¯',

    'SG': 'æ–°åŠ å¡', 'Singapore': 'æ–°åŠ å¡', 'SGP': 'æ–°åŠ å¡', 'SG': 'æ–°åŠ å¡',
    'æ˜Ÿ': 'æ–°åŠ å¡', 'ç‹®åŸ': 'æ–°åŠ å¡', 'å¡': 'æ–°åŠ å¡',

    'TW': 'å°æ¹¾', 'Taiwan': 'å°æ¹¾', 'TWN': 'å°æ¹¾',
    'Taipei': 'å°æ¹¾', 'Taichung': 'å°æ¹¾', 'Kaohsiung': 'å°æ¹¾',
    'æ–°åŒ—': 'å°æ¹¾', 'å½°åŒ–': 'å°æ¹¾', 'Hinet': 'å°æ¹¾', 'ä¸­åç”µä¿¡': 'å°æ¹¾',

    'KR': 'éŸ©å›½', 'Korea': 'éŸ©å›½', 'KOR': 'éŸ©å›½', 'Seoul': 'éŸ©å›½',
    'Busan': 'éŸ©å›½', 'KT': 'éŸ©å›½', 'SK': 'éŸ©å›½', 'LG': 'éŸ©å›½',
    'å—æœé²œ': 'éŸ©å›½', 'éŸ©': 'éŸ©å›½', 'éŸ“': 'éŸ©å›½',

    'DE': 'å¾·å›½', 'Germany': 'å¾·å›½', 'Frankfurt': 'å¾·å›½',
    'Munich': 'å¾·å›½', 'Berlin': 'å¾·å›½', 'Hetzner': 'å¾·å›½',

    'GB': 'è‹±å›½', 'United Kingdom': 'è‹±å›½', 'UK': 'è‹±å›½',
    'England': 'è‹±å›½', 'London': 'è‹±å›½', 'Manchester': 'è‹±å›½',

    'CA': 'åŠ æ‹¿å¤§', 'Canada': 'åŠ æ‹¿å¤§', 'Toronto': 'åŠ æ‹¿å¤§',
    'Vancouver': 'åŠ æ‹¿å¤§', 'Montreal': 'åŠ æ‹¿å¤§',

    'AU': 'æ¾³å¤§åˆ©äºš', 'Australia': 'æ¾³å¤§åˆ©äºš',
    'Sydney': 'æ¾³å¤§åˆ©äºš', 'Melbourne': 'æ¾³å¤§åˆ©äºš', 'Brisbane': 'æ¾³å¤§åˆ©äºš',
}

COUNTRY_NAME_TO_CODE_MAP = {
    "é˜¿æ ¹å»·": "AR", "æ¾³å¤§åˆ©äºš": "AU", "å¥¥åœ°åˆ©": "AT", "å­ŸåŠ æ‹‰å›½": "BD", "æ¯”åˆ©æ—¶": "BE",
    "å·´è¥¿": "BR", "ä¿åŠ åˆ©äºš": "BG", "åŠ æ‹¿å¤§": "CA", "æ™ºåˆ©": "CL", "å“¥ä¼¦æ¯”äºš": "CO",
    "å…‹ç½—åœ°äºš": "HR", "æ·å…‹": "CZ", "ä¸¹éº¦": "DK", "åŸƒåŠ": "EG", "çˆ±æ²™å°¼äºš": "EE",
    "èŠ¬å…°": "FI", "æ³•å›½": "FR", "å¾·å›½": "DE", "å¸Œè…Š": "GR", "é¦™æ¸¯": "HK", "åŒˆç‰™åˆ©": "HU",
    "å†°å²›": "IS", "å°åº¦": "IN", "å°åº¦å°¼è¥¿äºš": "ID", "çˆ±å°”å…°": "IE", "ä»¥è‰²åˆ—": "IL",
    "æ„å¤§åˆ©": "IT", "æ—¥æœ¬": "JP", "å“ˆè¨å…‹æ–¯å¦": "KZ", "éŸ©å›½": "KR", "æ‹‰è„±ç»´äºš": "LV",
    "ç«‹é™¶å®›": "LT", "å¢æ£®å ¡": "LU", "æ¾³é—¨": "MO", "é©¬æ¥è¥¿äºš": "MY", "å¢¨è¥¿å“¥": "MX",
    "æ‘©å°”å¤šç“¦": "MD", "è·å…°": "NL", "æ–°è¥¿å…°": "NZ", "å°¼æ—¥åˆ©äºš": "NG", "æŒªå¨": "NO",
    "å·´åŸºæ–¯å¦": "PK", "è²å¾‹å®¾": "PH", "æ³¢å…°": "PL", "è‘¡è„ç‰™": "PT", "ç½—é©¬å°¼äºš": "RO",
    "ä¿„ç½—æ–¯": "RU", "æ²™ç‰¹é˜¿æ‹‰ä¼¯": "SA", "å¡å°”ç»´äºš": "RS", "æ–°åŠ å¡": "SG", "æ–¯æ´›ä¼å…‹": "SK",
    "æ–¯æ´›æ–‡å°¼äºš": "SI", "å—é": "ZA", "è¥¿ç­ç‰™": "ES", "ç‘å…¸": "SE", "ç‘å£«": "CH",
    "å°æ¹¾": "TW", "æ³°å›½": "TH", "åœŸè€³å…¶": "TR", "ä¹Œå…‹å…°": "UA", "é˜¿è”é…‹": "AE",
    "è‹±å›½": "GB", "ç¾å›½": "US", "è¶Šå—": "VN", "é˜¿æ›¼": "OM", "æŸ¬åŸ”å¯¨": "KH",
    "ç§˜é²": "PE", "é˜¿å¡æ‹œç–†": "AZ", "å·´æ—": "BH","ä¼Šæ‹‰å…‹": "IQ", "å°¼æ³Šå°”": "NP",
    "å¡å¡”å°”": "QA", "ç§‘å¨ç‰¹": "KW", "é©¬è€³ä»–": "MT", "å¡æµ¦è·¯æ–¯": "CY", "æ ¼é²å‰äºš": "GE",
    "é˜¿å°”å·´å°¼äºš": "AL", "æ³¢é»‘": "BA", "åŒ—é©¬å…¶é¡¿": "MK", "é»å·´å«©": "LB", "çº¦æ—¦": "JO",
    "ç¼…ç”¸": "MM", "è€æŒ": "LA", "æ–¯é‡Œå…°å¡": "LK", "è‚¯å°¼äºš": "KE", "æ‘©æ´›å“¥": "MA",
    "çªå°¼æ–¯": "TN", "å„ç“œå¤šå°”": "EC", "ä¹Œæ‹‰åœ­": "UY", "å“¥æ–¯è¾¾é»åŠ ": "CR", "å·´æ‹¿é©¬": "PA",
}

JUNK_PATTERNS = re.compile(
    r"(?:ä¸“çº¿|IPLC|IEPL|BGP|ä½“éªŒ|ä¸‘å›¢|å®˜ç½‘|å€ç‡|x\d[\.\d]*|Rate|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)"
    r"|(?:(?:[\u2460-\u2473\u2776-\u277F\u2780-\u2789]|å…è²»|å›å®¶).*?(?=,|$))",
    re.IGNORECASE
)

CUSTOM_REGEX_RULES = {
    'é¦™æ¸¯': {
        'code': 'HK',
        'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong\s*Kong|HongKong|HKBN|HGC|PCCW|WTT|HKT|ä¹é¾™|æ²™ç”°|å±¯é—¨|èƒæ¹¾|æ·±æ°´åŸ—|æ²¹å°–æ—º'
    },
    'æ—¥æœ¬': {
        'code': 'JP',
        'pattern': r'æ—¥æœ¬|æ—¥|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|äº¬æ—¥|å¹¿æ—¥|JP|Japan|Tokyo|Osaka|Saitama|åŸ¼ç‰|åå¤å±‹|Nagoya|ç¦å†ˆ|Fukuoka|æ¨ªæ»¨|Yokohama|NTT|IIJ|GMO|Linode'
    },
    'æ–°åŠ å¡': {
        'code': 'SG',
        'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|ç‹®|æ–°|SG|Singapore|SG\d+|SGP|æ˜Ÿ|ç‹®å­åŸ'
    },
    'ç¾å›½': {
        'code': 'US',
        'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|ä¿„å‹’å†ˆ|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥|çº½çº¦|è¿ˆé˜¿å¯†|äºšç‰¹å…°å¤§|US|USA|United\s*States|America|LA|NYC|SF|San\s*Francisco|Washington|åç››é¡¿|Kansas|å ªè¨æ–¯|Denver|ä¸¹ä½›|Phoenix|Seattle|Chicago|Boston|æ³¢å£«é¡¿|Atlanta|Miami|Las\s*Vegas'
    },
    'å°æ¹¾': {
        'code': 'TW',
        'pattern': r'å°æ¹¾|æ¹¾çœ|å°|TW|Taiwan|TWN|å°åŒ—|Taipei|å°ä¸­|Taichung|é«˜é›„|Kaohsiung|æ–°åŒ—|å½°åŒ–|Hinet|ä¸­åç”µä¿¡'
    },
    'éŸ©å›½': {
        'code': 'KR',
        'pattern': r'éŸ©å›½|éŸ©|å—æœé²œ|é¦–å°”|é‡œå±±|ä»å·|KR|Korea|KOR|éŸ“|Seoul|Busan|KT|SK|LG'
    },
    'å¾·å›½': {
        'code': 'DE',
        'pattern': r'å¾·å›½|å¾·|æ³•å…°å…‹ç¦|æ…•å°¼é»‘|æŸæ—|DE|Germany|Frankfurt|Munich|Berlin|Hetzner'
    },
    'è‹±å›½': {
        'code': 'GB',
        'pattern': r'è‹±å›½|è‹±|ä¼¦æ•¦|æ›¼å½»æ–¯ç‰¹|UK|GB|United\s*Kingdom|Britain|England|London|Manchester'
    },
    'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'},
    'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},
}


FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')

def preprocess_regex_rules():
    for region, rules in CUSTOM_REGEX_RULES.items():
        parts = rules['pattern'].split('|')
        sorted_parts = sorted(parts, key=len, reverse=True)
        escaped_parts = [re.escape(p) for p in sorted_parts]
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(escaped_parts)

preprocess_regex_rules()

def sanitize_filename(name: str) -> str:
    import re
    match = re.match(r"#\s*(.*?)\s*[:ï¼š]", name, re.IGNORECASE)
    if match:
        title = match.group(1)
    else:
        title = name.lstrip('#').strip()
        title = re.sub(r'[:ï¼š]+$', '', title).strip()
    title = re.sub(r'[\\/:*?"<>|\sï¼š]+', '_', title)
    title = title.strip('_')
    return title or 'default'

def get_country_flag_emoji(country_code):
    if not country_code or len(country_code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in country_code)

def safe_b64decode(data):
    data = data.encode() if isinstance(data, str) else data
    missing_padding = (-len(data)) % 4
    data += b'=' * missing_padding
    return base64.urlsafe_b64decode(data)

# ----- ä¸‹è½½ç›¸å…³ -----
def attempt_download_using_wget(url):
    print(f"  â¬‡ï¸ wget ä¸‹è½½: {url[:80]}")
    if not shutil.which("wget"):
        print("  âœ— æœªå®‰è£… wget")
        return None
    try:
        proc = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        )
        return proc.stdout if proc.stdout else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget å¤±è´¥: {e.stderr.strip()}")
        return None

def attempt_download_using_requests(url):
    print(f"  â¬‡ï¸ requests ä¸‹è½½: {url[:80]}")
    try:
        headers = {'User-Agent': 'Clash'}
        r = requests.get(url, headers=headers, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding or 'utf-8'
        return r.text
    except Exception as e:
        print(f"  âœ— requests å¤±è´¥: {e}")
        return None

def download_subscription(url):
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        return []
    proxies = parse_proxies_from_content(content)
    if proxies:
        return proxies
    if is_base64(content):
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        print("  - Base64 è§£ç æ— æ•ˆèŠ‚ç‚¹")
    else:
        print("  - å†…å®¹é Base64")
    return []

# ----- è§£æç›¸å…³ -----
def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            if isinstance(proxies, list):
                return proxies
        elif isinstance(data, list):
            return data
    except Exception:
        pass
    return []

def is_base64(text):
    try:
        s = ''.join(text.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

def decode_base64_and_parse(content):
    try:
        decoded = base64.b64decode(''.join(content.split())).decode('utf-8', errors='ignore')
        # å¯é€‰ï¼šåœ¨è¿™é‡Œæ‰“å°è§£ç å†…å®¹é¢„è§ˆï¼ˆæ³¨é‡Šæ‰é¿å…å¤ªé•¿ï¼‰
        # print(f"  - Base64 è§£ç å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰ï¼š\n{decoded[:500]}{'...' if len(decoded) > 500 else ''}")
        proxies = []
        success_count = 0
        failure_count = 0
        for line in decoded.splitlines():
            line = line.strip()
            if not line:
                continue
            proxy = None
            if line.startswith('vmess://'):
                proxy = parse_vmess_node(line)
            elif line.startswith('vless://'):
                proxy = parse_vless_node(line)
            elif line.startswith('ssr://'):
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
                success_count += 1
            else:
                failure_count += 1
        print(f"  - Base64 è§£ç è§£æå®Œæˆï¼ŒæˆåŠŸè§£æèŠ‚ç‚¹æ•°ï¼š{success_count}ï¼Œå¤±è´¥æ•°ï¼š{failure_count}")
        return proxies
    except Exception as e:
        print(f"  - Base64 è§£ç è§£æå¼‚å¸¸: {e}")
        return []

# ----- åè®®è§£æå®ç° -----
def parse_vmess_node(line):
    try:
        content_b64 = line[8:]
        decoded = base64.b64decode(content_b64 + '=' * (-len(content_b64) % 4)).decode('utf-8', errors='ignore')
        info = json.loads(decoded)
        node = {
            'name': info.get('ps', 'vmess_node'),
            'type': 'vmess',
            'server': info.get('add') or info.get('host'),
            'port': int(info.get('port', 0)),
            'uuid': info.get('id') or info.get('uuid'),
            'alterId': int(info.get('aid', info.get('alterId', 0))) if str(info.get('aid', '')).isdigit() else 0,
            'cipher': info.get('scy', 'auto'),
            'network': info.get('net', 'tcp'),
            'tls': True if info.get('tls', '').lower() == 'tls' else False,
            'skip-cert-verify': info.get('allowInsecure', False),
            'ws-opts': {},
        }
        if node['network'] == 'ws':
            ws_opts = {
                'path': info.get('path', ''),
                'headers': {'Host': info.get('host', '')} if info.get('host') else {},
            }
            node['ws-opts'] = ws_opts
        return node
    except Exception as e:
        print(f"  - vmess èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_vless_node(line):
    try:
        line = line.strip()
        parsed = urlparse(line)
        if parsed.scheme != 'vless':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"vless_{parsed.hostname}",
            'type': 'vless',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'uuid': parsed.username,
            'encryption': 'none',
            'flow': params.get('flow', [''])[0],
            'tls': (parsed.query.lower().find('tls') != -1) or ('tls' in params),
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'network': params.get('type', ['tcp'])[0],
            'host': params.get('host', [''])[0],
            'path': params.get('path', [''])[0],
            'sni': params.get('sni', [''])[0],
        }
        if node['network'] == 'ws':
            node['ws-opts'] = {
                'path': node['path'],
                'headers': {'Host': node['host']} if node['host'] else {}
            }
        return node
    except Exception as e:
        print(f"  - vless èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_ssr_node(line):
    try:
        ssr_b64 = line[6:]
        ssr_decoded = base64.urlsafe_b64decode(ssr_b64 + '=' * (-len(ssr_b64) % 4)).decode('utf-8', errors='ignore')
        parts = ssr_decoded.split('/?')
        main = parts[0]
        params_str = parts[1] if len(parts) > 1 else ''
        
        server, port, protocol, method, obfs, password_b64 = main.split(':', 5)
        password = base64.urlsafe_b64decode(password_b64 + '=' * (-len(password_b64) % 4)).decode('utf-8', errors='ignore')
        
        params = {}
        for param in params_str.split('&'):
            if '=' in param:
                k, v = param.split('=', 1)
                params[k] = v

        remark = unquote(params.get('remarks', ''))
        node = {
            'name': remark or f"ssr_{server}",
            'type': 'ssr',
            'server': server,
            'port': int(port),
            'cipher': method,
            'protocol': protocol,
            'obfs': obfs,
            'password': password,
            'udp': params.get('udp', 'false').lower() == 'true'
        }
        return node
    except Exception as e:
        print(f"  - ssr èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_ss_node(line):
    try:
        line = line.strip()
        if not line.startswith('ss://'):
            return None
        content = line[5:]
        if '@' in content:
            parsed = urlparse('ss://' + content)
            user_pass = parsed.netloc.split('@')[0]
            method, password = user_pass.split(':', 1)
            server = parsed.hostname
            port = parsed.port
            name = unquote(parsed.fragment) if parsed.fragment else f"ss_{server}"
            node = {
                'name': name,
                'type': 'ss',
                'server': server,
                'port': port,
                'cipher': method,
                'password': password,
                'udp': True,
            }
            return node
        else:
            ss_b64 = content.split('#')[0]
            remark = ''
            if '#' in content:
                remark = unquote(content.split('#')[1])
            decoded = base64.urlsafe_b64decode(ss_b64 + '=' * (-len(ss_b64) % 4)).decode('utf-8', errors='ignore')
            method_password, server_port = decoded.split('@')
            method, password = method_password.split(':')
            server, port = server_port.split(':')
            node = {
                'name': remark or f"ss_{server}",
                'type': 'ss',
                'server': server,
                'port': int(port),
                'cipher': method,
                'password': password,
                'udp': True,
            }
            return node
    except Exception as e:
        print(f"  - ss èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_trojan_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'trojan':
            return None
        password = parsed.username or ''
        server = parsed.hostname or ''
        port = parsed.port or 0
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) if parsed.fragment else f"trojan_{server}",
            'type': 'trojan',
            'server': server,
            'port': port,
            'password': password,
            'sni': params.get('sni', [''])[0],
            'skip-cert-verify': params.get('allowInsecure', ['false'])[0].lower() == 'true',
            'udp': True,
            'alpn': params.get('alpn', []),
            'tls': True,
        }
        return node
    except Exception as e:
        print(f"  - trojan èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_hysteria_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria_{parsed.hostname}",
            'type': 'hysteria',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception as e:
        print(f"  - hysteria èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

def parse_hysteria2_node(line):
    try:
        parsed = urlparse(line)
        if parsed.scheme != 'hysteria2':
            return None
        params = parse_qs(parsed.query)
        node = {
            'name': unquote(parsed.fragment) or f"hysteria2_{parsed.hostname}",
            'type': 'hysteria2',
            'server': parsed.hostname,
            'port': int(parsed.port or 0),
            'auth': params.get('auth', [''])[0],
            'protocol': params.get('protocol', ['udp'])[0],
            'insecure': params.get('insecure', ['false'])[0].lower() == 'true',
            'obfs': params.get('obfs', [''])[0],
            'udp': True,
        }
        return node
    except Exception as e:
        print(f"  - hysteria2 èŠ‚ç‚¹è§£æå¤±è´¥: {e}")
        return None

# ----- åˆå¹¶å»é‡ -----
def get_proxy_key(proxy):
    try:
        key = f"{proxy.get('server', '')}:{proxy.get('port', 0)}|"
        if 'uuid' in proxy:
            key += proxy['uuid']
        elif 'password' in proxy:
            key += proxy['password']
        else:
            key += proxy.get('name', '')
        return hashlib.md5(key.encode('utf-8')).hexdigest()
    except:
        return None

def merge_and_deduplicate_proxies(proxies):
    unique = {}
    for proxy in proxies:
        if not isinstance(proxy, dict) or 'name' not in proxy:
            continue
        k = get_proxy_key(proxy)
        if k and k not in unique:
            unique[k] = proxy
    return list(unique.values())

# ----- é‡ç‚¹å‡½æ•°ï¼šé‡å‘½åæ’åº -----
def process_and_rename_proxies(proxies):
    country_counters = defaultdict(int)
    final_proxies = []

    # æå–æ‰€æœ‰å¯èƒ½çš„å›½å®¶åœ°åŒºè¯ï¼Œç”¨äºæ­£åˆ™åŒ¹é…
    all_country_names = set()
    for rules in CUSTOM_REGEX_RULES.values():
        all_country_names.update(rules['pattern'].split('|'))
    all_country_names.update(CHINESE_COUNTRY_MAP.keys())
    all_country_names.update(CHINESE_COUNTRY_MAP.values())
    all_country_names.update(COUNTRY_NAME_TO_CODE_MAP.keys())

    # æŒ‰é•¿åº¦å€’åºæ’åˆ—ï¼Œé¿å…å­ä¸²å†²çª
    sorted_country_names = sorted(all_country_names, key=len, reverse=True)
    country_pattern = re.compile('|'.join(map(re.escape, sorted_country_names)), re.IGNORECASE)

    # åŒ¹é…é€Ÿåº¦çš„æ­£åˆ™ï¼Œå…¼å®¹ M/K å•ä½
    speed_pattern = re.compile(r'(\d+(?:\.\d+)?)\s*(M|K)?B/s', re.IGNORECASE)

    # åˆ é™¤æ‰€æœ‰å›½æ—— Emoji
    def remove_all_flag_emojis(text):
        return FLAG_EMOJI_PATTERN.sub('', text).strip()

    def replace_country_code(m):
        code = m.group(0)
        return CHINESE_COUNTRY_MAP.get(code.upper(), code)

    for proxy in proxies:
        original_name = proxy.get('name', '').strip()

        # 1. åˆ é™¤æ‰€æœ‰å›½æ——å’Œåƒåœ¾å­—æ®µï¼Œå‡å°å¹²æ‰°
        clean_name = remove_all_flag_emojis(original_name)
        clean_name = JUNK_PATTERNS.sub('', clean_name)

        # 2. æ­£åˆ™æå–é€Ÿåº¦ï¼Œä¿ç•™ç¬¬ä¸€ä¸ªåŒ¹é…
        speed_text = ''
        speed_match = speed_pattern.search(clean_name)
        if speed_match:
            number, unit = speed_match.groups()
            unit = unit.upper() if unit else ''
            speed_text = f"{number}{unit}B/s"
            # ä»åå­—é‡Œå»æ‰é€Ÿåº¦æ–‡æœ¬
            clean_name = speed_pattern.sub('', clean_name, count=1).strip()

        # 3. æ­£åˆ™åŒ¹é…åœ°åŒº/å›½å®¶ï¼Œä¼˜å…ˆå–ç¬¬ä¸€ä¸ªåŒ¹é…
        country_match = country_pattern.search(clean_name)
        if country_match:
            region_name = country_match.group(0)
            # æ›¿æ¢ç®€å†™è‹±æ–‡ä¸ºä¸­æ–‡åï¼ˆå¦‚æœåœ¨CHINESE_COUNTRY_MAPé‡Œï¼‰
            region_name = replace_country_code(re.match(r'.*', region_name) or country_match)
            # å› å¯èƒ½è¿˜æ˜¯è‹±æ–‡ç¼©å†™ï¼Œç”¨æ˜ å°„å…ˆè½¬æ¢è‹±æ–‡->ä¸­æ–‡
            # è¿™é‡Œæ‰‹åŠ¨å†æ˜ å°„ä¸€æ¬¡ï¼Œç¡®ä¿æ˜¯ä¸­æ–‡æ˜¾ç¤º
            for eng, chn in CHINESE_COUNTRY_MAP.items():
                if re.fullmatch(re.escape(region_name), eng, re.IGNORECASE):
                    region_name = chn
                    break
        else:
            region_name = 'æœªçŸ¥'

        # 4. åºå·è®¡æ•°
        country_counters[region_name] += 1
        seq_num = country_counters[region_name]

        # 5. è·å–å›½æ—— emoji
        region_code = COUNTRY_NAME_TO_CODE_MAP.get(region_name) or CUSTOM_REGEX_RULES.get(region_name, {}).get('code', '')
        flag_emoji = get_country_flag_emoji(region_code)

        # 6. ç”Ÿæˆæ–°èŠ‚ç‚¹åï¼šå›½æ——emoji+åœ°åŒºå-åºå·|é€Ÿåº¦ï¼ˆé€Ÿåº¦å¯é€‰ï¼‰
        new_name = f"{flag_emoji}{region_name}-{seq_num}"
        if speed_text:
            new_name += f"|{speed_text}"

        proxy['name'] = new_name
        final_proxies.append(proxy)

    return final_proxies

# ----- æµ‹é€Ÿ -----
def test_single_proxy_socket(proxy):
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(SOCKET_TIMEOUT)
        start = time.time()
        sock.connect((str(server), int(port)))
        end = time.time()
        proxy['delay'] = int((end - start) * 1000)
        return proxy
    except Exception:
        return None
    finally:
        if 'sock' in locals():
            sock.close()

def speed_test_proxies(proxies):
    print(f"å¼€å§‹æµ‹é€Ÿ: å…± {len(proxies)} ä¸ªèŠ‚ç‚¹")
    fast_proxies = []
    total = len(proxies)
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_TEST_WORKERS) as executor:
        futures = {executor.submit(test_single_proxy_socket, p): p for p in proxies}
        for i, f in enumerate(concurrent.futures.as_completed(futures), 1):
            result = f.result()
            if i % 100 == 0 or i == total:
                print(f"\ræµ‹é€Ÿè¿›åº¦: {i}/{total}", end='', flush=True)
            if result:
                fast_proxies.append(result)
    print()
    print(f"æµ‹é€Ÿå®Œæˆ: æœ‰æ•ˆèŠ‚ç‚¹ {len(fast_proxies)}")
    return fast_proxies

# ----- é…ç½®æ–‡ä»¶ç”Ÿæˆ -----
def generate_config(proxies):
    if not proxies:
        return None
    proxy_names = [p['name'] for p in proxies]
    clean_proxies = [{k: v for k, v in p.items() if k not in ['region', 'delay']} for p in proxies]
    return {
        'mixed-port': 7890,
        'allow-lan': True,
        'bind-address': '*',
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': clean_proxies,
        'proxy-groups': [
            {'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'type': 'select',
             'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + proxy_names},
            {'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'type': 'url-test', 'proxies': proxy_names,
             'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
            {'name': 'ğŸ”¯ æ•…éšœè½¬ç§»', 'type': 'fallback', 'proxies': proxy_names,
             'url': 'http://www.gstatic.com/generate_204', 'interval': 300}],
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

# ------------------ å¤šåŒºå—è¯»å–ä¸å¤„ç† ------------------
def parse_url_txt_to_blocks():
    if not os.path.exists(URL_FILE):
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {URL_FILE}")
        return []
    with open(URL_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    blocks = []
    current_block = {'title': None, 'lines': []}
    for line in lines:
        stripped = line.strip()
        if stripped.startswith('#'):
            if current_block['title']:
                blocks.append(current_block)
            current_block = {'title': stripped, 'lines': []}
        else:
            if stripped:
                current_block['lines'].append(stripped)
    if current_block['title']:
        blocks.append(current_block)
    return blocks

def extract_urls_from_lines(lines):
    url_pattern = re.compile(r'https?://[^\s]+', re.IGNORECASE)
    urls = []
    for line in lines:
        urls.extend(url_pattern.findall(line))
    return urls

def process_block_to_yaml(block):
    title = block['title']
    lines = block['lines']
    urls = extract_urls_from_lines(lines)
    if not urls:
        print(f"{title} åŒºå—æ— æœ‰æ•ˆè®¢é˜…ï¼Œè·³è¿‡ã€‚")
        return
    print(f"\nå¤„ç†åŒºå—ï¼š{title} | {len(urls)} ä¸ªè®¢é˜…é“¾æ¥")
    all_proxies = []
    for url in urls:
        all_proxies.extend(download_subscription(url))
    if not all_proxies:
        print(f"{title} è®¢é˜…ä¸‹è½½å¤±è´¥æˆ–æ— èŠ‚ç‚¹ï¼Œè·³è¿‡ã€‚")
        return
    unique_proxies = merge_and_deduplicate_proxies(all_proxies)
    if ENABLE_SPEED_TEST:
        tested_proxies = speed_test_proxies(unique_proxies)
        if not tested_proxies:
            print(f"{title} æµ‹é€Ÿæ— å¯ç”¨èŠ‚ç‚¹ï¼Œä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ã€‚")
            tested_proxies = unique_proxies
    else:
        tested_proxies = unique_proxies
    region_order = {r: i for i, r in enumerate(REGION_PRIORITY)}
    tested_proxies.sort(key=lambda p: (region_order.get(p.get('region', 'æœªçŸ¥'), 999), p.get('delay', 9999)))
    final_proxies = process_and_rename_proxies(tested_proxies)
    config = generate_config(final_proxies)
    if not config:
        print(f"{title} é…ç½®ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚")
        return
    filename = sanitize_filename(title) + ".yaml"
    filepath = os.path.join(OUTPUT_DIR, filename)
    with open(filepath, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2)
    print(f"{title} é…ç½®å·²ç”Ÿæˆï¼š{filepath}ï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(final_proxies)}")

def main():
    print("=" * 60)
    print("å›ºå®šé“¾æ¥è·å–èŠ‚ç‚¹è„šæœ¬ V1")
    print(f"æ—¶é—´: {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    blocks = parse_url_txt_to_blocks()
    if not blocks:
        print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆåŒºå—ï¼Œé€€å‡ºã€‚")
        return
    for block in blocks:
        process_block_to_yaml(block)
    print(f"\nå…¨éƒ¨åŒºå—å¤„ç†å®Œæˆï¼Œé…ç½®æ–‡ä»¶å­˜æ”¾äºï¼š{OUTPUT_DIR}")

if __name__ == "__main__":
    main()
