"""
FlClashèŠ‚ç‚¹è·å–è„šæœ¬ V1.r1
-------------------------------------
åŠŸèƒ½æè¿°ï¼š
1. ä»å½“å‰ç›®å½•ä¸‹åä¸º URL.TXT çš„è®¢é˜…åˆ—è¡¨æ–‡ä»¶è¯»å–è®¢é˜…åœ°å€ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…è„šæœ¬æ–‡ä»¶åç­›é€‰ã€‚
2. æ”¯æŒé€šè¿‡ wget ä¼˜å…ˆä¸‹è½½è®¢é˜…å†…å®¹ï¼Œå¤±è´¥åè‡ªåŠ¨é™çº§ä½¿ç”¨ requests æ¨¡å—ä¸‹è½½ï¼Œå¢åŠ å…¼å®¹æ€§ã€‚
3. è‡ªåŠ¨è¯†åˆ«å¹¶è§£æè®¢é˜…å†…å®¹ï¼š
    - å…ˆå°è¯•å°†å†…å®¹è§£æä¸º YAML æ ¼å¼ï¼Œå¸¸è§ Clash è®¢é˜…æ ¼å¼ã€‚
    - è‹¥é YAMLï¼Œè‡ªåŠ¨æ£€æµ‹æ˜¯å¦ä¸º Base64 ç¼–ç ï¼Œæ”¯æŒè§£ç å¹¶è§£æå¸¸ç”¨åè®®é“¾æ¥ï¼ˆvmessã€vlessã€ssrã€ssã€trojanã€hysteriaç­‰ï¼‰ä¸ºä»£ç†èŠ‚ç‚¹ã€‚
4. åˆå¹¶å¤šä¸ªè®¢é˜…ä»£ç†èŠ‚ç‚¹ï¼Œå»é‡ï¼Œé¿å…é‡å¤èŠ‚ç‚¹ã€‚
5. æ”¯æŒçº¯ Python socket å¤šçº¿ç¨‹å¹¶å‘æµ‹é€ŸèŠ‚ç‚¹å»¶è¿Ÿï¼Œå‰”é™¤æ— å“åº”èŠ‚ç‚¹ï¼Œæå‡èŠ‚ç‚¹è´¨é‡ã€‚
6. èŠ‚ç‚¹åç§°æ™ºèƒ½é‡å‘½åï¼Œæ ¹æ®åœ°åŒºä¼˜å…ˆçº§åŠç‰¹å¾æå–ç”Ÿæˆè§„èŒƒåç§°ï¼Œè‡ªåŠ¨æ·»åŠ å›½æ—— Emojiã€‚
7. æ ¹æ®æµ‹é€Ÿç»“æœåŠé¢„è®¾åœ°åŒºä¼˜å…ˆçº§è¿›è¡Œæ’åºï¼Œå¹¶ç”Ÿæˆå¯ç›´æ¥ç”¨äº Clash è½¯ä»¶çš„å®Œæ•´é…ç½®æ–‡ä»¶ YAMLã€‚
8. è¾“å‡ºé…ç½®æ–‡ä»¶è‡³å½“å‰ç›®å½•ä¸‹ TG-SSRProxy.yamlã€‚
9. è®¾è®¡æ”¯æŒçµæ´»çš„è®¢é˜…åœ°å€ç®¡ç†åŠè‡ªåŠ¨åŒ–æ‰¹é‡åŒæ­¥æ›´æ–°ã€‚

ç‰ˆæœ¬è¯´æ˜ï¼š
V1.r1ï¼ˆ2025-12-02ï¼‰
- åˆå§‹ç‰ˆæœ¬å®Œæˆï¼Œæ ¸å¿ƒè®¢é˜…ä¸‹è½½ã€æ ¼å¼è§£æã€åˆå¹¶ã€æµ‹é€Ÿã€é‡å‘½åã€é…ç½®ç”Ÿæˆå…¨æµç¨‹åŠŸèƒ½ã€‚
- å¢åŠ  wget + requests åŒé‡ä¸‹è½½ä¿éšœã€‚
- å®ç° Base64 è‡ªåŠ¨æ£€æµ‹è§£ç åŠå¤šåè®®èŠ‚ç‚¹è§£æã€‚
- æ™ºèƒ½èŠ‚ç‚¹å‘½åï¼Œå¢å¼ºèŠ‚ç‚¹ç®¡ç†ä½“éªŒã€‚
- é«˜å¹¶å‘çº¯ Python æµ‹é€Ÿå®ç°ã€‚

æœªæ¥å¾…å®Œå–„é¡¹ï¼š
- æ”¯æŒæ›´å¤šä»£ç†åè®®è§£æã€‚
- å¢åŠ æ›´ä¸°å¯Œçš„è´¨é‡ç­›é€‰å’Œåˆ†ç±»åŠŸèƒ½ã€‚
- å¢å¼ºè®¢é˜…æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§ã€‚
- GUI æˆ–å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶ä¼˜åŒ–ã€‚
- æ›´å¤šæ—¥å¿—è¾“å‡ºåŠé”™è¯¯å¤„ç†ç»†åŒ–ã€‚

ä½¿ç”¨è¯´æ˜ï¼š
- å°†è®¢é˜…é“¾æ¥ä¿å­˜åœ¨ä¸è„šæœ¬åŒç›®å½•çš„ URL.TXT æ–‡ä»¶ä¸­ï¼Œæ ¼å¼ç¤ºä¾‹ï¼š
  # æ¸ é“åç§°
  FlClash-V2rayï¼šhttps://example.com/subscription
- ä¿®æ”¹è„šæœ¬åç§°åŒ¹é…å…³é”®å­—æ§åˆ¶åŠ è½½å“ªäº›è®¢é˜…ã€‚
- è¿è¡Œè„šæœ¬ï¼Œç­‰å¾…æµ‹é€Ÿå’Œé…ç½®ç”Ÿæˆå®Œæˆåï¼Œç›´æ¥åŠ è½½ç”Ÿæˆçš„ TG-SSRProxy.yaml åˆ° Clash æˆ–å…¶ä»–æ”¯æŒ YAML é…ç½®çš„è½¯ä»¶ã€‚
"""
# ========== ä¾èµ–é…ç½® ==========
import yaml
import base64
import time
from datetime import datetime
import sys
import os
import re
from collections import defaultdict
import socket
import concurrent.futures
import hashlib
import subprocess
import shutil
import requests
import json

# ========== åŸºç¡€é…ç½® ==========
# SUBSCRIPTION_URLS å°†é€šè¿‡ä» URL.TXT æ–‡ä»¶åŠ è½½æ¥åŠ¨æ€å¡«å……
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
URL_FILE = os.path.join(SCRIPT_DIR, "URL.TXT")  # å®šä¹‰ URL.TXT æ–‡ä»¶çš„è·¯å¾„
OUTPUT_FILE = os.path.join(SCRIPT_DIR, "TG-SSRProxy.yaml")
# è·å–å½“å‰è„šæœ¬çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œç”¨äºåŒ¹é… URL.TXT ä¸­çš„åç§°
CURRENT_SCRIPT_NAME = os.path.splitext(os.path.basename(__file__))[0]
print(f"å½“å‰è„šæœ¬æ–‡ä»¶å (ä¸å«æ‰©å±•å): {CURRENT_SCRIPT_NAME}")
# ========== æµ‹é€Ÿè¿‡æ»¤é…ç½® (çº¯ Python socket ç‰ˆ) ==========
ENABLE_SPEED_TEST = True  # Falseä¸ºä¸æµ‹é€Ÿï¼ŒTrueä¸ºæµ‹é€Ÿ
# socket è¿æ¥è¶…æ—¶æ—¶é—´(ç§’)
SOCKET_TIMEOUT = 10
# å¹¶å‘æµ‹é€Ÿçš„çº¿ç¨‹æ•°
MAX_TEST_WORKERS = 256  # socket éå¸¸è½»é‡ï¼Œå¯ä»¥å¤§å¹…å¢åŠ å¹¶å‘æ•°ä»¥æé«˜é€Ÿåº¦ï¼Œé»˜è®¤128
# ========== æ’åºä¸å‘½åé…ç½® ==========
REGION_PRIORITY = ['é¦™æ¸¯', 'æ—¥æœ¬', 'ç‹®åŸ', 'ç¾å›½', 'æ¹¾çœ', 'éŸ©å›½', 'å¾·å›½', 'è‹±å›½', 'åŠ æ‹¿å¤§', 'æ¾³å¤§åˆ©äºš']
CHINESE_COUNTRY_MAP = {'US': 'ç¾å›½', 'United States': 'ç¾å›½', 'USA': 'ç¾å›½', 'JP': 'æ—¥æœ¬', 'Japan': 'æ—¥æœ¬', 'HK': 'é¦™æ¸¯', 'Hong Kong': 'é¦™æ¸¯', 'SG': 'ç‹®åŸ', 'Singapore': 'ç‹®åŸ', 'TW': 'æ¹¾çœ', 'Taiwan': 'æ¹¾çœ', 'KR': 'éŸ©å›½', 'Korea': 'éŸ©å›½', 'KOR': 'éŸ©å›½', 'DE': 'å¾·å›½', 'Germany': 'å¾·å›½', 'GB': 'è‹±å›½', 'United Kingdom': 'è‹±å›½', 'UK': 'è‹±å›½', 'CA': 'åŠ æ‹¿å¤§', 'Canada': 'åŠ æ‹¿å¤§', 'AU': 'æ¾³å¤§åˆ©äºš', 'Australia': 'æ¾³å¤§åˆ©äºš', }
COUNTRY_NAME_TO_CODE_MAP = {"é˜¿å¯Œæ±—": "AF", "é˜¿å°”å·´å°¼äºš": "AL", "é˜¿å°”åŠåˆ©äºš": "DZ", "å®‰é“å°”": "AD", "å®‰å“¥æ‹‰": "AO", "å®‰åœ­æ‹‰": "AI", "å®‰æç“œå’Œå·´å¸ƒè¾¾": "AG", "é˜¿æ ¹å»·": "AR", "äºšç¾å°¼äºš": "AM", "é˜¿é²å·´": "AW", "æ¾³å¤§åˆ©äºš": "AU", "å¥¥åœ°åˆ©": "AT", "é˜¿å¡æ‹œç–†": "AZ", "å·´å“ˆé©¬": "BS", "å·´æ—": "BH", "å­ŸåŠ æ‹‰å›½": "BD", "å·´å·´å¤šæ–¯": "BB", "ç™½ä¿„ç½—æ–¯": "BY", "æ¯”åˆ©æ—¶": "BE", "ä¼¯åˆ©å…¹": "BZ", "è´å®": "BJ", "ç™¾æ…•å¤§": "BM", "ä¸ä¸¹": "BT", "ç»åˆ©ç»´äºš": "BO", "æ³¢é»‘": "BA", "åšèŒ¨ç“¦çº³": "BW", "å·´è¥¿": "BR", "æ–‡è±": "BN", "ä¿åŠ åˆ©äºš": "BG", "å¸ƒåŸºçº³æ³•ç´¢": "BF", "å¸ƒéš†è¿ª": "BI", "æŸ¬åŸ”å¯¨": "KH", "å–€éº¦éš†": "CM", "åŠ æ‹¿å¤§": "CA", "ä½›å¾—è§’": "CV", "å¼€æ›¼ç¾¤å²›": "KY", "ä¸­é": "CF", "ä¹å¾—": "TD", "æ™ºåˆ©": "CL", "ä¸­å›½": "CN", "å“¥ä¼¦æ¯”äºš": "CO", "ç§‘æ‘©ç½—": "KM", "åˆšæœï¼ˆé‡‘ï¼‰": "CD", "åˆšæœï¼ˆå¸ƒï¼‰": "CG", "å“¥æ–¯è¾¾é»åŠ ": "CR", "ç§‘ç‰¹è¿ªç“¦": "CI", "å…‹ç½—åœ°äºš": "HR", "å¤å·´": "CU", "å¡æµ¦è·¯æ–¯": "CY", "æ·å…‹": "CZ", "ä¸¹éº¦": "DK", "å‰å¸ƒæ": "DJ", "å¤šç±³å°¼å…‹": "DM", "å¤šç±³å°¼åŠ ": "DO", "å„ç“œå¤šå°”": "EC", "åŸƒåŠ": "EG", "è¨å°”ç“¦å¤š": "SV", "èµ¤é“å‡ å†…äºš": "GQ", "å„ç«‹ç‰¹é‡Œäºš": "ER", "çˆ±æ²™å°¼äºš": "EE", "åŸƒå¡ä¿„æ¯”äºš": "ET", "æ–æµ": "FJ", "èŠ¬å…°": "FI", "æ³•å›½": "FR", "åŠ è“¬": "GA", "å†ˆæ¯”äºš": "GM", "æ ¼é²å‰äºš": "GE", "åŠ çº³": "GH", "å¸Œè…Š": "GR", "æ ¼æ—çº³è¾¾": "GD", "å±åœ°é©¬æ‹‰": "GT", "å‡ å†…äºš": "GN", "å‡ å†…äºšæ¯”ç»": "GW", "åœ­äºšé‚£": "GY", "æµ·åœ°": "HT", "æ´ªéƒ½æ‹‰æ–¯": "HN", "åŒˆç‰™åˆ©": "HU", "å†°å²›": "IS", "å°åº¦": "IN", "å°å°¼": "ID", "å°åº¦å°¼è¥¿äºš": "ID", "ä¼Šæœ—": "IR", "ä¼Šæ‹‰å…‹": "IQ", "çˆ±å°”å…°": "IE", "ä»¥è‰²åˆ—": "IL", "æ„å¤§åˆ©": "IT", "ç‰™ä¹°åŠ ": "JM", "æ—¥æœ¬": "JP", "çº¦æ—¦": "JO", "å“ˆè¨å…‹æ–¯å¦": "KZ", "è‚¯å°¼äºš": "KE", "åŸºé‡Œå·´æ–¯": "KI", "ç§‘å¨ç‰¹": "KW", "å‰å°”å‰æ–¯æ–¯å¦": "KG", "è€æŒ": "LA", "æ‹‰è„±ç»´äºš": "LV", "é»å·´å«©": "LB", "è±ç´¢æ‰˜": "LS", "åˆ©æ¯”é‡Œäºš": "LR", "åˆ©æ¯”äºš": "LY", "åˆ—æ”¯æ•¦å£«ç™»": "LI", "ç«‹é™¶å®›": "LT", "å¢æ£®å ¡": "LU", "æ¾³é—¨": "MO", "åŒ—é©¬å…¶é¡¿": "MK", "é©¬è¾¾åŠ æ–¯åŠ ": "MG", "é©¬æ‹‰ç»´": "MW", "é©¬æ¥è¥¿äºš": "MY", "é©¬å°”ä»£å¤«": "MV", "é©¬é‡Œ": "ML", "é©¬è€³ä»–": "MT", "é©¬ç»å°”ç¾¤å²›": "MH", "æ¯›é‡Œå¡”å°¼äºš": "MR", "æ¯›é‡Œæ±‚æ–¯": "MU", "å¢¨è¥¿å“¥": "MX", "å¯†å…‹ç½—å°¼è¥¿äºš": "FM", "æ‘©å°”å¤šç“¦": "MD", "æ‘©çº³å“¥": "MC", "è’™å¤": "MN", "é»‘å±±": "ME", "æ‘©æ´›å“¥": "MA", "è«æ¡‘æ¯”å…‹": "MZ", "ç¼…ç”¸": "MM", "çº³ç±³æ¯”äºš": "NA", "ç‘™é²": "NR", "å°¼æ³Šå°”": "NP", "è·å…°": "NL", "æ–°è¥¿å…°": "NZ", "å°¼åŠ æ‹‰ç“œ": "NI", "å°¼æ—¥å°”": "NE", "å°¼æ—¥åˆ©äºš": "NG", "æŒªå¨": "NO", "é˜¿æ›¼": "OM", "å·´åŸºæ–¯å¦": "PK", "å¸•åŠ³": "PW", "å·´å‹’æ–¯å¦": "PS", "å·´æ‹¿é©¬": "PA", "å·´å¸ƒäºšæ–°å‡ å†…äºš": "PG", "å·´æ‹‰åœ­": "PY", "ç§˜é²": "PE", "è²å¾‹å®¾": "PH", "æ³¢å…°": "PL", "è‘¡è„ç‰™": "PT", "å¡å¡”å°”": "QA", "ç½—é©¬å°¼äºš": "RO", "ä¿„ç½—æ–¯": "RU", "å¢æ—ºè¾¾": "RW", "åœ£é©¬åŠ›è¯º": "SM", "æ²™ç‰¹é˜¿æ‹‰ä¼¯": "SA", "å¡å†…åŠ å°”": "SN", "å¡å°”ç»´äºš": "RS", "å¡èˆŒå°”": "SC", "å¡æ‹‰åˆ©æ˜‚": "SL", "æ–°åŠ å¡": "SG", "æ–¯æ´›ä¼å…‹": "SK", "æ–¯æ´›æ–‡å°¼äºš": "SI", "æ‰€ç½—é—¨ç¾¤å²›": "SB", "ç´¢é©¬é‡Œ": "SO", "å—é": "ZA", "è¥¿ç­ç‰™": "ES", "æ–¯é‡Œå…°å¡": "LK", "è‹ä¸¹": "SD", "è‹é‡Œå—": "SR", "ç‘å…¸": "SE", "ç‘å£«": "CH", "å™åˆ©äºš": "SY", "å¡”å‰å…‹æ–¯å¦": "TJ", "å¦æ¡‘å°¼äºš": "TZ", "æ³°å›½": "TH", "ä¸œå¸æ±¶": "TL", "å¤šå“¥": "TG", "æ±¤åŠ ": "TO", "ç‰¹ç«‹å°¼è¾¾å’Œå¤šå·´å“¥": "TT", "çªå°¼æ–¯": "TN", "åœŸè€³å…¶": "TR", "åœŸåº“æ›¼æ–¯å¦": "TM", "å›¾ç“¦å¢": "TV", "ä¹Œå¹²è¾¾": "UG", "ä¹Œå…‹å…°": "UA", "é˜¿è”é…‹": "AE", "ä¹Œæ‹‰åœ­": "UY", "ä¹Œå…¹åˆ«å…‹æ–¯å¦": "UZ", "ç“¦åŠªé˜¿å›¾": "VU", "å§”å†…ç‘æ‹‰": "VE", "è¶Šå—": "VN", "ä¹Ÿé—¨": "YE", "èµæ¯”äºš": "ZM", "æ´¥å·´å¸ƒéŸ¦": "ZW"}
JUNK_PATTERNS = re.compile(r"(?:ä¸“çº¿|IPLC|IEPL|BGP|ä½“éªŒ|å®˜ç½‘|å€ç‡|x\d[\.\d]*|Rate|[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*|Relay|æµé‡)|(?:(?:[\u2460-\u2473\u2776-\u277F\u2780-\u2789]|å…è²»|å›å®¶).*?(?=,|$))", re.IGNORECASE)
CUSTOM_REGEX_RULES = {'é¦™æ¸¯': {'code': 'HK', 'pattern': r'é¦™æ¸¯|æ¸¯|HK|Hong Kong|HKBN|HGC|PCCW|WTT'}, 'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|æ²ªæ—¥|æ·±æ—¥|JP|Japan'}, 'ç‹®åŸ': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|å¡|ç‹®åŸ|SG|Singapore'}, 'ç¾å›½': {'code': 'US', 'pattern': r'ç¾å›½|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥'}, 'æ¹¾çœ': {'code': 'TW', 'pattern': r'å°æ¹¾|æ¹¾çœ|å°|æ–°åŒ—|å½°åŒ–|TW|Taiwan'}, 'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©å›½|éŸ©|é¦–å°”|KR|Korea|KOR|éŸ“'}, 'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'}, 'è‹±å›½': {'code': 'GB', 'pattern': r'è‹±å›½|è‹±|UK|GB|United Kingdom|England'}, 'åŠ æ‹¿å¤§': {'code': 'CA', 'pattern': r'åŠ æ‹¿å¤§|æ«å¶|å¤šä¼¦å¤š|æ¸©å“¥å|è’™ç‰¹åˆ©å°”|CA|Canada'}, 'æ¾³å¤§åˆ©äºš': {'code': 'AU', 'pattern': r'æ¾³å¤§åˆ©äºš|æ¾³æ´²|æ‚‰å°¼|AU|Australia'},}
# ===== å›½æ——è¡¨æƒ…æ­£åˆ™è¡¨è¾¾å¼ =====
# åŒ¹é…ä»»æ„ä¸¤ä¸ªåŒºåŸŸæŒ‡ç¤ºç¬¦ç¬¦å·ï¼ˆå³å›½æ——è¡¨æƒ…ï¼‰
FLAG_EMOJI_PATTERN = re.compile(r'[\U0001F1E6-\U0001F1FF]{2}')

# ========== é¢„å¤„ç†è‡ªå®šä¹‰æ­£åˆ™è§„åˆ™ ==========
def preprocess_regex_rules():
    for region, rules in CUSTOM_REGEX_RULES.items():
        parts = rules['pattern'].split('|')
        sorted_parts = sorted(parts, key=len, reverse=True)  # æŒ‰é•¿åº¦é™åºæ’åº
        CUSTOM_REGEX_RULES[region]['pattern'] = '|'.join(sorted_parts)
preprocess_regex_rules()


def get_country_flag_emoji(country_code):
    if not country_code or len(country_code) != 2:
        return "â“"
    return "".join(chr(0x1F1E6 + ord(c.upper()) - ord('A')) for c in country_code)


# -------------- æ–°å¢çš„ wget + requests ä¸‹è½½åŠè§£æ --------------
def attempt_download_using_wget(url):
    """ä½¿ç”¨ wget ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ wget ä¸‹è½½: {url[:80]}...")
    if not shutil.which("wget"):
        print("  âœ— é”™è¯¯: wget æœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œä¸‹è½½ã€‚")
        return None
    try:
        result = subprocess.run(
            ["wget", "-O", "-", "--timeout=30", "--header=User-Agent: Clash", url],
            capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore'
        )
        content = result.stdout
        return content if content else None
    except subprocess.CalledProcessError as e:
        print(f"  âœ— wget ä¸‹è½½å¤±è´¥: {e.stderr}")
        return None

def attempt_download_using_requests(url):
    """ä½¿ç”¨ requests ä¸‹è½½è®¢é˜…é“¾æ¥"""
    print(f"  â¬‡ï¸ æ­£åœ¨ä½¿ç”¨ requests ä¸‹è½½: {url[:80]}...")
    try:
        headers = {'User-Agent': 'Clash'}
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or 'utf-8'
        return response.text
    except requests.RequestException as e:
        print(f"  âœ— requests ä¸‹è½½å¤±è´¥: {e}")
        return None

def download_subscription(url):
    """
    ä¼˜å…ˆä½¿ç”¨ wget ä¸‹è½½ï¼Œå¤±è´¥åä½¿ç”¨ requests ä¸‹è½½ã€‚
    è¿”å›ä¸‹è½½å†…å®¹æˆ– Noneã€‚
    """
    content = attempt_download_using_wget(url)
    if content is None:
        content = attempt_download_using_requests(url)
    if content is None:
        return []
    # å°è¯•ç›´æ¥è§£æ
    proxies = parse_proxies_from_content(content)
    if proxies:
        return proxies
    # å¦‚æœé YAMLï¼Œæ£€æŸ¥æ˜¯å¦ä¸º base64
    if is_base64(content):
        proxies = decode_base64_and_parse(content)
        if proxies:
            return proxies
        else:
            print("  - Base64 è§£ç åæœªè§£æåˆ° Clash èŠ‚ç‚¹")
    else:
        print("  - å†…å®¹é Base64 ç¼–ç ï¼Œæ— æ³•è§£æä¸ºä»£ç†èŠ‚ç‚¹")
    # ä»¥ä¸Šéƒ½å¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    return []

# -------------- è§£æYAMLä»£ç†èŠ‚ç‚¹ --------------
def parse_proxies_from_content(content):
    try:
        data = yaml.safe_load(content)
        if isinstance(data, dict):
            proxies = data.get('proxies', [])
            return proxies if isinstance(proxies, list) else []
        elif isinstance(data, list):
            return data  # å¦‚æœ content æ˜¯ä¸€ä¸ªç›´æ¥çš„ä»£ç†åˆ—è¡¨
        else:
            print(f"  - è­¦å‘Š: è§£æçš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ proxies æ ¼å¼: {str(content)[:100]}")
            return []
    except (yaml.YAMLError, AttributeError) as e:
        print(f"  - YAML è§£æé”™è¯¯: {e}")
        return []
    except Exception as e:
        print(f"  - è§£æå†…å®¹æ—¶å…¶ä»–é”™è¯¯: {e}")
        return []

# -------------- åˆ¤æ–­æ˜¯å¦æ˜¯ base64 --------------
def is_base64(string):
    try:
        s = ''.join(string.split())
        if not s or len(s) % 4 != 0:
            return False
        if not re.match(r'^[A-Za-z0-9+/=]+$', s):
            return False
        base64.b64decode(s, validate=True)
        return True
    except Exception:
        return False

# -------------- base64 è§£ç å¹¶è§£æ Clash èŠ‚ç‚¹ --------------
def decode_base64_and_parse(base64_str):
    try:
        decoded_content = base64.b64decode(''.join(base64_str.split())).decode('utf-8', errors='ignore')
        proxies = []
        for line in decoded_content.splitlines():
            line = line.strip()
            proxy = None
            if line.startswith('vless://'):
                proxy = parse_vless_node(line)
            elif line.startswith('vmess://'):
                proxy = parse_vmess_node(line)
            elif line.startswith('ssr://'):
                proxy = parse_ssr_node(line)
            elif line.startswith('ss://'):
                proxy = parse_ss_node(line)
            elif line.startswith('trojan://'):
                proxy = parse_trojan_node(line)
            elif line.startswith('hysteria://'):
                proxy = parse_hysteria_node(line)
            elif line.startswith('hysteria2://'):
                proxy = parse_hysteria2_node(line)
            if proxy:
                proxies.append(proxy)
        return [p for p in proxies if p]
    except Exception as e:
        print(f"  - è§£ç  Base64 å¹¶è§£ææ—¶å‡ºé”™: {e}")
        return []


# ---------------- ä¸‹é¢æ˜¯å„ç§åè®®è§£æå‡½æ•° ----------------

def parse_vless_node(node_str):
    try:
        from urllib.parse import urlparse, parse_qs
        uri = urlparse(node_str)
        params = parse_qs(uri.query)
        proxy = {
            "name": uri.fragment or f"VLESS {uri.hostname}:{uri.port}",
            "type": "vless",
            "server": uri.hostname,
            "port": int(uri.port),
            "uuid": uri.username,
            "tls": params.get('security', ['none'])[0] == 'tls',
            "network": params.get('type', ['tcp'])[0],
            "servername": params.get('sni', [uri.hostname])[0],
        }
        return proxy
    except Exception as e:
        print(f"  - è§£æ VLESS èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def parse_ssr_node(node_str):
    try:
        node_str = node_str[6:]
        missing_padding = len(node_str) % 4
        if missing_padding:
            node_str += '=' * (4 - missing_padding)
        decoded = base64.urlsafe_b64decode(node_str).decode('utf-8')
        parts = decoded.split('/?')
        main_part, params_part = parts[0], parts[1] if len(parts) > 1 else ''
        main_params = main_part.split(':')
        server = main_params[0]
        port = main_params[1]
        protocol = main_params[2]
        method = main_params[3]
        obfs = main_params[4]
        password_encoded = main_params[5]
        password = base64.urlsafe_b64decode(password_encoded + '=' * (-len(password_encoded) % 4)).decode('utf-8')
        proxy = {
            "name": f"SSR {server}:{port}",
            "type": "ssr",
            "server": server,
            "port": int(port),
            "password": password,
            "cipher": method,
            "obfs": obfs,
            "protocol": protocol,
        }
        return proxy
    except Exception as e:
        print(f"  - è§£æ SSR èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def parse_vmess_node(node_str):
    try:
        base64_str = node_str[8:]
        decoded_str = base64.urlsafe_b64decode(base64_str + '=' * (-len(base64_str) % 4)).decode('utf-8')
        json_data = json.loads(decoded_str)
        proxy = {
            "name": json_data.get('ps', f"Vmess {json_data.get('add')}:{json_data.get('port')}"),
            "type": "vmess",
            "server": json_data.get('add'),
            "port": int(json_data.get('port')),
            "uuid": json_data.get('id'),
            "alterId": int(json_data.get('aid', 0)),
            "cipher": json_data.get('scy', "auto"),
            "tls": json_data.get('tls') == "tls",
            "network": json_data.get('net'),
            "ws-opts": {"path": json_data.get('path'), "headers": {"Host": json_data.get('host')}} if json_data.get('net') == 'ws' else None,
            "servername": json_data.get('sni', json_data.get('host')),
        }
        if proxy["ws-opts"]:
            proxy["ws-opts"] = {k: v for k, v in proxy["ws-opts"].items() if v}
            if not proxy["ws-opts"]:
                proxy["ws-opts"] = None
        proxy = {k: v for k, v in proxy.items() if v is not None}
        return proxy
    except Exception as e:
        print(f"  - è§£æ Vmess èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def parse_ss_node(node_str):
    try:
        from urllib.parse import urlparse, unquote
        uri = urlparse(node_str)
        userinfo = uri.username
        if userinfo is None:
            raise ValueError("SS URI ç¼ºå°‘ç”¨æˆ·ä¿¡æ¯éƒ¨åˆ†")
        userinfo_decoded = base64.urlsafe_b64decode(userinfo + '=' * (-len(userinfo) % 4)).decode('utf-8')
        cipher, password = userinfo_decoded.split(':', 1)
        proxy = {
            "name": unquote(uri.fragment) if uri.fragment else f"SS {uri.hostname}:{uri.port}",
            "type": "ss",
            "server": uri.hostname,
            "port": int(uri.port),
            "password": password,
            "cipher": cipher
        }
        return proxy
    except Exception as e:
        try:
            from urllib.parse import unquote
            parts = node_str[5:].split('#')
            main_part = parts[0]
            name = unquote(parts[1]) if len(parts) > 1 else None
            at_parts = main_part.split('@')
            if len(at_parts) != 2:
                raise ValueError("SS URI æ ¼å¼ä¸æ­£ç¡®")
            cred, server_info = at_parts[0], at_parts[1]
            cred_decoded = base64.urlsafe_b64decode(cred + '=' * (-len(cred) % 4)).decode('utf-8')
            cipher, password = cred_decoded.split(':', 1)
            server, port = server_info.split(':')
            proxy = {
                "name": name or f"SS {server}:{port}",
                "type": "ss",
                "server": server,
                "port": int(port),
                "password": password,
                "cipher": cipher
            }
            return proxy
        except Exception as e_inner:
            print(f"  - è§£æ SS èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯ (ä¸¤ç§æ–¹æ³•å‡å¤±è´¥): {e_inner}")
            return {}

def parse_trojan_node(node_str):
    try:
        from urllib.parse import urlparse, parse_qs, unquote
        uri = urlparse(node_str)
        params = parse_qs(uri.query)
        proxy = {
            "name": unquote(uri.fragment) if uri.fragment else f"Trojan {uri.hostname}:{uri.port}",
            "type": "trojan",
            "server": uri.hostname,
            "port": int(uri.port),
            "password": uri.username,
            "sni": params.get('sni', [uri.hostname])[0],
            "alpn": params.get('alpn', [None])[0],
        }
        if proxy.get('alpn'):
            proxy['alpn'] = proxy['alpn'].split(',')
        proxy = {k: v for k, v in proxy.items() if v is not None}
        return proxy
    except Exception as e:
        print(f"  - è§£æ Trojan èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def parse_hysteria_node(node_str):
    try:
        from urllib.parse import urlparse, parse_qs
        uri = urlparse(node_str)
        params = parse_qs(uri.query)
        proxy = {
            "name": uri.fragment or f"Hysteria {uri.hostname}:{uri.port}",
            "type": "hysteria",
            "server": uri.hostname,
            "port": int(uri.port),
            "auth_str": params.get('auth', [None])[0] or uri.username,
            "up": int(params['up_mbps'][0]) if 'up_mbps' in params else None,
            "down": int(params['down_mbps'][0]) if 'down_mbps' in params else None,
            "protocol": params.get('protocol', ['udp'])[0],
            "sni": params.get('sni', [uri.hostname])[0],
            "insecure": params.get('insecure', ['0'])[0] == '1',
            "obfs": params.get('obfs', [None])[0],
        }
        proxy = {k: v for k, v in proxy.items() if v is not None}
        return proxy
    except Exception as e:
        print(f"  - è§£æ Hysteria èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

def parse_hysteria2_node(node_str):
    try:
        from urllib.parse import urlparse, parse_qs, unquote
        uri = urlparse(node_str)
        params = parse_qs(uri.query)
        proxy = {
            "name": unquote(uri.fragment) if uri.fragment else f"Hysteria2 {uri.hostname}:{uri.port}",
            "type": "hysteria2",
            "server": uri.hostname,
            "port": int(uri.port),
            "password": uri.username,
            "sni": params.get('sni', [uri.hostname])[0],
            "insecure": params.get('insecure', ['0'])[0] == '1',
            "obfs": params.get('obfs', [None])[0],
            "obfs-password": params.get('obfs-password', [None])[0],
        }
        proxy = {k: v for k, v in proxy.items() if v is not None}
        return proxy
    except Exception as e:
        print(f"  - è§£æ Hysteria2 èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}

# ======================== å‰©ä½™åŸè„šæœ¬åŠŸèƒ½ ========================

def get_proxy_key(proxy):
    try:
        identifier = f"{proxy.get('server','')}:{proxy.get('port',0)}|"
        if 'uuid' in proxy:
            identifier += proxy['uuid']
        elif 'password' in proxy:
            identifier += proxy['password']
        else:
            identifier += proxy.get('name', '')
        return hashlib.md5(identifier.encode('utf-8')).hexdigest()
    except Exception:
        return None

def merge_and_deduplicate_proxies(subscriptions_proxies):
    unique_proxies = {}
    for proxy in subscriptions_proxies:
        if not isinstance(proxy, dict) or 'name' not in proxy:
            continue
        proxy_key = get_proxy_key(proxy)
        if proxy_key and proxy_key not in unique_proxies:
            unique_proxies[proxy_key] = proxy
    return list(unique_proxies.values())

def process_and_rename_proxies(proxies):
    country_counters = defaultdict(lambda: defaultdict(int))
    final_proxies = []

    all_region_names_for_stripping = set()
    for rules in CUSTOM_REGEX_RULES.values():
        all_region_names_for_stripping.update(rules['pattern'].split('|'))
    for k, v in CHINESE_COUNTRY_MAP.items():
        all_region_names_for_stripping.add(k)
        all_region_names_for_stripping.add(v)
    for k in COUNTRY_NAME_TO_CODE_MAP.keys():
        all_region_names_for_stripping.add(k)

    sorted_region_names = sorted(list(all_region_names_for_stripping), key=len, reverse=True)
    master_region_pattern = re.compile('|'.join(map(re.escape, sorted_region_names)), re.IGNORECASE)

    for p in proxies:
        original_name = p.get('name', '')
        temp_name_for_region_detection = FLAG_EMOJI_PATTERN.sub('', original_name)
        temp_name_for_region_detection = JUNK_PATTERNS.sub('', temp_name_for_region_detection).strip()
        for eng, chn in CHINESE_COUNTRY_MAP.items():
            temp_name_for_region_detection = re.sub(r'\b' + re.escape(eng) + r'\b', chn, temp_name_for_region_detection,
                                                    flags=re.IGNORECASE)
        p['region'] = 'æœªçŸ¥'
        for region_name, rules in CUSTOM_REGEX_RULES.items():
            if re.search(rules['pattern'], temp_name_for_region_detection, re.IGNORECASE):
                p['region'] = region_name
                break
        if p['region'] == 'æœªçŸ¥':
            for country_chn_name, country_code in COUNTRY_NAME_TO_CODE_MAP.items():
                if re.search(r'\b' + re.escape(country_chn_name) + r'\b', temp_name_for_region_detection, re.IGNORECASE):
                    p['region'] = country_chn_name
                    break

    for proxy in proxies:
        original_name = proxy.get('name', '')
        region_info = {'name': proxy['region'], 'code': COUNTRY_NAME_TO_CODE_MAP.get(proxy['region'])}
        if not region_info['code']:
            region_info['code'] = CUSTOM_REGEX_RULES.get(region_info['name'], {}).get('code', '')
        chosen_flag = ""
        name_for_feature_extraction = original_name
        match_existing_flag = FLAG_EMOJI_PATTERN.search(original_name)
        if match_existing_flag:
            chosen_flag = match_existing_flag.group(0)
            name_for_feature_extraction = FLAG_EMOJI_PATTERN.sub('', original_name, 1)
        else:
            chosen_flag = get_country_flag_emoji(region_info['code'])

        node_feature = master_region_pattern.sub(' ', name_for_feature_extraction)
        node_feature = JUNK_PATTERNS.sub(' ', node_feature)
        node_feature = node_feature.replace('-', ' ').strip()
        node_feature = re.sub(r'\s+', ' ', node_feature).strip()

        if not node_feature:
            seq = sum(1 for p_final in final_proxies if p_final.get('region') == region_info['name']) + 1
            node_feature = f"{seq:02d}"

        new_name = f"{chosen_flag} {region_info['name']} {node_feature}".strip()

        country_counters[region_info['name']][new_name] += 1
        count = country_counters[region_info['name']][new_name]
        if count > 1:
            new_name = f"{new_name} {count}"

        proxy['name'] = new_name
        final_proxies.append(proxy)
    return final_proxies

# --- æ–°çš„çº¯ Python socket æµ‹é€Ÿå‡½æ•° ---
def test_single_proxy_socket(proxy):
    server = proxy.get('server')
    port = proxy.get('port')
    if not server or not port:
        return None
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(SOCKET_TIMEOUT)
        start_time = time.time()
        sock.connect((str(server), int(port)))
        end_time = time.time()
        delay = (end_time - start_time) * 1000
        proxy['delay'] = int(delay)
        return proxy
    except (socket.timeout, ConnectionRefusedError, socket.gaierror, OSError):
        return None
    finally:
        if 'sock' in locals():
            sock.close()

def speed_test_proxies(proxies):
    print(f"å¼€å§‹ä½¿ç”¨çº¯ Python socket è¿›è¡Œå¹¶å‘æµ‹é€Ÿ (å…± {len(proxies)} ä¸ªèŠ‚ç‚¹)")
    fast_proxies = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_TEST_WORKERS) as executor:
        future_to_proxy = {executor.submit(test_single_proxy_socket, p): p for p in proxies}
        for i, future in enumerate(concurrent.futures.as_completed(future_to_proxy)):
            result = future.result()
            sys.stdout.write(f"\r  æµ‹è¯•è¿›åº¦: {i + 1}/{len(proxies)}")
            sys.stdout.flush()
            if result:
                fast_proxies.append(result)
    print(f"\næµ‹é€Ÿå®Œæˆï¼Œå‰©ä½™å¯ç”¨èŠ‚ç‚¹: {len(fast_proxies)}")
    return fast_proxies

def generate_config(proxies):
    if not proxies:
        return None
    proxy_names = [p['name'] for p in proxies]
    clean_proxies = [{k: v for k, v in p.items() if k not in ['region', 'delay']} for p in proxies]
    return {
        'mixed-port': 7890,
        'allow-lan': True,
        'bind-address': '*',
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'dns': {
            'enable': True,
            'listen': '0.0.0.0:53',
            'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16',
            'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': clean_proxies,
        'proxy-groups': [
            {'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'type': 'select', 'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + proxy_names},
            {'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'type': 'url-test', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
            {'name': 'ğŸ”¯ æ•…éšœè½¬ç§»', 'type': 'fallback', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300}
        ],
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

def load_subscription_urls_from_file(url_file_path, script_name_filter):
    urls = []
    if not os.path.exists(url_file_path):
        print(f"é”™è¯¯: è®¢é˜…æ–‡ä»¶ {url_file_path} ä¸å­˜åœ¨ã€‚è¯·ç¡®ä¿è¯¥æ–‡ä»¶ä¸è„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
        return urls
    print(f"æ­£åœ¨ä» {url_file_path} è¯»å–è®¢é˜…åœ°å€ï¼Œå¹¶è¿‡æ»¤åç§°åŒ…å« '{script_name_filter}' çš„æ¡ç›®")
    try:
        with open(url_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                match = re.search(r'([^ï¼š]+)ï¼š\s*(https?://\S+)', line)
                if match:
                    name_from_file = match.group(1).strip()
                    url = match.group(2)
                    if script_name_filter in name_from_file:
                        urls.append(url)
                        print(f"  âœ“ æ‰¾åˆ°å¹¶åŒ¹é…åˆ°è®¢é˜…: '{name_from_file}' -> {url[:80]}")
                    else:
                        print(f"  - è·³è¿‡ä¸åŒ¹é…çš„è®¢é˜… (åç§° '{name_from_file}' ä¸åŒ…å« '{script_name_filter}'): {line[:60]}")
                else:
                    print(f"  âœ— è·³è¿‡æ— æ³•è¯†åˆ«çš„è¡Œ (ä¸ç¬¦åˆ 'åç§°ï¼šåœ°å€' æ ¼å¼): {line[:60]}")
    except Exception as e:
        print(f"è¯»å–è®¢é˜…æ–‡ä»¶ {url_file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    return urls

def main():
    print("=" * 60)
    print("FlClashèŠ‚ç‚¹è·å–è„šæœ¬ V1.r1")
    print(f"Clash è®¢é˜…åˆå¹¶ @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    subscription_urls_from_file = load_subscription_urls_from_file(URL_FILE, CURRENT_SCRIPT_NAME)
    if not subscription_urls_from_file:
        sys.exit(f"\nâŒ é”™è¯¯: æœªèƒ½ä» {URL_FILE} æ–‡ä»¶ä¸­è¯»å–åˆ°ä»»ä½•åŒ¹é… '{CURRENT_SCRIPT_NAME}' çš„æœ‰æ•ˆè®¢é˜…åœ°å€ã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹å’Œæ ¼å¼ã€‚")

    print("\n[1/4] ä¸‹è½½ä¸åˆå¹¶è®¢é˜…")
    all_proxies = []
    for url in subscription_urls_from_file:
        all_proxies.extend(download_subscription(url))

    unique_proxies = merge_and_deduplicate_proxies(all_proxies)
    if not unique_proxies:
        sys.exit("\nâŒ é”™è¯¯: æ‰€æœ‰è®¢é˜…ä¸‹è½½å¤±è´¥æˆ–åˆå¹¶åæ— èŠ‚ç‚¹ã€‚")
    print(f"  âœ“ åˆå¹¶åå…± {len(unique_proxies)} ä¸ªä¸é‡å¤èŠ‚ç‚¹ã€‚")

    print("\n[2/4] æµ‹é€Ÿä¸ç­›é€‰èŠ‚ç‚¹")
    if ENABLE_SPEED_TEST:
        available_proxies = speed_test_proxies(unique_proxies)
        if not available_proxies:
            print("\n  âš ï¸ è­¦å‘Š: æµ‹é€Ÿåæ— å¯ç”¨èŠ‚ç‚¹ï¼Œå°†ä½¿ç”¨æ‰€æœ‰èŠ‚ç‚¹ç”Ÿæˆé…ç½®ã€‚")
            available_proxies = unique_proxies
    else:
        print("  - å·²è·³è¿‡å»¶è¿Ÿæµ‹è¯•ã€‚")
        available_proxies = unique_proxies

    print("\n[3/4] æ’åºä¸é‡å‘½åèŠ‚ç‚¹")
    region_order = {region: i for i, region in enumerate(REGION_PRIORITY)}
    available_proxies.sort(key=lambda p: (region_order.get(p.get('region', 'æœªçŸ¥'), 99), p.get('delay', 9999)))
    final_proxies = process_and_rename_proxies(available_proxies)
    print(f"\n  âœ“ å…± {len(final_proxies)} ä¸ªèŠ‚ç‚¹å®Œæˆæ’åºå’Œé‡å‘½åã€‚")

    print("\n[4/4] ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶")
    config = generate_config(final_proxies)
    if not config:
        sys.exit("\nâŒ é”™è¯¯: æ— æ³•ç”Ÿæˆé…ç½®æ–‡ä»¶ã€‚")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2)
    print(f"\n  âœ“ é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}")

    print("\nâœ… ä»»åŠ¡å®Œæˆï¼")

if __name__ == '__main__':
    main()
