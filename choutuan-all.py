#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‘å›¢ - Clash è®¢é˜…åˆå¹¶è„šæœ¬ (v3 - æ™ºèƒ½é‡å‘½åç‰ˆ)
- ç²¾å‡†å»é‡: Server + Port + Password/UUID
- æ™ºèƒ½é‡å‘½å: è‡ªåŠ¨è¯†åˆ«å›½å®¶/åœ°åŒºï¼Œå¹¶é‡å‘½åä¸º [Emoji][åœ°åŒº] - [åºå·]
"""

import requests
import yaml
from datetime import datetime
import sys
import os
import hashlib
import re
from collections import defaultdict

# ========== è®¢é˜…é…ç½® ==========
SUBSCRIPTION_URLS = [
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A21?token=ChouLink1",
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A22?token=ChouLink2",
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A23?token=ChouLink3",
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A24?token=ChouLink4",
]

OUTPUT_DIR = "flclashyaml"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "choutuan-all.yaml")

# ========== å›½å®¶/åœ°åŒºåŒ¹é…è§„åˆ™ (æŒ‰é¡ºåºåŒ¹é…) ==========
# æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åŸå§‹èŠ‚ç‚¹åï¼Œä»¥ç¡®å®šå…¶åœ°ç†ä½ç½®
COUNTRY_RULES = {
    'é¦™æ¸¯': {'emoji': 'ğŸ‡­ğŸ‡°', 'regex': re.compile(r'HK|Hong|HONG|Kong|KONG|æ¸¯|é¦™æ¸¯')},
    'å°æ¹¾': {'emoji': 'ğŸ‡¹ğŸ‡¼', 'regex': re.compile(r'TW|Taiwan|TAIWAN|å°|å°æ¹¾|è‡º')},
    'æ–°åŠ å¡': {'emoji': 'ğŸ‡¸ğŸ‡¬', 'regex': re.compile(r'SG|Singapore|SINGAPORE|ç‹®åŸ|å¡')},
    'æ—¥æœ¬': {'emoji': 'ğŸ‡¯ğŸ‡µ', 'regex': re.compile(r'JP|Japan|JAPAN|æ—¥|æ—¥æœ¬|ä¸œäº¬|å¤§é˜ª|åŸ¼ç‰|æ²ªæ—¥|æ·±æ—¥')},
    'ç¾å›½': {'emoji': 'ğŸ‡ºğŸ‡¸', 'regex': re.compile(r'US|USA|United States|ç¾|ç¾å›½|äºšç‰¹å…°å¤§|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|ä¿„å‹’å†ˆ|å‡¤å‡°åŸ|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|è¥¿é›…å›¾|èŠåŠ å“¥')},
    'éŸ©å›½': {'emoji': 'ğŸ‡°ğŸ‡·', 'regex': re.compile(r'KR|Korea|KOREA|éŸ©|éŸ©å›½|é¦–å°”|éŸ“')},
    'è‹±å›½': {'emoji': 'ğŸ‡¬ğŸ‡§', 'regex': re.compile(r'UK|United Kingdom|è‹±|è‹±å›½')},
    'å¾·å›½': {'emoji': 'ğŸ‡©ğŸ‡ª', 'regex': re.compile(r'DE|Germany|GERMANY|å¾·|å¾·å›½')},
    'ä¿„ç½—æ–¯': {'emoji': 'ğŸ‡·ğŸ‡º', 'regex': re.compile(r'RU|Russia|RUSSIA|ä¿„|ä¿„ç½—æ–¯')},
    # å¿…é¡»æ”¾åœ¨æœ€åï¼Œä½œä¸ºâ€œæœªåŒ¹é…â€çš„é»˜è®¤é€‰é¡¹
    'å…¶ä»–': {'emoji': 'ğŸŒ', 'regex': re.compile(r'.*')}
}


def download_subscription(url):
    """ä¸‹è½½å¹¶è§£æè®¢é˜…å†…å®¹"""
    try:
        headers = {'User-Agent': 'Clash/1.11.4 (Windows; x64)'}
        print(f"  ä¸‹è½½: {url[:60]}...")
        response = requests.get(url, timeout=30, headers=headers)
        response.raise_for_status()
        data = yaml.safe_load(response.text)
        if not isinstance(data, dict) or 'proxies' not in data:
            print("  âš  è­¦å‘Š: è®¢é˜…å†…å®¹æ— æ•ˆæˆ–æ— èŠ‚ç‚¹ã€‚")
            return None
        return data
    except Exception as e:
        print(f"  âœ— ä¸‹è½½æˆ–è§£æå¤±è´¥: {e}")
        return None

def get_proxy_key(proxy):
    """æ ¹æ®èŠ‚ç‚¹çš„å…³é”®ä¿¡æ¯ (server, port, password/uuid) ç”Ÿæˆå”¯ä¸€æ ‡è¯†"""
    try:
        server = proxy.get('server', '')
        port = proxy.get('port', 0)
        password = proxy.get('password', '') or proxy.get('uuid', '')
        return hashlib.md5(f"{server}:{port}|{password}".encode('utf-8')).hexdigest()
    except Exception:
        return None

def merge_and_deduplicate_proxies(subscriptions):
    """åˆå¹¶å¹¶ä½¿ç”¨ç²¾ç¡®è§„åˆ™å»é‡ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹åç§°ç”¨äºåç»­å¤„ç†"""
    unique_proxies = {}
    total_nodes = 0
    invalid_nodes = 0

    for sub in subscriptions:
        proxies_in_sub = sub.get('proxies', [])
        if not isinstance(proxies_in_sub, list):
            continue
        for proxy in proxies_in_sub:
            total_nodes += 1
            if not isinstance(proxy, dict) or 'name' not in proxy:
                invalid_nodes += 1
                continue
            
            proxy_key = get_proxy_key(proxy)
            if proxy_key and proxy_key not in unique_proxies:
                unique_proxies[proxy_key] = proxy
    
    print(f"  - å…±å¤„ç†èŠ‚ç‚¹: {total_nodes}")
    print(f"  - æ— æ•ˆ/æ ¼å¼é”™è¯¯èŠ‚ç‚¹: {invalid_nodes}")
    print(f"  - é‡å¤èŠ‚ç‚¹(å·²åˆå¹¶): {total_nodes - invalid_nodes - len(unique_proxies)}")
    
    return list(unique_proxies.values())

def rename_and_sort_proxies(proxies):
    """æ ¹æ®å›½å®¶/åœ°åŒºè§„åˆ™å¯¹èŠ‚ç‚¹è¿›è¡Œé‡å‘½åå’Œæ’åº"""
    renamed_proxies = []
    country_counters = defaultdict(int)

    for proxy in proxies:
        original_name = proxy['name']
        matched_country = None

        for country, rules in COUNTRY_RULES.items():
            if rules['regex'].search(original_name):
                matched_country = country
                break
        
        # å¢åŠ å¯¹åº”å›½å®¶çš„è®¡æ•°å™¨
        country_counters[matched_country] += 1
        
        # ç”Ÿæˆæ–°åç§°ï¼Œä¾‹å¦‚ï¼šğŸ‡­ğŸ‡° é¦™æ¸¯ - 01
        emoji = COUNTRY_RULES[matched_country]['emoji']
        seq_num = country_counters[matched_country]
        new_name = f"{emoji} {matched_country} - {seq_num:02d}"
        
        # æ›´æ–°èŠ‚ç‚¹åç§°
        proxy['name'] = new_name
        renamed_proxies.append(proxy)
        
    print(f"  âœ“ æˆåŠŸé‡å‘½å {len(renamed_proxies)} ä¸ªèŠ‚ç‚¹ã€‚")
    return renamed_proxies


def generate_config(proxies):
    """æ ¹æ®æœ€ç»ˆçš„èŠ‚ç‚¹åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„ Clash é…ç½®æ–‡ä»¶"""
    if not proxies:
        print("  âœ— é”™è¯¯: æ²¡æœ‰å¯ç”¨äºç”Ÿæˆé…ç½®çš„èŠ‚ç‚¹ã€‚")
        return None
        
    proxy_names = [p['name'] for p in proxies]
    
    return {
        'profile-name': 'ä¸‘å›¢',
        'mixed-port': 7890,
        'allow-lan': True,
        'bind-address': '*',
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'external-ui': 'ui',
        'dns': {
            'enable': True, 'listen': '0.0.0.0:53', 'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16', 'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': proxies,
        'proxy-groups': [
            {'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'type': 'select', 'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + proxy_names},
            {'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'type': 'url-test', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
            {'name': 'ğŸ”¯ æ•…éšœè½¬ç§»', 'type': 'fallback', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300}
        ],
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

def main():
    print("=" * 60)
    print(f"ä¸‘å›¢ - Clash è®¢é˜…åˆå¹¶ (v3 - æ™ºèƒ½é‡å‘½åç‰ˆ) @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print("\n[1/4] å¼€å§‹ä¸‹è½½è®¢é˜…...")
    subscriptions = []
    for url in SUBSCRIPTION_URLS:
        sub_data = download_subscription(url)
        if sub_data:
            subscriptions.append(sub_data)
    
    if not subscriptions:
        print("\nâŒ é”™è¯¯: æ‰€æœ‰è®¢é˜…éƒ½ä¸‹è½½å¤±è´¥ï¼Œä»»åŠ¡ä¸­æ–­ã€‚")
        sys.exit(1)
    
    print(f"\n[2/4] å¼€å§‹åˆå¹¶ä¸å»é‡...")
    unique_proxies = merge_and_deduplicate_proxies(subscriptions)
    
    if not unique_proxies:
        print("\nâŒ é”™è¯¯: åˆå¹¶åæ²¡æœ‰å¯ç”¨çš„èŠ‚ç‚¹ï¼Œä»»åŠ¡ä¸­æ–­ã€‚")
        sys.exit(1)

    print(f"\n[3/4] å¼€å§‹æ™ºèƒ½é‡å‘½åèŠ‚ç‚¹...")
    final_proxies = rename_and_sort_proxies(unique_proxies)

    print(f"\n[4/4] å¼€å§‹ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶...")
    config = generate_config(final_proxies)
    
    if not config:
        sys.exit(1)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2, default_flow_style=False)
    
    print(f"  âœ“ é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}")
    print("\nâœ… ä»»åŠ¡å®Œæˆï¼")

if __name__ == '__main__':
    main()
