#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‘å›¢ - Clash è®¢é˜…åˆå¹¶è„šæœ¬ (v7 - è‡ªå®šä¹‰æ­£åˆ™ç‰ˆ)
- æ”¯æŒé«˜ä¼˜å…ˆçº§çš„è‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼ï¼Œç”¨äºç²¾å‡†åŒ¹é…å¸¸è§åœ°åŒº
- åŠ¨æ€ç”Ÿæˆå…¨çƒ ~250 ä¸ªå›½å®¶/åœ°åŒºçš„åŒ¹é…è§„åˆ™ä½œä¸ºè¡¥å……
- æ™ºèƒ½æ¸…æ´—èŠ‚ç‚¹åï¼Œå»é™¤å¹²æ‰°è¯
- ä¼˜å…ˆåŒ¹é…å›½å®¶/åœ°åŒºå¹¶é‡å‘½åï¼Œæ— æ³•åŒ¹é…çš„åˆ™æ¸…æ´—åç§°åä¿ç•™
- ç²¾å‡†å»é‡: Server + Port + Password/UUID
"""

import requests
import yaml
from datetime import datetime
import sys
import os
import hashlib
import re
from collections import defaultdict
import pycountry

# ========== è®¢é˜…é…ç½® ==========
SUBSCRIPTION_URLS = [
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A21?token=ChouLink1",
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A22?token=ChouLink2",
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A23?token=ChouLink3",
    "https://substore.panell.top/share/file/%E4%B8%91%E5%9B%A24?token=ChouLink4",
]

OUTPUT_DIR = "flclashyaml"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "choutuan-all.yaml")

# ========== åç§°æ¸…æ´—è§„åˆ™ ==========
JUNK_PATTERNS = re.compile(
    r'ä¸‘å›¢|ä¸“çº¿|IPLC|IEPL|BGP|ä½“éªŒ|å®˜ç½‘|'
    r'[\[\(ã€ã€Œ].*?[\]\)ã€‘ã€]|^\s*@\w+\s*',
    re.IGNORECASE
)

# ========== é«˜ä¼˜å…ˆçº§è‡ªå®šä¹‰æ­£åˆ™è§„åˆ™ ==========
# åœ¨è¿™é‡Œå¯ä»¥è‡ªç”±ä¿®æ”¹å’Œæ·»åŠ æ­£åˆ™è¡¨è¾¾å¼ï¼Œå®ƒä»¬ä¼šæœ€å…ˆè¢«ç”¨æ¥åŒ¹é…
CUSTOM_REGEX_RULES = {
    # æ˜¾ç¤ºåç§°: { code: 'ä¸¤å­—æ¯å›½å®¶ä»£ç ', pattern: r'æ­£åˆ™è¡¨è¾¾å¼' }
    'é¦™æ¸¯': {'code': 'HK', 'pattern': r'æ¸¯|HK|Hong Kong'},
    'æ—¥æœ¬': {'code': 'JP', 'pattern': r'æ—¥æœ¬|å·æ—¥|ä¸œäº¬|å¤§é˜ª|æ³‰æ—¥|åŸ¼ç‰|æ²ªæ—¥|æ·±æ—¥|JP|Japan'},
    'ç‹®åŸ': {'code': 'SG', 'pattern': r'æ–°åŠ å¡|SG|Singapore|å¡|ç‹®åŸ'},
    'ç¾å›½': {'code': 'US', 'pattern': r'^(?!.*(?:aus|rus)).*(?:\b(?:us|usa|united states)\b|ç¾|æ³¢ç‰¹å…°|è¾¾æ‹‰æ–¯|Oregon|å‡¤å‡°åŸ|è´¹åˆ©è’™|ç¡…è°·|æ‹‰æ–¯ç»´åŠ æ–¯|æ´›æ‰çŸ¶|åœ£ä½•å¡|åœ£å…‹æ‹‰æ‹‰|è¥¿é›…å›¾|èŠåŠ å“¥)'},
    'æ¹¾çœ': {'code': 'TW', 'pattern': r'å°æ¹¾|TW|Taiwan|å°|æ–°åŒ—|å½°åŒ–'},
    'éŸ©å›½': {'code': 'KR', 'pattern': r'éŸ©|KR|Korea|KOR|é¦–å°”|éŸ“'},
    'å¾·å›½': {'code': 'DE', 'pattern': r'å¾·å›½|DE|Germany'},
}

def code_to_emoji(code):
    """å°†ä¸¤å­—æ¯å›½å®¶ä»£ç è½¬æ¢ä¸ºå›½æ—— Emoji"""
    if not code or len(code) != 2: return 'ğŸŒ'
    return "".join(chr(0x1F1E6 + ord(char.upper()) - ord('A')) for char in code)

def build_country_rules():
    """åŠ¨æ€æ„å»ºå…¨çƒå›½å®¶/åœ°åŒºçš„åŒ¹é…è§„åˆ™"""
    print("  - æ„å»ºå›½å®¶åŒ¹é…è§„åˆ™...")
    rules = {}
    
    # 1. åŠ è½½é«˜ä¼˜å…ˆçº§çš„è‡ªå®šä¹‰æ­£åˆ™è§„åˆ™
    for display_name, data in CUSTOM_REGEX_RULES.items():
        rules[display_name] = {
            'emoji': code_to_emoji(data['code']),
            'regex': re.compile(data['pattern'], re.IGNORECASE)
        }
    print(f"  âœ“ åŠ è½½äº† {len(rules)} æ¡è‡ªå®šä¹‰é«˜ä¼˜è§„åˆ™ã€‚")
    
    # 2. ä½¿ç”¨ pycountry åŠ¨æ€ç”Ÿæˆå…¶ä»–å›½å®¶çš„è§„åˆ™ä½œä¸ºè¡¥å……
    covered_codes = {data['code'] for data in CUSTOM_REGEX_RULES.values()}
    pycountry_added = 0
    for country in pycountry.countries:
        if country.alpha_2 in covered_codes: continue
        
        keywords = [country.alpha_2, country.alpha_3]
        if hasattr(country, 'common_name'): keywords.append(country.common_name)
        if hasattr(country, 'official_name'): keywords.append(country.official_name)
        
        keywords = sorted(list(set(kw for kw in keywords if len(kw) > 1)), key=len, reverse=True)
        
        if keywords:
            display_name = country.name.split(',')[0] # ä½¿ç”¨æ›´ç®€æ´çš„åç§°
            rules[display_name] = {
                'emoji': code_to_emoji(country.alpha_2),
                'regex': re.compile('|'.join(map(re.escape, keywords)), re.IGNORECASE)
            }
            pycountry_added += 1
            
    print(f"  âœ“ åŠ¨æ€ç”Ÿæˆäº† {pycountry_added} æ¡å…¨çƒè§„åˆ™ã€‚")
    print(f"  - æ€»è®¡ {len(rules)} æ¡è§„åˆ™ã€‚")
    return rules

COUNTRY_RULES = build_country_rules()


def download_subscription(url):
    """ä¸‹è½½å¹¶è§£æè®¢é˜…å†…å®¹"""
    try:
        headers = {'User-Agent': 'Clash/1.11.4 (Windows; x64)'}
        print(f"  ä¸‹è½½: {url[:60]}...")
        response = requests.get(url, timeout=30, headers=headers)
        response.raise_for_status()
        data = yaml.safe_load(response.text)
        if not isinstance(data, dict) or 'proxies' not in data:
            print("  âš  è­¦å‘Š: è®¢é˜…å†…å®¹æ— æ•ˆæˆ–æ— èŠ‚ç‚¹ã€‚")
            return None
        return data
    except Exception as e:
        print(f"  âœ— ä¸‹è½½æˆ–è§£æå¤±è´¥: {e}")
        return None

def get_proxy_key(proxy):
    """æ ¹æ®èŠ‚ç‚¹çš„å…³é”®ä¿¡æ¯ç”Ÿæˆå”¯ä¸€æ ‡è¯†"""
    try:
        server = proxy.get('server', '')
        port = proxy.get('port', 0)
        password = proxy.get('password', '') or proxy.get('uuid', '')
        return hashlib.md5(f"{server}:{port}|{password}".encode('utf-8')).hexdigest()
    except Exception:
        return None

def merge_and_deduplicate_proxies(subscriptions):
    """åˆå¹¶å¹¶ä½¿ç”¨ç²¾ç¡®è§„åˆ™å»é‡"""
    unique_proxies = {}
    for sub in subscriptions:
        proxies_in_sub = sub.get('proxies', [])
        if not isinstance(proxies_in_sub, list): continue
        for proxy in proxies_in_sub:
            if not isinstance(proxy, dict) or 'name' not in proxy: continue
            proxy_key = get_proxy_key(proxy)
            if proxy_key and proxy_key not in unique_proxies:
                unique_proxies[proxy_key] = proxy
    return list(unique_proxies.values())

def process_and_rename_proxies(proxies):
    """
    æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼š
    1. ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ­£åˆ™åŒ¹é…å›½å®¶å¹¶é‡å‘½åã€‚
    2. è‹¥æ— æ³•åŒ¹é…ï¼Œåˆ™ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„å…¨çƒè§„åˆ™åŒ¹é…ã€‚
    3. è‹¥ä»æ— æ³•åŒ¹é…ï¼Œåˆ™æ¸…æ´—åç§°åä¿ç•™ã€‚
    4. æœ€åå¤„ç†æ‰€æœ‰åç§°å†²çªï¼Œç¡®ä¿å”¯ä¸€æ€§ã€‚
    """
    processed_proxies = []
    country_counters = defaultdict(int)
    unmatched_nodes_count = 0

    for proxy in proxies:
        original_name = proxy['name']
        cleaned_name = JUNK_PATTERNS.sub('', original_name).strip()
        
        matched_display_name = None
        for display_name, rules in COUNTRY_RULES.items():
            if rules['regex'].search(cleaned_name) or rules['regex'].search(original_name):
                matched_display_name = display_name
                break
        
        if matched_display_name:
            country_counters[matched_display_name] += 1
            emoji = COUNTRY_RULES[matched_display_name]['emoji']
            seq_num = country_counters[matched_display_name]
            proxy['name'] = f"{emoji} {matched_display_name} - {seq_num:02d}"
        else:
            proxy['name'] = cleaned_name if cleaned_name else original_name
            unmatched_nodes_count += 1
        
        processed_proxies.append(proxy)
    
    print(f"\n  - æˆåŠŸåŒ¹é…å›½å®¶/åœ°åŒºçš„èŠ‚ç‚¹: {len(processed_proxies) - unmatched_nodes_count}")
    print(f"  - æœªåŒ¹é…å›½å®¶/åœ°åŒº (å·²ä¿ç•™å¹¶æ¸…æ´—åç§°) çš„èŠ‚ç‚¹: {unmatched_nodes_count}")

    final_proxies = []
    seen_names = set()
    for proxy in processed_proxies:
        base_name = proxy['name']
        final_name = base_name
        counter = 1
        while final_name in seen_names:
            final_name = f"{base_name} ({counter})"
            counter += 1
        
        proxy['name'] = final_name
        seen_names.add(final_name)
        final_proxies.append(proxy)
        
    print(f"  âœ“ æ€»è®¡ä¿ç•™èŠ‚ç‚¹: {len(final_proxies)}")
    return final_proxies


def generate_config(proxies):
    """æ ¹æ®æœ€ç»ˆçš„èŠ‚ç‚¹åˆ—è¡¨ç”Ÿæˆå®Œæ•´çš„ Clash é…ç½®æ–‡ä»¶"""
    if not proxies:
        print("  âœ— é”™è¯¯: æ²¡æœ‰å¯ç”¨äºç”Ÿæˆé…ç½®çš„èŠ‚ç‚¹ã€‚")
        return None
        
    proxy_names = [p['name'] for p in proxies]
    
    return {
        'profile-name': 'ä¸‘å›¢',
        'mixed-port': 7890,
        'allow-lan': True,
        'bind-address': '*',
        'mode': 'rule',
        'log-level': 'info',
        'external-controller': '127.0.0.1:9090',
        'external-ui': 'ui',
        'dns': {
            'enable': True, 'listen': '0.0.0.0:53', 'enhanced-mode': 'fake-ip',
            'fake-ip-range': '198.18.0.1/16', 'nameserver': ['223.5.5.5', '119.29.29.29'],
            'fallback': ['https://dns.google/dns-query', 'https://1.1.1.1/dns-query']
        },
        'proxies': proxies,
        'proxy-groups': [
            {'name': 'ğŸš€ èŠ‚ç‚¹é€‰æ‹©', 'type': 'select', 'proxies': ['â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'ğŸ”¯ æ•…éšœè½¬ç§»', 'DIRECT'] + proxy_names},
            {'name': 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©', 'type': 'url-test', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
            {'name': 'ğŸ”¯ æ•…éšœè½¬ç§»', 'type': 'fallback', 'proxies': proxy_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300}
        ],
        'rules': ['GEOIP,CN,DIRECT', 'MATCH,ğŸš€ èŠ‚ç‚¹é€‰æ‹©']
    }

def main():
    print("=" * 60)
    print(f"ä¸‘å›¢ - Clash è®¢é˜…åˆå¹¶ (v7 - è‡ªå®šä¹‰æ­£åˆ™ç‰ˆ) @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print("\n[1/4] å¼€å§‹ä¸‹è½½è®¢é˜…...")
    subscriptions = [sub for sub in (download_subscription(url) for url in SUBSCRIPTION_URLS) if sub]
    if not subscriptions:
        print("\nâŒ é”™è¯¯: æ‰€æœ‰è®¢é˜…éƒ½ä¸‹è½½å¤±è´¥ï¼Œä»»åŠ¡ä¸­æ–­ã€‚")
        sys.exit(1)
    
    print(f"\n[2/4] å¼€å§‹åˆå¹¶ä¸å»é‡...")
    unique_proxies = merge_and_deduplicate_proxies(subscriptions)
    if not unique_proxies:
        print("\nâŒ é”™è¯¯: åˆå¹¶åæ²¡æœ‰å¯ç”¨çš„èŠ‚ç‚¹ï¼Œä»»åŠ¡ä¸­æ–­ã€‚")
        sys.exit(1)

    print(f"\n[3/4] å¼€å§‹å¤„ç†å’Œé‡å‘½åèŠ‚ç‚¹...")
    final_proxies = process_and_rename_proxies(unique_proxies)

    print(f"\n[4/4] å¼€å§‹ç”Ÿæˆæœ€ç»ˆé…ç½®æ–‡ä»¶...")
    config = generate_config(final_proxies)
    if not config:
        sys.exit(1)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, sort_keys=False, indent=2, default_flow_style=False)
    
    print(f"  âœ“ é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {OUTPUT_FILE}")
    print("\nâœ… ä»»åŠ¡å®Œæˆï¼")

if __name__ == '__main__':
    main()
